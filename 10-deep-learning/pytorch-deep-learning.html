
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>PyTorch: Deep Learning</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Transformers: Transfer Learning" href="transformers-transfer-learning.html" />
    <link rel="prev" title="Keras: Convolutional Networks" href="keras-convolutional-networks.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.svg" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../util/intro.html">
                    Data Science
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01-python-programing/_intro.html">
   <b>
    1. Python Programing
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-basic-concepts.html">
     Python: Basic Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-data-types.html">
     Python: Data Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-data-containers.html">
     Python: Data Containers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-functions-objects.html">
     Python: Functions and Objects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-algorithms.html">
     (w) Python: Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-external-sources.html">
     Python: External Sources
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/selenium-web-scraping.html">
     Selenium: Web Scraping
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02-mathematics/_intro.html">
   <b>
    2. Mathematics
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/numpy-linear-algebra.html">
     NumPy: Linear Algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/sympy-calculus.html">
     SymPy: Calculus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/numpy-probability.html">
     NumPy: Probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/numpy-statistics.html">
     NumPy: Statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/scipy-hypothesis-testing.html">
     SciPy: Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/numpy-applied-mathematics.html">
     NumPy: Applied Mathematics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/networkx-network-analysis.html">
     (w) NetworkX: Network Analysis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03-data-manipulation/_intro.html">
   <b>
    3. Data Manipulation
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/numpy-arrays.html">
     NumPy: Arrays
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/pandas-data-exploratory.html">
     Pandas: Data Exploratory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/pandas-data-cleaning.html">
     Pandas: Data Cleaning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/pandas-data-transformation.html">
     Pandas: Data Transformation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/janitor-pandas-extensions.html">
     Janitor: Pandas Extensions
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04-big-data/_intro.html">
   <b>
    4. Big Data
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/hiveql-data-manipulation.html">
     HiveQL: Data Manipulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/pyspark-data-exploratory.html">
     PySpark: Data Exploratory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/pyspark-data-cleaning.html">
     PySpark: Data Cleaning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/pyspark-data-transformation.html">
     PySpark: Data Transformation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/dask-parallelized-pandas.html">
     Dask: Parallelized Pandas
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../05-data-visualization/_intro.html">
   <b>
    5. Data Visualization
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-data-visualization/matplotlib-graph-construction.html">
     Matplotlib: Graph Construction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-data-visualization/seaborn-statistical-visualization.html">
     Seaborn: Statistical Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-data-visualization/plotly-interactive-visualization.html">
     Plotly: Interactive Visualization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../06-machine-learning/_intro.html">
   <b>
    6. Machine Learning
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-machine-learning/sklearn-machine-learning.html">
     Sklearn: Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-machine-learning/sklearn-classification.html">
     Sklearn: Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-machine-learning/sklearn-regression.html">
     Sklearn: Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-machine-learning/sklearn-feature-engineering.html">
     Sklearn: Feature Engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-machine-learning/lenskit-recommendation.html">
     Lenskit: Recommendation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-machine-learning/pyspark-machine-learning.html">
     PySpark: Machine Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../07-tabular-learning/_intro.html">
   <b>
    7. Tabular Learning
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-tabular-learning/sklearn-ensemble-learning.html">
     Sklearn: Ensemble Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-tabular-learning/xgboost-tree-boosting.html">
     XGBoost: Tree Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-tabular-learning/ray-hyperparameter-optimization.html">
     Ray: Hyperparam Optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-tabular-learning/shap-model-interpretation.html">
     Shap: Model Interpretation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-tabular-learning/imblearn-targeted-modeling.html">
     Imblearn: Targeted Modeling
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../08-time-series/_intro.html">
   <b>
    8. Time Series
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-time-series/statsmodels-temporal-analysis.html">
     Statsmodels: Temporal Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-time-series/prophet-forecasting-algorithms.html">
     Prophet: Forecasting Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-time-series/sktime-forecasting-pipeline.html">
     Sktime: Forecasting Pipeline
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-time-series/darts-deep-forecasting.html">
     Darts: Deep Forecasting
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../09-unsupervised-learning/_intro.html">
   <b>
    9. Unsupervised Learning
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-unsupervised-learning/mlxtend-association-rules.html">
     (w) MLxtend: Association Rules
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-unsupervised-learning/sklearn-clustering.html">
     Sklearn: Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-unsupervised-learning/sklearn-dimensional-reduction.html">
     Sklearn: Dimensional Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-unsupervised-learning/pyod-anomaly-detection.html">
     PyOD: Anomaly Detection
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="_intro.html">
   <b>
    10. Deep Learning
   </b>
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="gensim-text-mining.html">
     Gensim: Text Mining
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="opencv-image-processing.html">
     OpenCV: Image Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="numpy-gradient-descent.html">
     Python: Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="keras-multilayer-perceptron.html">
     Keras: Multilayer Perceptron
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="keras-recurrent-networks.html">
     Keras: Recurrent Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="keras-convolutional-networks.html">
     Keras: Convolutional Networks
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     PyTorch: Deep Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="transformers-transfer-learning.html">
     Transformers: Transfer Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../11-r-programing/_intro.html">
   <b>
    11. R Programing
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/r-basic-concepts.html">
     R: Basic Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/r-data-structures.html">
     R: Data Structures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/tidyverse-data-wrangling.html">
     Tidyverse: Data Wrangling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/dplyr-data-cleaning.html">
     Dplyr: Data Cleaning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/ggplot-data-visualization.html">
     Ggplot: Data Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/r-statistics.html">
     R: Statistics
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/hungpq7/tabular-book/master?urlpath=lab/tree/10-deep-learning/pytorch-deep-learning.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/hungpq7/tabular-book/blob/master/10-deep-learning/pytorch-deep-learning.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/hungpq7/tabular-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/10-deep-learning/pytorch-deep-learning.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-manipulation">
   1. Data manipulation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#computation">
     1.1. Computation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tensor">
       Tensor
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autograd">
       Autograd
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#optimization">
       Optimization
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-loader">
     1.2. Data loader
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gradient-zeroing">
       Gradient zeroing
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gradient-accumulation">
       Gradient accumulation
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#w-language-processing">
     (w) Language processing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#w-image-processing">
     (w) Image processing
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#neural-networks">
   2. Neural networks
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modular-design">
     2.1. Modular design
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#layers">
       Layers
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resources">
   Resources
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#install">
   Install
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>PyTorch: Deep Learning</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-manipulation">
   1. Data manipulation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#computation">
     1.1. Computation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tensor">
       Tensor
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#autograd">
       Autograd
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#optimization">
       Optimization
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-loader">
     1.2. Data loader
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gradient-zeroing">
       Gradient zeroing
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gradient-accumulation">
       Gradient accumulation
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#w-language-processing">
     (w) Language processing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#w-image-processing">
     (w) Image processing
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#neural-networks">
   2. Neural networks
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modular-design">
     2.1. Modular design
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#layers">
       Layers
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resources">
   Resources
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#install">
   Install
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="pytorch-deep-learning">
<h1>PyTorch: Deep Learning<a class="headerlink" href="#pytorch-deep-learning" title="Permalink to this headline">#</a></h1>
<p><a class="reference external" href="https://github.com/pytorch/pytorch">PyTorch</a> is one of the two most popular Deep Learning frameworks in Python, besides TensorFlow. Here is some key points when comparing the two:</p>
<ul class="simple">
<li><p>In terms of low or high level, PyTorch falls somewhere in between TensorFlow and Keras. No fit-and-predict interface, must be done by hand.</p></li>
<li><p>PyTorch is prefered by research community with more customizations, as we normally see newly published architectures written in PyTorch.</p></li>
<li><p>TensorFlow/Keras is better for production due to high-level interface and large deployment ecosystem.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">janitor</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;seaborn&#39;</span><span class="p">,</span> <span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">])</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
</pre></div>
</div>
</div>
</div>
<section id="data-manipulation">
<h2>1. Data manipulation<a class="headerlink" href="#data-manipulation" title="Permalink to this headline">#</a></h2>
<section id="computation">
<h3>1.1. Computation<a class="headerlink" href="#computation" title="Permalink to this headline">#</a></h3>
<section id="tensor">
<h4>Tensor<a class="headerlink" href="#tensor" title="Permalink to this headline">#</a></h4>
<p>In PyTorch, we work most of the time with <a class="reference external" href="https://pytorch.org/docs/stable/tensors.html"><code class="docutils literal notranslate"><span class="pre">Tensor</span></code></a> whose operations are very much like NumPyâ€™s array. Being very natural to PyTorch, tensor operations are provided directly in the <a class="reference external" href="https://pytorch.org/docs/stable/torch.html">mother package</a>. One thing to notice is that PyTorch requires tensors to be of the same data type so mathematical computation can be performed on them. When error occurs, we should check all input data and make sure they are <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>, as this is the default data type in PyTorch.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
    <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">]</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.4156, 0.0905, 0.5030],
        [0.9803, 0.4548, 0.9625]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="autograd">
<h4>Autograd<a class="headerlink" href="#autograd" title="Permalink to this headline">#</a></h4>
<p>PyTorch provides automatic differentiation via the sub-module <a class="reference external" href="https://pytorch.org/docs/stable/autograd.html"><code class="docutils literal notranslate"><span class="pre">autograd</span></code></a>, with functions implemented as <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> methods. Being a mathematical module, it distinguishes two types of tensor, <em>constant</em> and <em>variable</em>, indicated via the flag <code class="docutils literal notranslate"><span class="pre">requires_grad</span></code>. All tensors are constants by default, and become variables when this flag is enabled. Autograd is designed to work on a computational graph, where:</p>
<ul class="simple">
<li><p>The <em>foward</em> pass requires inputs to be tensors and output to be a scalar. This pass is done using normal tensor operations.</p></li>
<li><p>During <em>backward</em> pass (by calling the <code class="docutils literal notranslate"><span class="pre">backward()</span></code> method on the output), PyTorch will compute and accumulate partial derivatives for leaf nodes. This information can be accessed via the <code class="docutils literal notranslate"><span class="pre">grad</span></code> attribute of input variables.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">x1</span> <span class="o">-</span> <span class="mf">0.3</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">x2</span> <span class="o">-</span> <span class="mf">0.7</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>

<span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">x1</span><span class="o">.</span><span class="n">grad</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([ 0.0713,  0.3037,  0.2373,  0.1683,  0.0828, -0.0628,  0.2589,  0.1536])
</pre></div>
</div>
</div>
</div>
</section>
<section id="optimization">
<h4>Optimization<a class="headerlink" href="#optimization" title="Permalink to this headline">#</a></h4>
<p>The sub-module <a class="reference external" href="https://pytorch.org/docs/stable/optim.html"><code class="docutils literal notranslate"><span class="pre">optim</span></code></a>
implements various optimization algorithms from the basic SGD to the standard Adam. We are going to demonstrate <code class="docutils literal notranslate"><span class="pre">autograd</span></code> and <code class="docutils literal notranslate"><span class="pre">optim</span></code> combining together using a simple problem, finding <span class="math notranslate nohighlight">\(\min\bar{\mathbf{y}}\)</span> where <span class="math notranslate nohighlight">\(\mathbf{y}=(\mathbf{x}_1-0.3)^2+(\mathbf{x}_2-0.7)^2\)</span>. Recall that all gradient descent algorithms share three components:</p>
<ul class="simple">
<li><p>(1) configurations such as learning rate <span class="math notranslate nohighlight">\(\eta\)</span>, momentum <span class="math notranslate nohighlight">\(\gamma\)</span> and weight decay <span class="math notranslate nohighlight">\(\rho\)</span></p></li>
<li><p>(2) the variable <span class="math notranslate nohighlight">\(x_t\)</span> and its gradient <span class="math notranslate nohighlight">\(g_t\)</span> at each iteration <span class="math notranslate nohighlight">\(t\)</span></p></li>
<li><p>(3) intermediate variables such as exponential moving averages <span class="math notranslate nohighlight">\(m\)</span> and <span class="math notranslate nohighlight">\(v\)</span></p></li>
</ul>
<p>PyTorch implements its optimization algorithms in a low-level interface. During initialization, we set component (1) and register component (2) to our optimizer. Then, when we call the
<code class="docutils literal notranslate"><span class="pre">step()</span></code>
method, PyTorch will compute everything needed in component (3) and perform update in-place to <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>The registration step surprisingly makes sense, as we realize that gradient descent actually only cares about <span class="math notranslate nohighlight">\(x\)</span> and never touches <span class="math notranslate nohighlight">\(y\)</span>. The optimization process is very clearly here: Autograd handles computational graphs to updates <span class="math notranslate nohighlight">\(g_t\)</span>, then Optim uses <span class="math notranslate nohighlight">\(g_t\)</span> to perform a gradient descent step and passes the updated <span class="math notranslate nohighlight">\(x_t\)</span> back to Autograd. We can see how smartly PyTorch is designed, each sub-module is account for a specific task, they alternately do their jobs and pass the output to the other. Learning optimization in PyTorch makes understanding about gradient descent much deeper.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">x1</span> <span class="o">-</span> <span class="mf">0.3</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">x2</span> <span class="o">-</span> <span class="mf">0.7</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nIter</span> <span class="o">=</span> <span class="mi">5</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nIter</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
    <span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s1">&#39;min func = </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.6f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s1">&#39;var1 = </span><span class="si">{</span><span class="n">x1</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, grad1 = </span><span class="si">{</span><span class="n">x1</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s1">&#39;var1 = </span><span class="si">{</span><span class="n">x2</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, grad1 = </span><span class="si">{</span><span class="n">x2</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>min func = 0.000255
var1 = 0.3040, grad1 = 0.0198
var1 = 0.6950, grad1 = -0.0251
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="data-loader">
<h3>1.2. Data loader<a class="headerlink" href="#data-loader" title="Permalink to this headline">#</a></h3>
<p>The sub-module <a class="reference external" href="https://pytorch.org/docs/stable/data.html"><code class="docutils literal notranslate"><span class="pre">utils.data</span></code></a> provides abstract interface helping Data Scientists to work with different types of data. First, we create a dataset class by inherting <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset"><code class="docutils literal notranslate"><span class="pre">Dataset</span></code></a> and overriding two methods <code class="docutils literal notranslate"><span class="pre">__len__()</span></code> and <code class="docutils literal notranslate"><span class="pre">__getitem__()</span></code>. Then we pass this dataset to <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"><code class="docutils literal notranslate"><span class="pre">DataLoader</span></code></a> to enable batch behaviour.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TabularData</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">labelName</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">samples</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">labelName</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">samples</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">samples</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">labelName</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">samples</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">sample</span><span class="p">,</span> <span class="n">label</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/boston.csv&#39;</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">TabularData</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;price&#39;</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">params</span> <span class="o">=</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">listLoss</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">nEpoch</span> <span class="o">=</span> <span class="mi">20</span>
<span class="k">for</span> <span class="n">epochNum</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nEpoch</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">batchNum</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">yHat</span> <span class="o">=</span> <span class="n">x</span><span class="nd">@w</span> <span class="o">+</span> <span class="n">b</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">yHat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">listLoss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">listLoss</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/pytorch-deep-learning_22_0.png"><img alt="../_images/pytorch-deep-learning_22_0.png" class="align-center" src="../_images/pytorch-deep-learning_22_0.png" style="width: 483.5px; height: 248.0px;" /></a>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LinearRegression</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nFeatures</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">nFeatures</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">yHat</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
        <span class="k">return</span> <span class="n">yHat</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">nFeatures</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="gradient-zeroing">
<h4>Gradient zeroing<a class="headerlink" href="#gradient-zeroing" title="Permalink to this headline">#</a></h4>
<p>We might notice that at some points in the training loop, the method
<code class="docutils literal notranslate"><span class="pre">zero_grad()</span></code>
is called on the optimizer. This is because PyTorch accumulates gradient to the
<code class="docutils literal notranslate"><span class="pre">grad</span></code>
attribute and will not reset until we explicitly zero it. By looking at the below example, we can easily point out the difference in behaviours with and without gradient zeroing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x1</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x2</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;grad1=</span><span class="si">{</span><span class="n">x1</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s1"> grad2=</span><span class="si">{</span><span class="n">x2</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>grad1=3.0 grad2=4.0
grad1=6.0 grad2=8.0
grad1=9.0 grad2=12.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">])</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x1</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x2</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;grad1=</span><span class="si">{</span><span class="n">x1</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s1"> grad2=</span><span class="si">{</span><span class="n">x2</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>grad1=3.0 grad2=4.0
grad1=3.0 grad2=4.0
grad1=3.0 grad2=4.0
</pre></div>
</div>
</div>
</div>
</section>
<section id="gradient-accumulation">
<h4>Gradient accumulation<a class="headerlink" href="#gradient-accumulation" title="Permalink to this headline">#</a></h4>
<p>At this point, you may wonder why does PyTorch behave like this? Why not just overwrite the attribute by writing
<code class="docutils literal notranslate"><span class="pre">x.grad</span> <span class="pre">=</span> <span class="pre">grad</span></code> but make things more complicated by
<code class="docutils literal notranslate"><span class="pre">x.grad</span> <span class="pre">+=</span> <span class="pre">grad</span></code>? The underlying reason is that SGD is trained on mini-batches rather than full-batches. This is a way to compromise memory limitation, where larger batch sizes are usually better. But in many scenarios, especially in Computer Vision, we can only read small batches, but that will produce poor accuracy. This problem can be resolved by <em>gradient accumulation</em>.</p>
<p>To perform it, we set an <em>accumulation step</em> indicating parameters update frequency. This means, gradients are still computed per batch, but we only make changes to model parameters after a number of rounds. Because gradients are accumulated, we are visiting batches but only gathering key information they provide. Until we collect enough gradients to be actually statistical significant, stop accumulating and reset it. Imagine we are processing high resolution images that only 16 of them can be read at once. By setting accumulation step to 4, we achieve almost the same result as working with batch size of 64.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TabularData</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">labelName</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">samples</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">labelName</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">samples</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">samples</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">labelName</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">samples</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">sample</span><span class="p">,</span> <span class="n">label</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/boston.csv&#39;</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">TabularData</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;price&#39;</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">params</span> <span class="o">=</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">listLoss</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">nEpoch</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">nStepAccum</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">batchCounter</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">epochNum</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nEpoch</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">batchNum</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1"># foward pass</span>
        <span class="n">yHat</span> <span class="o">=</span> <span class="n">x</span><span class="nd">@w</span> <span class="o">+</span> <span class="n">b</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">yHat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        
        <span class="c1"># backward pass, accumulate gradient</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">batchCounter</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="k">if</span> <span class="n">batchCounter</span> <span class="o">==</span> <span class="n">nStepAccum</span><span class="p">:</span>
            <span class="c1"># update model parameters</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">listLoss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            
            <span class="c1"># reset gradient and counter</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">batchCounter</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">listLoss</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/pytorch-deep-learning_31_0.png"><img alt="../_images/pytorch-deep-learning_31_0.png" class="align-center" src="../_images/pytorch-deep-learning_31_0.png" style="width: 483.5px; height: 248.0px;" /></a>
</div>
</div>
</section>
</section>
<section id="w-language-processing">
<h3>(w) Language processing<a class="headerlink" href="#w-language-processing" title="Permalink to this headline">#</a></h3>
<p><a class="reference external" href="https://pytorch.org/text/stable/index.html"><code class="docutils literal notranslate"><span class="pre">torchtext</span></code></a></p>
</section>
<section id="w-image-processing">
<h3>(w) Image processing<a class="headerlink" href="#w-image-processing" title="Permalink to this headline">#</a></h3>
<p><a class="reference external" href="https://pytorch.org/vision/stable/index.html"><code class="docutils literal notranslate"><span class="pre">torchvision</span></code></a></p>
</section>
</section>
<section id="neural-networks">
<h2>2. Neural networks<a class="headerlink" href="#neural-networks" title="Permalink to this headline">#</a></h2>
<section id="modular-design">
<h3>2.1. Modular design<a class="headerlink" href="#modular-design" title="Permalink to this headline">#</a></h3>
<p>PyTorch has two APIs for creating models, where the recommended one is <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html"><code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></a>, being equivalent to functional API in Keras. To create a model, we inherit this class, define building blocks inside the <code class="docutils literal notranslate"><span class="pre">__init__()</span></code> method and design the neural network architecture with the <code class="docutils literal notranslate"><span class="pre">foward()</span></code> method. We donâ€™t need to to specify the backward pass, as the submodule <code class="docutils literal notranslate"><span class="pre">autograd</span></code> will handle it for us. The second API, <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html"><code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code></a>, is good for simple architectures as well as small blocks in large networks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LinearRegression</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nFeature</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">nFeature</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">nFeature</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="layers">
<h4>Layers<a class="headerlink" href="#layers" title="Permalink to this headline">#</a></h4>
<p>A neural network is a collection of layers, and each layer is a function. These functions can be simple (such as fully connected layer) or complicated (such as recurrent layers), but this fact does not change the nature of a layer. We can construct a layer completely by hand, as seen in the linear regression example above. With the help of the class <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html"><code class="docutils literal notranslate"><span class="pre">nn.Parameter</span></code></a>, we turn tensors into trainable parameters that are visible to model classes. This is used only on rare occasions, and most of the time we would want to use built-in layers of PyTorch.</p>
<p>PyTorch has two APIs for accessing its layers, <a class="reference external" href="https://pytorch.org/docs/stable/nn.html"><code class="docutils literal notranslate"><span class="pre">nn</span></code></a> (abbreviated for <em>neural network</em>) and <a class="reference external" href="https://pytorch.org/docs/stable/nn.functional.html"><code class="docutils literal notranslate"><span class="pre">nn.functional</span></code></a>. The first module provides object interface (that supports auto differentiation) and the second module provides function interface (easier to use). So, the best practice is using object interface for layers with trainable parameters such as recurrent or convolutional, and using function interface for loss functions or activation functions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LinearRegression</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nFeature</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nFeature</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">foward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="resources">
<h2>Resources<a class="headerlink" href="#resources" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><em>pytorch - <a class="reference external" href="https://pytorch.org/docs/stable/notes/autograd.html">Autograd mechanics</a></em></p></li>
<li><p><em>pytorch - <a class="reference external" href="https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html">Automatic differentiation with Torchâ€™s Autograd</a></em></p></li>
<li><p><em>pytorch - <a class="reference external" href="https://pytorch.org/tutorials/beginner/nn_tutorial.html">What is Torchâ€™s NN really?</a></em></p></li>
<li><p><em>medium - <a class="reference external" href="https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e">Understanding PyTorch with an example: a step-by-step tutorial</a></em></p></li>
<li><p><em>medium - <a class="reference external" href="https://towardsdatascience.com/pytorch-vs-tensorflow-spotting-the-difference-25c75777377b">PyTorch vs TensorFlow - spotting the difference</a></em></p></li>
<li><p><em>blog.paperspace - <a class="reference external" href="https://blog.paperspace.com/pytorch-101-advanced/">PyTorch 101 advanced</a></em></p></li>
<li><p><em>poloclub.github - <a class="reference external" href="https://poloclub.github.io/cnn-explainer/">CNN explainer</a></em></p></li>
<li><p><em>cs230.stanford - <a class="reference external" href="https://cs230.stanford.edu/blog/pytorch/">Introduction to Pytorch Code Examples</a></em></p></li>
</ul>
</section>
<section id="install">
<h2>Install<a class="headerlink" href="#install" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="n">pytorch</span> <span class="n">torchvision</span> <span class="n">torchaudio</span> <span class="n">cpuonly</span> <span class="o">-</span><span class="n">c</span> <span class="n">pytorch</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip3 install torch torchvision torchaudio --user
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "hungpq7/tabular-book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./10-deep-learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="keras-convolutional-networks.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Keras: Convolutional Networks</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="transformers-transfer-learning.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Transformers: Transfer Learning</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Quang Hung &#9829; Thuy Linh<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>