
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Sklearn: Machine Learning</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Sklearn: Classification" href="sklearn-classification.html" />
    <link rel="prev" title="6. Machine Learning" href="_intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.svg" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01-python-programing/_intro.html">
   <b>
    1. Python Programing
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-basic-concepts.html">
     Python: Basic Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-data-types.html">
     Python: Data Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-data-containers.html">
     Python: Data Containers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-functions-objects.html">
     Python: Functions and Objects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-algorithms.html">
     (w) Python: Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-external-sources.html">
     Python: External Sources
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/selenium-web-scraping.html">
     Selenium: Web Scraping
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02-mathematics/_intro.html">
   <b>
    2. Mathematics
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/numpy-linear-algebra.html">
     NumPy: Linear Algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/sympy-calculus.html">
     SymPy: Calculus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/numpy-probability.html">
     NumPy: Probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/numpy-statistics.html">
     NumPy: Statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/scipy-hypothesis-testing.html">
     SciPy: Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/numpy-applied-mathematics.html">
     (w) NumPy: Applied Mathematics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/networkx-network-analysis.html">
     (w) NetworkX: Network Analysis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03-data-manipulation/_intro.html">
   <b>
    3. Data Manipulation
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/numpy-arrays.html">
     NumPy: Arrays
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/pandas-data-exploratory.html">
     Pandas: Data Exploratory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/pandas-data-cleaning.html">
     Pandas: Data Cleaning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/pandas-data-transformation.html">
     Pandas: Data Transformation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/janitor-pandas-extensions.html">
     Janitor: Pandas Extensions
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04-big-data/_intro.html">
   <b>
    4. Big Data
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/hiveql-data-manipulation.html">
     HiveQL: Data Manipulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/pyspark-data-exploratory.html">
     PySpark: Data Exploratory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/pyspark-data-cleaning.html">
     PySpark: Data Cleaning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/pyspark-data-transformation.html">
     PySpark: Data Transformation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/dask-parallelized-pandas.html">
     Dask: Parallelized Pandas
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../05-data-visualization/_intro.html">
   <b>
    5. Data Visualization
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-data-visualization/matplotlib-graph-construction.html">
     Matplotlib: Graph Construction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-data-visualization/seaborn-statistical-visualization.html">
     Seaborn: Statistical Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-data-visualization/plotly-interactive-visualization.html">
     Plotly: Interactive Visualization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="_intro.html">
   <b>
    6. Machine Learning
   </b>
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Sklearn: Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sklearn-classification.html">
     Sklearn: Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sklearn-regression.html">
     Sklearn: Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sklearn-feature-engineering.html">
     Featuretools: Feature Engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="lenskit-recommendation.html">
     Lenskit: Recommendation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pyspark-machine-learning.html">
     PySpark: Machine Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../07-tabular-learning/_intro.html">
   <b>
    7. Tabular Learning
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-tabular-learning/sklearn-ensemble-learning.html">
     Sklearn: Ensemble Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-tabular-learning/xgboost-tree-boosting.html">
     XGBoost: Tree Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-tabular-learning/ray-hyperparameter-optimization.html">
     Ray: Hyperparam Optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-tabular-learning/shap-model-interpretation.html">
     Shap: Model Interpretation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-tabular-learning/imblearn-targeted-modeling.html">
     Imblearn: Targeted Modeling
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../08-time-series/_intro.html">
   <b>
    8. Time Series
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-time-series/statsmodels-temporal-analysis.html">
     Statsmodels: Temporal Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-time-series/prophet-forecasting-algorithms.html">
     Prophet: Forecasting Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-time-series/sktime-forecasting-pipeline.html">
     Sktime: Forecasting Pipeline
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-time-series/darts-deep-forecasting.html">
     (w) Darts: Deep Forecasting
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../09-unsupervised-learning/_intro.html">
   <b>
    9. Unsupervised Learning
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-unsupervised-learning/mlxtend-association-rules.html">
     (w) MLxtend: Association Rules
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-unsupervised-learning/sklearn-clustering.html">
     Sklearn: Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-unsupervised-learning/sklearn-dimensional-reduction.html">
     Sklearn: Dimensional Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-unsupervised-learning/pyod-anomaly-detection.html">
     PyOD: Anomaly Detection
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../10-deep-learning/_intro.html">
   <b>
    10. Deep Learning
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/gensim-text-mining.html">
     Gensim: Text Mining
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/opencv-image-processing.html">
     (w) OpenCV: Image Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/numpy-gradient-descent.html">
     Python: Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/keras-multilayer-perceptron.html">
     Keras: Multilayer Perceptron
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/keras-recurrent-networks.html">
     Keras: Recurrent Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/keras-convolutional-networks.html">
     (w) Keras: Convolutional Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/pytorch-deep-learning.html">
     PyTorch: Deep Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/transformers-transfer-learning.html">
     (w) Transformers: Transfer Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../11-r-programing/_intro.html">
   <b>
    11. R Programing
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/r-basic-concepts.html">
     R: Basic Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/r-data-structures.html">
     R: Data Structures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/tidyverse-data-wrangling.html">
     Tidyverse: Data Wrangling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/dplyr-data-cleaning.html">
     Dplyr: Data Cleaning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/ggplot-data-visualization.html">
     Ggplot: Data Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/r-statistics.html">
     R: Statistics
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/hungpq7/tabular-book/master?urlpath=lab/tree/06-machine-learning/sklearn-machine-learning.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/hungpq7/tabular-book/blob/master/06-machine-learning/sklearn-machine-learning.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/hungpq7/tabular-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#terminology">
   1. Terminology
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     1.1. Training
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#algorithm-and-model">
       Algorithm and model
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#model">
       Model
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#loss-function">
       Loss function
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#optimization">
       Optimization
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#validating">
     1.2. Validating
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#hyperparameters">
       Hyperparameters
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#metrics">
       Metrics
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#validation">
       Validation
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cross-validation">
       Cross validation
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#testing">
     1.3. Testing
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#goodness-of-fit">
       Goodness of fit
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#data-leakage">
       Data leakage
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluation">
   2. Evaluation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-visualization">
     2.1. Classification visualization
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#confusion-matrix">
       Confusion matrix
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#precision-recall-chart">
       Precision-Recall Chart
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#roc-curve">
       ROC Curve
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cumulative-gains">
       Cumulative Gains
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#lift-curve">
       Lift Curve
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-metrics">
     2.2. Classification metrics
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#accuracy">
       Accuracy
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#precision">
       Precision
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#recall">
       Recall
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#f-score">
       F-score
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#auroc">
       AUROC
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#multi-class-metrics">
       Multi-class metrics
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#customized-metrics">
       Customized metrics
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regression-metrics">
     2.3. Regression metrics
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coefficient-of-determination">
       Coefficient of Determination
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mean-absolute-error">
       Mean Absolute Error
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mean-squared-error">
       Mean Squared Error
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Sklearn: Machine Learning</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#terminology">
   1. Terminology
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     1.1. Training
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#algorithm-and-model">
       Algorithm and model
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#model">
       Model
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#loss-function">
       Loss function
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#optimization">
       Optimization
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#validating">
     1.2. Validating
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#hyperparameters">
       Hyperparameters
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#metrics">
       Metrics
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#validation">
       Validation
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cross-validation">
       Cross validation
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#testing">
     1.3. Testing
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#goodness-of-fit">
       Goodness of fit
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#data-leakage">
       Data leakage
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluation">
   2. Evaluation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-visualization">
     2.1. Classification visualization
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#confusion-matrix">
       Confusion matrix
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#precision-recall-chart">
       Precision-Recall Chart
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#roc-curve">
       ROC Curve
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cumulative-gains">
       Cumulative Gains
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#lift-curve">
       Lift Curve
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-metrics">
     2.2. Classification metrics
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#accuracy">
       Accuracy
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#precision">
       Precision
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#recall">
       Recall
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#f-score">
       F-score
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#auroc">
       AUROC
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#multi-class-metrics">
       Multi-class metrics
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#customized-metrics">
       Customized metrics
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regression-metrics">
     2.3. Regression metrics
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coefficient-of-determination">
       Coefficient of Determination
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mean-absolute-error">
       Mean Absolute Error
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mean-squared-error">
       Mean Squared Error
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="sklearn-machine-learning">
<h1>Sklearn: Machine Learning<a class="headerlink" href="#sklearn-machine-learning" title="Permalink to this headline">#</a></h1>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Machine_learning">Machine Learning</a> is the study of computer algorithms that improve automatically through experience. Machine Learning algorithms build a <a class="reference external" href="https://en.wikipedia.org/wiki/Mathematical_model">mathematical model</a> based on sample data in order to make predictions or decisions. In Data Analytics, Machine Learning is referred to as <em>predictive analysis</em> (supervised learning) and <em>data mining</em> (unsupervised learning). There are many libraries in Python designed for Machine Learning, but we’ll start with the most basic one: <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html">Scikit-learn</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">fbeta_score</span><span class="p">,</span> <span class="n">make_scorer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">r2_score</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;seaborn&#39;</span><span class="p">,</span> <span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">])</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Supervised Machine Learning refers to algorithms that learn a general <em>rule</em> from labeled data, then use that <em>rule</em> to predict labels for new, unlabeled data. The <em>rule</em> in this context can be understood as a function mapping input (features) to output (label). Supervised learning is all about predicting labels, containing:</p>
<ul class="simple">
<li><p>Classification</p></li>
<li><p>Regression</p></li>
<li><p>Forecasting</p></li>
<li><p>Recommendation</p></li>
</ul>
<p>Unsupervised Machine Learning does not require known labels, it finds hidden data patterns on their own. However, unsupervised learning is less popular and harder to evaluate the performance, compared to supervised learning. Here are some important applications of unsupervised learning:</p>
<ul class="simple">
<li><p>Clustering</p></li>
<li><p>Dimensionality reduction</p></li>
<li><p>Anomaly detection</p></li>
</ul>
</div>
<section id="terminology">
<h2>1. Terminology<a class="headerlink" href="#terminology" title="Permalink to this headline">#</a></h2>
<p>This section focuses on concepts that occur in supervised Machine Learning.</p>
<section id="training">
<h3>1.1. Training<a class="headerlink" href="#training" title="Permalink to this headline">#</a></h3>
<p>Training is the process of generating a particular model from an algorithm.</p>
<section id="algorithm-and-model">
<h4>Algorithm and model<a class="headerlink" href="#algorithm-and-model" title="Permalink to this headline">#</a></h4>
<p>A supervised Machine Learning <em>algorithm</em> is an instruction to the computer to <em>learn</em> a <em>model</em>. A <em>model</em> can be summarized into a map <span class="math notranslate nohighlight">\(f\)</span> that maps input variables <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> into the output variable <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>:</p>
<div class="math notranslate nohighlight">
\[f:\mathbf{X}\mapsto\mathbf{y}\]</div>
<p>In practice, two terms <em>algorithm</em> and <em>model</em> can be used interchangeably. A Machine Learning model <span class="math notranslate nohighlight">\(f\)</span> can be either <em>parametric</em> or <em>non-parametric</em>.</p>
<ul class="simple">
<li><p><em>Parametric models</em> assume the relationship between <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> can be described using a mathematical function with a finite number of parameters, the function form remains unchanged when the data size grows. Models of this type are very much like narrow-minded people: the function form is fixed, it makes them look at every problem the same way. Parametric models are fast, but they are unlikely to match the underlying rules in practice.</p></li>
<li><p><em>Non-parametric models</em>, in contrast, can use an infinite number of parameters to model data relationship. Due to the high complexity and flexibility, non-parametric models have more prediction power but are also slower when fitting to the data.</p></li>
</ul>
</section>
<section id="model">
<h4>Model<a class="headerlink" href="#model" title="Permalink to this headline">#</a></h4>
<p>A model is the output of a Machine Learning algorithm has run on the data. For example, the Linear Regression algorithm results in a model being a vector of parameters (also known as weights). Machine Learning uses mathematical techniques to estimate those parameters.</p>
<p>After the parameters have been calculated, the model is saved as a file and can be used on the data it hasn’t seen before to make predictions.</p>
</section>
<section id="loss-function">
<h4>Loss function<a class="headerlink" href="#loss-function" title="Permalink to this headline">#</a></h4>
<p>Loss function is a function that maps a model to its associated cost. In Machine Learning, loss functions usually evaluate the error; for example, the difference between real values and predicted values. Each algorithm tries to minimize its own loss function to estimate the parameters.</p>
</section>
<section id="optimization">
<h4>Optimization<a class="headerlink" href="#optimization" title="Permalink to this headline">#</a></h4>
<p>In multivariate calculus, the gradient of a multivariable function <span class="math notranslate nohighlight">\(f(x,y,z,\dots)\)</span>, denoted <span class="math notranslate nohighlight">\(\nabla{f}\)</span> is a vector that stores all partial derivatives.</p>
<div class="math notranslate nohighlight">
\[\nabla{f} =
\begin{bmatrix}
\frac{\partial{f}}{\partial{x}} &amp;
\frac{\partial{f}}{\partial{y}} &amp;
\frac{\partial{f}}{\partial{z}} &amp;
\cdots &amp;
\end{bmatrix}^T\]</div>
<p>At every local minimum or local maximum of the function <span class="math notranslate nohighlight">\(f(x,y,z,\dots)\)</span>, the gradient <span class="math notranslate nohighlight">\(\nabla{f}\)</span> is <span class="math notranslate nohighlight">\(\mathbf{0}\)</span>. By solving the linear system, we can find extreme points can be found and then compare them to find the minimum and maximum. The steps above show how to use gradient to find the minimum of a loss function and the associated values of parameters. However, for very large linear systems, solving them directly seems impossible.</p>
<p>Therefore, an iterative method called gradient descent is commonly used as the optimization algorithm in Machine Learning. The algorithm begins at a point (initial value), moves in the opposite direction of the gradient and stops when <span class="math notranslate nohighlight">\(\|\nabla{f}\|_2 \approx 0\)</span>.</p>
<p>Gradient descent has a parameter, <span class="math notranslate nohighlight">\(\eta\)</span> - the learning rate, represents how fast the algorithm goes down. A high learning rate means fewer iterations to perform, but we risk bypassing the lowest point. A low learning rate makes sure we can always reach the bottom, but it can take a very long time.</p>
</section>
</section>
<section id="validating">
<h3>1.2. Validating<a class="headerlink" href="#validating" title="Permalink to this headline">#</a></h3>
<p>Validating is the process of finding optimal hyperparameters. Also called hyperparameters tuning.</p>
<section id="hyperparameters">
<h4>Hyperparameters<a class="headerlink" href="#hyperparameters" title="Permalink to this headline">#</a></h4>
<p>A hyperparameter is a configuration that is external to the model. Hyperparameters cannot be estimated since they need to be set before fitting the algorithm. They are optimized using rules of thumb or trial and error.</p>
</section>
<section id="metrics">
<h4>Metrics<a class="headerlink" href="#metrics" title="Permalink to this headline">#</a></h4>
<p>Metrics are the formulas that evaluate the performance of Machine Learning models. The metrics are selected depend on the type of algorithm, which can be either regression, classification or clustering. Also notice that multiple metrics can be used on a single model; and the loss function can also be used as a metric.</p>
</section>
<section id="validation">
<h4>Validation<a class="headerlink" href="#validation" title="Permalink to this headline">#</a></h4>
<p>The final purpose of a Machine Learning model is to work well on completely new data. To achieve this, we perform validation:</p>
<ul class="simple">
<li><p>Step 1: Randomly split the data into 3 sets: training set, validation set and test set. The ratio is usually 70:15:15 or 80:10:10.</p></li>
<li><p>Step 2: Fit the algorithm on the training data. Then use the output model to predict label for the validation set and evaluate the performance.</p></li>
<li><p>Step 3: Repeat step 2 with different values of hyperparameters to find the model with the best performance.</p></li>
<li><p>Step 4: Apply the model to the test data and calculate metrics.</p></li>
</ul>
</section>
<section id="cross-validation">
<h4>Cross validation<a class="headerlink" href="#cross-validation" title="Permalink to this headline">#</a></h4>
<p>Considering validation, when the data is not large enough, the training set and the test set may not distribute the same way, which leads to bias. A technique called cross validation my be used to handle the situation.</p>
<ul class="simple">
<li><p>Step 1: Randomly divide the entire dataset into <span class="math notranslate nohighlight">\(k\)</span> equal folds (<span class="math notranslate nohighlight">\(k\)</span> is usually from 5 to 10).</p></li>
<li><p>Step 2: Run a loop through each of the <span class="math notranslate nohighlight">\(k\)</span> folds. In each iteration:</p>
<ul>
<li><p>Take the selected fold as the test set and take the <span class="math notranslate nohighlight">\(k-1\)</span> remaining folds to form the training set</p></li>
<li><p>Fit the algorithm on the training set and evaluate it on the test set</p></li>
<li><p>Retain the metric and discard the model</p></li>
</ul>
</li>
<li><p>Step 3: Fit the algorithm on the entire data to get the final model. Then calculate the average of the recorded scores as the overall performance metric for the model. The standard deviation of the scores should not be too high.</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/cross_validation.png"><img alt="../_images/cross_validation.png" class="align-center" src="../_images/cross_validation.png" style="height: 300px;" /></a>
</section>
</section>
<section id="testing">
<h3>1.3. Testing<a class="headerlink" href="#testing" title="Permalink to this headline">#</a></h3>
<section id="goodness-of-fit">
<h4>Goodness of fit<a class="headerlink" href="#goodness-of-fit" title="Permalink to this headline">#</a></h4>
<p>Generalization is the ability of a model to give sensible output when given the data is has never seen before. A model generalizes well if it is neither <em>underfitting</em> nor <em>overfitting</em>.</p>
<a class="reference internal image-reference" href="../_images/goodness_of_fit.png"><img alt="../_images/goodness_of_fit.png" class="align-center" src="../_images/goodness_of_fit.png" style="height: 250px;" /></a>
<br>
<p><em>Overfitting</em> refers to the situation that the performance of a model is very good on the training set but drops significantly over the test set. This can be explained that the model has learned the noises and random fluctuations from the training data, which do not occur on new data. <em>Early stopping</em> and <em>regularization</em> are two popular techniques to reduce overfitting.</p>
<p><em>Underfitting</em> can be recognized when the model performs poorly on both the test and the training set. The reason behind this is the model is not complex enough to capture patterns from the training data, so obviously there is no way it can work well on new data. The only thing that can be done to prevent underfitting is increasing the complexity of the model.</p>
</section>
<section id="data-leakage">
<h4>Data leakage<a class="headerlink" href="#data-leakage" title="Permalink to this headline">#</a></h4>
<p>Data leakage refers to the situation when information from the outside training dataset is used to create the model. This causes the result of the model unreliable, and when such a model is used on truly unseen data, performance will be much lower than expected. There are some common causes of data leakage:</p>
<ul class="simple">
<li><p><em>Preprocessing</em>: Make sure these transformations only have knowledge of the training set, even though they are applied to the test set as well. When using pre-processor, you must <em>fit</em> it to the training set instead of the entire dataset, and only use <em>transform</em> method on the testing data.</p></li>
<li><p><em>Duplicates</em>: The training and testing set can contain the same data point if the dataset has duplicate values, data cleaning must be used before applying the model. In some cases, duplicate values must be kept, be careful when splitting train-test.</p></li>
<li><p><em>Temporal data</em> (implicit data): Even when you are not explicitly leaking information, you may still experience data leakage if there are dependencies between the test and train set. This usually happens with time series data, for example, the training set contains <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_3\)</span> while the test set contains <span class="math notranslate nohighlight">\(x_2\)</span>. In this case, the model was trained on future knowledge, so its result will be unrealistic. In order to fix this problem, make sure that the test-train split is also split across time.</p></li>
</ul>
<p>According to the causes of data leakage, there are some methods to prevent it.</p>
<ul class="simple">
<li><p>Using cross-validation, create validation set separately.</p></li>
<li><p>Apply preprocessors to train and test sets separately</p></li>
<li><p>Doing EDA carefully, such as dropping the features which have high correlation with the target and removing duplicated values.</p></li>
<li><p>Choose the cutting point with time-series data to prevent unrealistic prediction</p></li>
</ul>
</section>
</section>
</section>
<section id="evaluation">
<h2>2. Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this headline">#</a></h2>
<p>This section discusses evaluation metrics for supervised tasks, specifically classification and regression, and <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics">their implementations</a> in Scikit-learn.</p>
<section id="classification-visualization">
<h3>2.1. Classification visualization<a class="headerlink" href="#classification-visualization" title="Permalink to this headline">#</a></h3>
<p>This section visualizes the performance of binary classification problems.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/credit_scoring.csv&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;bad_customer&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">bad_customer</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">algo</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">algo</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">yTrue</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">yProb</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">yPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yTrue</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(150000,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yProb</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(150000,)
</pre></div>
</div>
</div>
</div>
<section id="confusion-matrix">
<h4>Confusion matrix<a class="headerlink" href="#confusion-matrix" title="Permalink to this headline">#</a></h4>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Confusion_matrix">Confusion matrix</a> is a visualization for the performance of classification algorithms. Each column represents the number of observations in an actual class and each row represents the number of observations in a predicted class.</p>
<a class="reference internal image-reference" href="../_images/confusion_matrix_binary.png"><img alt="../_images/confusion_matrix_binary.png" class="align-center" src="../_images/confusion_matrix_binary.png" style="height: 250px;" /></a>
<br>
<p>However, in real-world problems, sometimes a class is more important than the others. From the perspective of that class (orange, for example), an observation may have the following statuses:</p>
<ul class="simple">
<li><p>Positive if the predicted class is orange, Negative if the predicted class is not orange</p></li>
<li><p>True if the predicted class is correct, False if the predicted class is incorrect</p></li>
</ul>
<p>The combination of the statuses above are: TP (True Positive), TN (True Negative), FP (False Positive) and FN (False Negative), which are used to calculate metrics for classification algorithms. These terms are arranged in a single table:</p>
<a class="reference internal image-reference" href="../_images/confusion_matrix_multiclass.png"><img alt="../_images/confusion_matrix_multiclass.png" class="align-center" src="../_images/confusion_matrix_multiclass.png" style="height: 300px;" /></a>
<br><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yPred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[139452,    522],
       [  5664,   4362]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">((</span><span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">),</span> <span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">tp</span><span class="p">))</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yPred</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="precision-recall-chart">
<h4>Precision-Recall Chart<a class="headerlink" href="#precision-recall-chart" title="Permalink to this headline">#</a></h4>
<p>PR Chart plots the values of Precision and Recall at different thresholds. Looking at this graph allows Data Scientists to understand deeply about the trade-off between Precision and Recall and can select an optimal threshold.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plotPRChart</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yProb</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yProb</span><span class="p">)</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">precision</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="n">recall</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="n">precision</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="n">recall</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Threshold&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Precision&#39;</span><span class="p">,</span> <span class="s1">&#39;Recall&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;scaled&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plotPRChart</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yProb</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/sklearn-machine-learning_28_0.png"><img alt="../_images/sklearn-machine-learning_28_0.png" class="align-center" src="../_images/sklearn-machine-learning_28_0.png" style="width: 357.5px; height: 343.5px;" /></a>
</div>
</div>
</section>
<section id="roc-curve">
<h4>ROC Curve<a class="headerlink" href="#roc-curve" title="Permalink to this headline">#</a></h4>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">Receiver Operating Characteristics</a> (ROC) curve is plotted with TPR (True Positive Rate) against FPR (False Positive Rate) at different decision thresholds. It gives an overview about how well the model distinguishes between the two classes.</p>
<div class="math notranslate nohighlight">
\[\mathrm{TPR}=\mathrm{Recall}=\mathrm{Sensitivity} = 
\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}}\]</div>
<div class="math notranslate nohighlight">
\[\mathrm{FPR}=1-\mathrm{Specificity} = 
\frac{\mathrm{FP}}{\mathrm{TN}+\mathrm{FP}}\]</div>
<p>In real world problems, there is always a trade-off between high Sensitivity and high Specificity. By looking at the ROC curve, there are many insights that can be read from it:</p>
<ul class="simple">
<li><p>Comparing the quality of different models. The more convex the curve is, the more predictive power it has.</p></li>
<li><p>Determining the optimal threshold.</p></li>
<li><p>Calculating the AUROC (Area Under the ROC), which is a single value that summarizes the overall performance of the model.</p></li>
</ul>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plotROC</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yProb</span><span class="p">):</span>
    
    <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yProb</span><span class="p">)</span>
    <span class="n">sensitivity</span> <span class="o">=</span> <span class="n">tpr</span>
    <span class="n">specificity</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">fpr</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">specificity</span><span class="p">,</span> <span class="n">sensitivity</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Specificity&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Sensitivity&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;scaled&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plotROC</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yProb</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/sklearn-machine-learning_30_0.png"><img alt="../_images/sklearn-machine-learning_30_0.png" class="align-center" src="../_images/sklearn-machine-learning_30_0.png" style="width: 348.0px; height: 343.5px;" /></a>
</div>
</div>
</section>
<section id="cumulative-gains">
<h4>Cumulative Gains<a class="headerlink" href="#cumulative-gains" title="Permalink to this headline">#</a></h4>
<p>In many business problems, resources are limited, making only the most potential targets are visited. So it is really important for the model to cover a high ratio of positive instances only by visiting a small part of the dataset, and this is where Cumulative Gains is used.</p>
<p>Cumulative Gains shows the overall positive percentage <em>gained</em> by targeting the top fraction of all observations. A popular method for determining the fractions of observations is <em>deciles</em> (10-quantiles). The diagonal in the chart represents the <em>baseline</em> model, which targets observations at random. A good model should have a high gain value at the very first deciles.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plotCumulativeGains</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yProb</span><span class="p">):</span>
    
    <span class="n">dfProb</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;yTrue&#39;</span><span class="p">:</span> <span class="n">yTrue</span><span class="p">,</span> <span class="s1">&#39;yProb&#39;</span><span class="p">:</span> <span class="n">yProb</span><span class="p">})</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;yProb&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">dfProb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">nPositive</span> <span class="o">=</span> <span class="n">dfProb</span><span class="p">[</span><span class="n">dfProb</span><span class="o">.</span><span class="n">yTrue</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="n">deciles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
    <span class="n">gains</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">decile</span> <span class="ow">in</span> <span class="n">deciles</span><span class="p">:</span>
        <span class="n">nVisit</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">decile</span><span class="p">)</span>
        <span class="n">dfGain</span> <span class="o">=</span> <span class="n">dfProb</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">nVisit</span><span class="p">)</span>
        <span class="n">nGainPositive</span> <span class="o">=</span> <span class="n">dfGain</span><span class="p">[</span><span class="n">dfGain</span><span class="o">.</span><span class="n">yTrue</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">gain</span> <span class="o">=</span> <span class="n">nGainPositive</span> <span class="o">/</span> <span class="n">nPositive</span>
        <span class="n">gains</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gain</span><span class="p">)</span>
    
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">deciles</span><span class="p">,</span> <span class="n">gains</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Baseline&#39;</span><span class="p">,</span> <span class="s1">&#39;Gains&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Deciles&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Gains&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;scaled&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotCumulativeGains</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yProb</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/sklearn-machine-learning_33_0.png"><img alt="../_images/sklearn-machine-learning_33_0.png" class="align-center" src="../_images/sklearn-machine-learning_33_0.png" style="width: 348.0px; height: 343.5px;" /></a>
</div>
</div>
</section>
<section id="lift-curve">
<h4>Lift Curve<a class="headerlink" href="#lift-curve" title="Permalink to this headline">#</a></h4>
<p>Besides Cumulative Gains, Lift Curve is also a powerful tool being widely used in marketing campaigns. It helps analyze the overall positive percentage in each bin, compared to bin size. Notice that bin size represents the expected percent of positive instances if targeted randomly. For example, assume there is a total of 70 positive instances and the bin size is chosen of 10% (<em>deciles</em>), then each bin is expected to contain <span class="math notranslate nohighlight">\(70\cdot 10\%=7\)</span> positive instances.</p>
<p>The Lift Curve for an ideal model should have very high values at first, then drop significantly to the point that lift values are below the <em>baseline</em>. This proves that the vast majority of positive instances are in first bins.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plotLiftCurve</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yProb</span><span class="p">):</span>
    
    <span class="n">bin_size</span> <span class="o">=</span> <span class="mf">0.01</span>
    <span class="n">dfProb</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;yTrue&#39;</span><span class="p">:</span> <span class="n">yTrue</span><span class="p">,</span> <span class="s1">&#39;yProb&#39;</span><span class="p">:</span> <span class="n">yProb</span><span class="p">})</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;yProb&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">dfProb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">nVisit</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">bin_size</span><span class="p">)</span>
    <span class="n">nPositive</span> <span class="o">=</span> <span class="n">dfProb</span><span class="p">[</span><span class="n">dfProb</span><span class="o">.</span><span class="n">yTrue</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="n">deciles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span> <span class="n">bin_size</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">lifts</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">decile</span> <span class="ow">in</span> <span class="n">deciles</span><span class="p">:</span>
        <span class="n">nTop</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">decile</span><span class="p">)</span>
        <span class="n">dfGain</span> <span class="o">=</span> <span class="n">dfProb</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">nTop</span><span class="p">)</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="n">nVisit</span><span class="p">)</span>
        <span class="n">nGainPositive</span> <span class="o">=</span> <span class="n">dfGain</span><span class="p">[</span><span class="n">dfGain</span><span class="o">.</span><span class="n">yTrue</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">lift</span> <span class="o">=</span> <span class="n">nGainPositive</span> <span class="o">/</span> <span class="n">nPositive</span> <span class="o">/</span> <span class="n">bin_size</span>
        <span class="n">lifts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lift</span><span class="p">)</span>
    
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">deciles</span><span class="p">,</span> <span class="n">lifts</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Deciles&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Lift&#39;</span><span class="p">)</span>
<span class="c1">#     ax.axis(&#39;scaled&#39;)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotLiftCurve</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yProb</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/sklearn-machine-learning_36_0.png"><img alt="../_images/sklearn-machine-learning_36_0.png" class="align-center" src="../_images/sklearn-machine-learning_36_0.png" style="width: 492.5px; height: 343.5px;" /></a>
</div>
</div>
</section>
</section>
<section id="classification-metrics">
<h3>2.2. Classification metrics<a class="headerlink" href="#classification-metrics" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/credit_scoring.csv&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;bad_customer&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">bad_customer</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">algo</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">algo</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">yTrue</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">yProb</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">yPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="accuracy">
<h4>Accuracy<a class="headerlink" href="#accuracy" title="Permalink to this headline">#</a></h4>
<p>Accuracy treats all the classes equally, since it calculates the True rate, which is the number of correct predictions over the total of predictions made. Accuracy is the default classification metric used in Scikit-learn.</p>
<div class="math notranslate nohighlight">
\[\mathrm{Accuracy} = \frac{\mathrm{T}}{\mathrm{T}+\mathrm{F}}\]</div>
<p>Accuracy is a good measure when the classes are (nearly) balanced; however, it should never be used when the majority of the data falls into a single class. For example, there are 5 people have cancer out of 100 observations, and a predictive model classifies all 100 people have no cancer. So even it is very terrible at predicting cancer, such a bad model still has an Accuracy of 95%.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yPred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9588466666666666
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># accuracy is also the default metric</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9588466666666666
</pre></div>
</div>
</div>
</div>
</section>
<section id="precision">
<h4>Precision<a class="headerlink" href="#precision" title="Permalink to this headline">#</a></h4>
<p>The Precision of a class shares the same meaning with Accuracy, but it considers only Positive predictions. It is calculated as the proportion of those Positive predictions are actually Positive.</p>
<div class="math notranslate nohighlight">
\[\mathrm{Precision} = \frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FP}}\]</div>
<p>Precision should be used when you want to make classification for one class as good as possible. For example, a video recommendation system classifies Positive for relevant videos and Negative for non-relevant ones. The recommended videos should be relevant to the users, so the system should have a high Precision.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">precision_score</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yPred</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8912202077816256
</pre></div>
</div>
</div>
</div>
</section>
<section id="recall">
<h4>Recall<a class="headerlink" href="#recall" title="Permalink to this headline">#</a></h4>
<p>The per-class Recall, also known as Sensitivity, measures the proportion of actual Positive observations that are correctly classified.</p>
<div class="math notranslate nohighlight">
\[\mathrm{Recall} = \frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}}\]</div>
<p>If you don’t want to mispredict any real Positive case, then you need Recall. For example, a COVID-19 test kit must detect as many infected people (Positive) as possible, so it should have a high Recall.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">recall_score</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yPred</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.43636544983044084
</pre></div>
</div>
</div>
</div>
</section>
<section id="f-score">
<h4>F-score<a class="headerlink" href="#f-score" title="Permalink to this headline">#</a></h4>
<p>Machine Learning is full of trade-offs, oftentimes your classifier does not have good Precision and good Recall at the same time. A single metric that summarizes both is needed, and that’s where F-score is used.</p>
<div class="math notranslate nohighlight">
\[
F_1 = \left(\frac{1}{2}\cdot\mathrm{Precision}^{-1}+\frac{1}{2}\cdot\mathrm{Recall}^{-1}\right)^{-1}
\]</div>
<p>To compute <span class="math notranslate nohighlight">\(F_1\)</span> score, the harmonic mean is used instead of the usual arithmetic mean since this method gives a higher weight to the lower quantity of the two. For example, a classifier has a Precision of 10% and a Recall of 90%, then their harmonic mean is 18% while their arithmetic mean is 50%. So, a high <span class="math notranslate nohighlight">\(F_1\)</span> score ensures that the Precision and Recall are both high.</p>
<p>However, there is a disadvantage of <span class="math notranslate nohighlight">\(F_1\)</span> score is that it treats both Precision and Recall equally. Sometimes it is required to include domain knowledge in the model, specifically more Recall or more Precision. To solve this, we add a weight to Recall, denoted <span class="math notranslate nohighlight">\(\beta\)</span>, to control the trade-off between Precision and Recall. <span class="math notranslate nohighlight">\(\beta\)</span> implies how many times is Recall more important than Precision.</p>
<div class="math notranslate nohighlight">
\[
F_{\beta} = \left(\frac{1}{1+\beta^2}\cdot\mathrm{Precision}^{-1} + \frac{\beta^2}{1+\beta^2}\cdot\mathrm{Recall}^{-1}\right)^{-1}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fbeta_score</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yPred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7374755579529363
</pre></div>
</div>
</div>
</div>
</section>
<section id="auroc">
<h4>AUROC<a class="headerlink" href="#auroc" title="Permalink to this headline">#</a></h4>
<p>AUROC stands for Area Under the ROC curve, the name shows how it is calculated. The value of AUROC is in the range <span class="math notranslate nohighlight">\([0,1]\)</span>, where higher value means better ability in distinguishing the two classes. AUROC is a well-rounded metric and is widely used in real world classification problems.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yProb</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9201729303801544
</pre></div>
</div>
</div>
</div>
</section>
<section id="multi-class-metrics">
<h4>Multi-class metrics<a class="headerlink" href="#multi-class-metrics" title="Permalink to this headline">#</a></h4>
<p>Notice that except for Accuracy, all the above metrics are defined for binary classification. In multi-class problems, they can only measure the performance of a class versus the rest. Here is how the overall metric of the model is calculated, let’s take Precision as an example:</p>
<ul class="simple">
<li><p>Micro Precision, by taking the average TP and FP for each class, then applying the same per-class formula.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathrm{MicroPrecision}=\frac{\sum{\mathrm{TP}_c}}{\sum{\mathrm{TP}_c}+\sum{\mathrm{FP}_c}}\]</div>
<ul class="simple">
<li><p>Macro Precision, by taking the arithmetic mean of Precision of all classes (<span class="math notranslate nohighlight">\(C\)</span> is the number of classes).</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathrm{MacroPrecision}=\frac{1}{C}\sum{\mathrm{Precision}_c}\]</div>
<ul class="simple">
<li><p>Weighted Precision, by taking the weighted sum of Precision of all classes. The weight <span class="math notranslate nohighlight">\(w_c\)</span> is defined as the proportion of each class.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathrm{WeightedPrecision}=\sum{w_c\cdot\mathrm{Precision}_c}\]</div>
<p>The Scikit-learn library provides the <code class="docutils literal notranslate"><span class="pre">classification_report</span></code> function that calculates both per-class metrics and overall metrics.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yPred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.96      1.00      0.98    139974
           1       0.89      0.44      0.59     10026

    accuracy                           0.96    150000
   macro avg       0.93      0.72      0.78    150000
weighted avg       0.96      0.96      0.95    150000
</pre></div>
</div>
</div>
</div>
</section>
<section id="customized-metrics">
<h4>Customized metrics<a class="headerlink" href="#customized-metrics" title="Permalink to this headline">#</a></h4>
<p>The default metric used in Scikit-learn is Accuracy, however you can use another metric, or even a <a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules">customized one</a> using the <code class="docutils literal notranslate"><span class="pre">scoring</span></code> parameter. It takes a string as input, where available options can be found in the reference. For a complex metric, the function requires to define it first.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">params_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]}</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">fbeta_score</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">params_grid</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;precision&#39;</span><span class="p">)</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">params_grid</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">metric</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="regression-metrics">
<h3>2.3. Regression metrics<a class="headerlink" href="#regression-metrics" title="Permalink to this headline">#</a></h3>
<p>Let <span class="math notranslate nohighlight">\(\mathbf{y}=(y_1,y_2,\dots,y_N)\)</span> is the vector of true data labels and <span class="math notranslate nohighlight">\(\hat{\mathbf{y}}=(\hat{y}_1,\hat{y}_2,\dots,\hat{y}_N)\)</span> is the vector of predicted values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/boston.csv&#39;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;price&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">algo</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">algo</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">yTrue</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">yPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="coefficient-of-determination">
<h4>Coefficient of Determination<a class="headerlink" href="#coefficient-of-determination" title="Permalink to this headline">#</a></h4>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Coefficient_of_determination">Coefficient of Determination</a>, denoted <span class="math notranslate nohighlight">\(R^2\)</span> <span class="math notranslate nohighlight">\((R^2 \leq 1)\)</span>, evaluates the scatter of data point around the fitted regression function. It is calculated using <span class="math notranslate nohighlight">\(\text{SSE}\)</span> (sum of squared errors) and <span class="math notranslate nohighlight">\(\text{SST}\)</span> (total sum of squares).</p>
<div class="math notranslate nohighlight">
\[R^2=1-\dfrac{\text{SSE}}{\text{SST}}\]</div>
<p>Look closely at <span class="math notranslate nohighlight">\(\text{SSE}\)</span> and <span class="math notranslate nohighlight">\(\text{SST}\)</span>, if we divide both of them by <span class="math notranslate nohighlight">\(N\)</span>, then the ratio between them is the ratio between (1) the error of our Machine Learning model and (2) the error made by a naive model using mean as prediction.</p>
<div class="math notranslate nohighlight">
\[\text{SSE}=\sum_{n=1}^{N}(y_n-\hat{y}_n)^2;\quad
\text{SST}=\sum_{n=1}^{N}(y_n-\bar{y})^2\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">r2_score</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yPred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7406426641094095
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># r2 is also the default score</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7406426641094095
</pre></div>
</div>
</div>
</div>
</section>
<section id="mean-absolute-error">
<h4>Mean Absolute Error<a class="headerlink" href="#mean-absolute-error" title="Permalink to this headline">#</a></h4>
<p>MAE is simply the average distance between the real and the predicted values. The absolute value is taken to ensure they do not cancel each other out. MAE does not fall into any certain range, it itself cannot tell if the model is good enough, you can only use MAE to compare the performance of different models.</p>
<div class="math notranslate nohighlight">
\[{\mbox{MAE}}={\frac{1}{N}}\sum_{n=1}^{N}|y_n-\hat{y}_n|\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yPred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.2708628109003164
</pre></div>
</div>
</div>
</div>
</section>
<section id="mean-squared-error">
<h4>Mean Squared Error<a class="headerlink" href="#mean-squared-error" title="Permalink to this headline">#</a></h4>
<p>MSE is quite similar to MAE, however MSE gives higher penalization to big error. In real world problems, RMSE (Root Mean Squared Error) is used more commonly since it brings MSE back to the same unit with MAE.</p>
<div class="math notranslate nohighlight">
\[\mbox{MSE} = \mbox{RMSE}^2 = {\frac{1}{N}} \sum_{n=1}^{N}(y_n-\hat{y}_n)^{2}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># mse</span>
<span class="n">mean_squared_error</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yPred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>21.894831181729202
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># rmse</span>
<span class="n">mean_squared_error</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yPred</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4.679191295697281
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "hungpq7/tabular-book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./06-machine-learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="_intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><b>6. Machine Learning</b></p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="sklearn-classification.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Sklearn: Classification</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Quang Hung &#9829; Thuy Linh<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>