
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Sklearn: Classification</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Sklearn: Regression" href="sklearn-regression.html" />
    <link rel="prev" title="Sklearn: Machine Learning" href="sklearn-machine-learning.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.svg" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01-python-programing/_intro.html">
   <b>
    1. Python Programing
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-basic-concepts.html">
     Python: Basic Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-data-types.html">
     Python: Data Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-data-containers.html">
     Python: Data Containers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-functions-objects.html">
     Python: Functions and Objects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-algorithms.html">
     (w) Python: Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-external-sources.html">
     Python: External Sources
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/selenium-web-scraping.html">
     Selenium: Web Scraping
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02-mathematics/_intro.html">
   <b>
    2. Mathematics
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/numpy-linear-algebra.html">
     NumPy: Linear Algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/sympy-calculus.html">
     SymPy: Calculus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/numpy-probability.html">
     NumPy: Probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/numpy-statistics.html">
     NumPy: Statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/scipy-hypothesis-testing.html">
     SciPy: Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/numpy-applied-mathematics.html">
     (w) NumPy: Applied Mathematics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/networkx-network-analysis.html">
     (w) NetworkX: Network Analysis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03-data-manipulation/_intro.html">
   <b>
    3. Data Manipulation
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/numpy-arrays.html">
     NumPy: Arrays
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/pandas-data-exploratory.html">
     Pandas: Data Exploratory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/pandas-data-cleaning.html">
     Pandas: Data Cleaning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/pandas-data-transformation.html">
     Pandas: Data Transformation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/janitor-pandas-extensions.html">
     Janitor: Pandas Extensions
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04-big-data/_intro.html">
   <b>
    4. Big Data
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/hiveql-data-manipulation.html">
     HiveQL: Data Manipulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/pyspark-data-exploratory.html">
     PySpark: Data Exploratory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/pyspark-data-cleaning.html">
     PySpark: Data Cleaning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/pyspark-data-transformation.html">
     PySpark: Data Transformation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/dask-parallelized-pandas.html">
     Dask: Parallelized Pandas
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../05-data-visualization/_intro.html">
   <b>
    5. Data Visualization
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-data-visualization/matplotlib-graph-construction.html">
     Matplotlib: Graph Construction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-data-visualization/seaborn-statistical-visualization.html">
     Seaborn: Statistical Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-data-visualization/plotly-interactive-visualization.html">
     Plotly: Interactive Visualization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="_intro.html">
   <b>
    6. Machine Learning
   </b>
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="sklearn-machine-learning.html">
     Sklearn: Machine Learning
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Sklearn: Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sklearn-regression.html">
     Sklearn: Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sklearn-feature-engineering.html">
     Featuretools: Feature Engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="lenskit-recommendation.html">
     Lenskit: Recommendation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pyspark-machine-learning.html">
     PySpark: Machine Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../07-tabular-learning/_intro.html">
   <b>
    7. Tabular Learning
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-tabular-learning/sklearn-ensemble-learning.html">
     Sklearn: Ensemble Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-tabular-learning/xgboost-tree-boosting.html">
     XGBoost: Tree Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-tabular-learning/ray-hyperparameter-optimization.html">
     Ray: Hyperparam Optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-tabular-learning/shap-model-interpretation.html">
     Shap: Model Interpretation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-tabular-learning/imblearn-targeted-modeling.html">
     Imblearn: Targeted Modeling
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../08-time-series/_intro.html">
   <b>
    8. Time Series
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-time-series/statsmodels-temporal-analysis.html">
     Statsmodels: Temporal Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-time-series/prophet-forecasting-algorithms.html">
     Prophet: Forecasting Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-time-series/sktime-forecasting-pipeline.html">
     Sktime: Forecasting Pipeline
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-time-series/darts-deep-forecasting.html">
     (w) Darts: Deep Forecasting
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../09-unsupervised-learning/_intro.html">
   <b>
    9. Unsupervised Learning
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-unsupervised-learning/mlxtend-association-rules.html">
     (w) MLxtend: Association Rules
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-unsupervised-learning/sklearn-clustering.html">
     Sklearn: Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-unsupervised-learning/sklearn-dimensional-reduction.html">
     Sklearn: Dimensional Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-unsupervised-learning/pyod-anomaly-detection.html">
     PyOD: Anomaly Detection
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../10-deep-learning/_intro.html">
   <b>
    10. Deep Learning
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/gensim-text-mining.html">
     Gensim: Text Mining
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/opencv-image-processing.html">
     (w) OpenCV: Image Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/numpy-gradient-descent.html">
     Python: Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/keras-multilayer-perceptron.html">
     Keras: Multilayer Perceptron
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/keras-recurrent-networks.html">
     Keras: Recurrent Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/keras-convolutional-networks.html">
     (w) Keras: Convolutional Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/pytorch-deep-learning.html">
     PyTorch: Deep Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/transformers-transfer-learning.html">
     (w) Transformers: Transfer Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../11-r-programing/_intro.html">
   <b>
    11. R Programing
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/r-basic-concepts.html">
     R: Basic Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/r-data-structures.html">
     R: Data Structures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/tidyverse-data-wrangling.html">
     Tidyverse: Data Wrangling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/dplyr-data-cleaning.html">
     Dplyr: Data Cleaning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/ggplot-data-visualization.html">
     Ggplot: Data Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/r-statistics.html">
     R: Statistics
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/hungpq7/tabular-book/master?urlpath=lab/tree/06-machine-learning/sklearn-classification.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/hungpq7/tabular-book/blob/master/06-machine-learning/sklearn-classification.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/hungpq7/tabular-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#k-nearest-neighbors">
   1. K-Nearest Neighbors
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algorithm">
     1.1. Algorithm
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#distance-metrics">
       Distance metrics
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#implementation">
     1.2. Implementation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#hyperparameters">
       Hyperparameters
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#model-structure">
       Model structure
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#decision-tree">
   2. Decision Tree
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     2.1. Algorithm
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tree-components">
       Tree components
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#measures-of-impurity">
       Measures of impurity
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#algorithm-details">
       Algorithm details
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     2.2. Implementation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       Hyperparameters
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#feature-importances">
       Feature importances
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interpretation">
       Interpretation
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tree-structure">
       Tree structure
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#multilabel-problem">
       Multilabel problem
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#naive-bayes">
   3. Naive Bayes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     3.1. Algorithm
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#likelihood-estimation">
       Likelihood estimation
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     3.2. Implementation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tabular-data">
       Tabular data
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#text-data">
       Text data
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#support-vector-machines">
   4. Support Vector Machines
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     4.1. Algorithm
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-loss-function">
       The loss function
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#soft-margin-svm">
       Soft Margin SVM
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#kernel-svm">
       Kernel SVM
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     4.2. Implementation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id8">
       Hyperparameters
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#probabilistic-prediction">
       Probabilistic prediction
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Sklearn: Classification</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#k-nearest-neighbors">
   1. K-Nearest Neighbors
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algorithm">
     1.1. Algorithm
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#distance-metrics">
       Distance metrics
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#implementation">
     1.2. Implementation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#hyperparameters">
       Hyperparameters
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#model-structure">
       Model structure
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#decision-tree">
   2. Decision Tree
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     2.1. Algorithm
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tree-components">
       Tree components
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#measures-of-impurity">
       Measures of impurity
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#algorithm-details">
       Algorithm details
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     2.2. Implementation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       Hyperparameters
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#feature-importances">
       Feature importances
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interpretation">
       Interpretation
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tree-structure">
       Tree structure
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#multilabel-problem">
       Multilabel problem
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#naive-bayes">
   3. Naive Bayes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     3.1. Algorithm
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#likelihood-estimation">
       Likelihood estimation
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     3.2. Implementation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tabular-data">
       Tabular data
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#text-data">
       Text data
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#support-vector-machines">
   4. Support Vector Machines
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     4.1. Algorithm
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-loss-function">
       The loss function
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#soft-margin-svm">
       Soft Margin SVM
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#kernel-svm">
       Kernel SVM
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     4.2. Implementation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id8">
       Hyperparameters
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#probabilistic-prediction">
       Probabilistic prediction
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="sklearn-classification">
<h1>Sklearn: Classification<a class="headerlink" href="#sklearn-classification" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">datetime</span> <span class="k">as</span> <span class="nn">dt</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span><span class="p">,</span> <span class="n">plot_tree</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span><span class="p">,</span> <span class="n">CategoricalNB</span><span class="p">,</span> <span class="n">BernoulliNB</span><span class="p">,</span> <span class="n">MultinomialNB</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span> <span class="k">as</span> <span class="n">AUC</span><span class="p">,</span> <span class="n">fbeta_score</span> <span class="k">as</span> <span class="n">FScore</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">paired_cosine_distances</span><span class="p">,</span> <span class="n">cosine_distances</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;seaborn&#39;</span><span class="p">,</span> <span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">])</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
</pre></div>
</div>
</div>
</div>
<section id="k-nearest-neighbors">
<h2>1. K-Nearest Neighbors<a class="headerlink" href="#k-nearest-neighbors" title="Permalink to this headline">#</a></h2>
<section id="algorithm">
<h3>1.1. Algorithm<a class="headerlink" href="#algorithm" title="Permalink to this headline">#</a></h3>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">K-NN</a> (<span class="math notranslate nohighlight">\(K\)</span>-Nearest Neighbors) does not actually <em>learn</em> anything, it only <em>saves</em> all training data point. When predicting the label for a new query point <span class="math notranslate nohighlight">\(\mathbf{s}_q\)</span>, the model first measures the distance <span class="math notranslate nohighlight">\(d_n\)</span> from each training point <span class="math notranslate nohighlight">\(\mathbf{s}_n\)</span> (<span class="math notranslate nohighlight">\(n=1,2,\dots,N\)</span>) to <span class="math notranslate nohighlight">\(\mathbf{s}_q\)</span>. Then, select <span class="math notranslate nohighlight">\(K\)</span> points with smallest distance and do majority/weighted voting to determine which class the query point belongs to. For weighted voting, the query point will fall into the class with the highest total of weight. The corresponding weight of the observation <span class="math notranslate nohighlight">\(\mathbf{s}_k\)</span> is <span class="math notranslate nohighlight">\(\displaystyle{w_k=1/d_k}\)</span> (<span class="math notranslate nohighlight">\(k=1,2,\dots,K\)</span>). Majority voting can be thought as weighted voting where all sample weights are set to <span class="math notranslate nohighlight">\(1/K\)</span>.</p>
<p>K-NN can also predict the probability that the query point falls into a specific class by computing the ratio between the total weights of those neighbors who support that class over the total weights of all <span class="math notranslate nohighlight">\(K\)</span> neighbors.</p>
<section id="distance-metrics">
<h4>Distance metrics<a class="headerlink" href="#distance-metrics" title="Permalink to this headline">#</a></h4>
<p>Some popular <a class="reference external" href="https://en.wikipedia.org/wiki/Metric_(mathematics)">distance metrics</a> being used in K-NN are:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Taxicab_geometry">Manhattan distance</a>, measures the total distance of going along side every axis.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Euclidean_distance">Euclidean distance</a>, measures the direct distance.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Mahalanobis_distance">Mahalanobis distance</a>, same as Euclidean but variables are scaled and transformed to be uncorrelated.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Cosine_similarity">Cosine distance</a>, measures how large the angle between two vectors is.</p></li>
</ul>
<p>However, Euclidean distance is the most common method:</p>
<div class="math notranslate nohighlight">
\[d_n = \sqrt{(x_{1n}-x_{1q})^2+(x_{2n}-x_{2q})^2+\dots}\]</div>
</section>
</section>
<section id="implementation">
<h3>1.2. Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline">#</a></h3>
<p>Scikit-learn implements K-NN via the class <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"><code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.94788442, 0.93111455, 0.96362229, 0.97291022, 0.95923633])
</pre></div>
</div>
</div>
</div>
<section id="hyperparameters">
<h4>Hyperparameters<a class="headerlink" href="#hyperparameters" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code>: the number of neighbors who vote for the label (<span class="math notranslate nohighlight">\(K\)</span>), defaults to <em>5</em>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weights</span></code>: the voting strategy, defaults to <em>uniform</em> (majority voting). Can be set to <em>distance</em> for weighted voting.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">metrics</span></code>: the type of distance metric, defaults to <em>euclidean</em>. Other options are <em>manhattan</em>, <em>mahalanobis</em>, <em>minkowski</em> and <em>chebyshev</em>. Also accepts customized metrics with the signature
<code class="docutils literal notranslate"><span class="pre">funcDistance(x,</span> <span class="pre">y)</span> <span class="pre">-&gt;</span> <span class="pre">distance</span></code>,
beside <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html">bulit-in ones</a>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dfCancer</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/breast_cancer.csv&#39;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">target</span>
<span class="n">xTrain</span><span class="p">,</span> <span class="n">xTest</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">yTest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">start</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">cosine_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="kn">import</span> <span class="n">norm</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">x</span> <span class="o">@</span> <span class="n">y</span> <span class="o">/</span> <span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">norm</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

<span class="n">space1</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span>
    <span class="s1">&#39;weights&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;distance&#39;</span><span class="p">],</span>
    <span class="s1">&#39;metric&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">cosine_distance</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">space2</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span>
    <span class="s1">&#39;weights&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;distance&#39;</span><span class="p">],</span>
    <span class="s1">&#39;metric&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mahalanobis&#39;</span><span class="p">],</span>
    <span class="s1">&#39;metric_params&#39;</span><span class="p">:</span> <span class="p">[{</span><span class="s1">&#39;VI&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">xTrain</span><span class="p">)}]</span>
<span class="p">}</span>

<span class="n">space3</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span>
    <span class="s1">&#39;weights&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;distance&#39;</span><span class="p">],</span>
    <span class="s1">&#39;metric&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;minkowski&#39;</span><span class="p">],</span>
    <span class="s1">&#39;p&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">space1</span><span class="p">,</span> <span class="n">space2</span><span class="p">,</span> <span class="n">space3</span><span class="p">]</span>

<span class="n">algo</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">validator</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">algo</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">)</span>
<span class="n">validator</span> <span class="o">=</span> <span class="n">validator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">validator</span><span class="o">.</span><span class="n">best_estimator_</span>

<span class="n">end</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0:00:45.142652
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">validator</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;metric&#39;: &#39;minkowski&#39;, &#39;n_neighbors&#39;: 9, &#39;p&#39;: 1, &#39;weights&#39;: &#39;distance&#39;}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yTestPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">xTest</span><span class="p">)[:,</span> <span class="n">model</span><span class="o">.</span><span class="n">classes_</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">aucTest</span> <span class="o">=</span> <span class="n">AUC</span><span class="p">(</span><span class="n">yTest</span><span class="p">,</span> <span class="n">yTestPred</span><span class="p">)</span>
<span class="n">modelName</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;AUC = </span><span class="si">{</span><span class="n">aucTest</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1"> [</span><span class="si">{</span><span class="n">modelName</span><span class="si">}</span><span class="s1">]&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AUC = 0.9730 [KNeighborsClassifier]
</pre></div>
</div>
</div>
</div>
</section>
<section id="model-structure">
<h4>Model structure<a class="headerlink" href="#model-structure" title="Permalink to this headline">#</a></h4>
<p>Here are the information you can extract from a K-NN model fit by Scikit-learn:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.kneighbors"><code class="docutils literal notranslate"><span class="pre">kneighbors()</span></code></a> method: find the <span class="math notranslate nohighlight">\(K\)</span> neighbors and their corresponding distances of query points.</p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.kneighbors_graph"><code class="docutils literal notranslate"><span class="pre">kneighbors_graph()</span></code></a> method: compute the weighted graph of <span class="math notranslate nohighlight">\(K\)</span> neighbors for query points.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">neighborDistance</span><span class="p">,</span> <span class="n">neighborIndex</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">xTest</span><span class="p">)</span>
<span class="n">neighborDistance</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(114, 9)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">graph</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">kneighbors_graph</span><span class="p">(</span><span class="n">xTest</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;distance&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">graph</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(114, 455)
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="decision-tree">
<h2>2. Decision Tree<a class="headerlink" href="#decision-tree" title="Permalink to this headline">#</a></h2>
<section id="id1">
<h3>2.1. Algorithm<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Decision_tree_learning">Decision Tree</a> is a method aiming to find a set of if-else statements to build a preditive model, visualized as a hierarchy diagram. There has been several Decision Tree algorithms invented throught out the history, notably include:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/ID3_algorithm">ID3</a>, an algorithm that creates a multiway classification tree using <a class="reference external" href="https://en.wikipedia.org/wiki/Information_gain_in_decision_trees">information gain</a> principle and works only on categorical variables.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/C4.5_algorithm">C4.5</a>, the successor of ID3, makes a number of improvements: (1) accepting continuous variables using thresholdList, (2) ignoring missing values in the calculation of information gain and (3) introducing tree pruning.</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Predictive_analytics#Classification_and_regression_trees_(CART)">CART</a>, a similar algorithm to C4.5 but it only grows binary trees and supports regression problems. This is the algorithm used in Scikit-learn.</p></li>
</ul>
<section id="tree-components">
<h4>Tree components<a class="headerlink" href="#tree-components" title="Permalink to this headline">#</a></h4>
<p>In a Decision Tree, a node is the representation of data. The data is then split using a variable and a split condition. A node is a parent node if it is split, the smaller nodes after splitting it are child nodes. Here are the components of a tree:</p>
<ul class="simple">
<li><p>Root node: the topmost node, represents the entire data</p></li>
<li><p>Leaf node (terminal node): the node that is not split further and predicts the label</p></li>
<li><p>Internal node: any node other than leaf nodes</p></li>
<li><p>Edge: the specific criterion to split a node</p></li>
<li><p>Branch: represents a sub-tree which considers an internal node as root node</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/tree_components.png"><img alt="../_images/tree_components.png" class="align-center" src="../_images/tree_components.png" style="height: 200px;" /></a>
</section>
<section id="measures-of-impurity">
<h4>Measures of impurity<a class="headerlink" href="#measures-of-impurity" title="Permalink to this headline">#</a></h4>
<p>The ultimate goal of Decision Tree is to construct a tree having leaf nodes as <em>pure</em> as possible. A node is considered <em>pure</em> if most of its observations fall into a single class. In contrast, an <em>impure</em> node distributes its observations equally into different classes. In this section, we learn about some quality metrics that measure the <em>impurity</em> of a node. These metrics should be designed so that the higher values they are, the less pure a node is.</p>
<p>Lets say at a node, the probability (ratio) that an observation falls into a class <span class="math notranslate nohighlight">\(\mathcal{C}_m\)</span> is <span class="math notranslate nohighlight">\(p_m\)</span>. Here are the two measures of impurity:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\displaystyle{\text{Entropy} = -\sum_{m=1}^{M}{p_m\log{p_m}}}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\displaystyle{\text{Gini} = 1-\sum_{m=1}^{M}{p_m^2}}\)</span></p></li>
</ul>
<p>Now lets graph these functions for the most simple case: binary classification. Despite that there are 2 classes, we only need to plot against the ratio of positive class.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;seaborn&#39;</span><span class="p">,</span> <span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">])</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;

<span class="n">error</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">boundLeft</span><span class="p">,</span> <span class="n">boundRight</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">boundLeft</span><span class="p">,</span> <span class="n">boundRight</span> <span class="o">=</span> <span class="n">boundLeft</span> <span class="o">+</span> <span class="n">error</span><span class="p">,</span> <span class="n">boundRight</span> <span class="o">-</span> <span class="n">error</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">boundLeft</span><span class="p">,</span> <span class="n">boundRight</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">q</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">p</span>

<span class="n">entropy</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">p</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="n">q</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">q</span><span class="p">))</span>
<span class="n">gini</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">p</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">q</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">entropy</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Entropy&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">gini</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Gini&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/sklearn-classification_20_0.png"><img alt="../_images/sklearn-classification_20_0.png" class="align-center" src="../_images/sklearn-classification_20_0.png" style="width: 481.5px; height: 329.5px;" /></a>
</div>
</div>
</section>
<section id="algorithm-details">
<h4>Algorithm details<a class="headerlink" href="#algorithm-details" title="Permalink to this headline">#</a></h4>
<p><em>Input</em></p>
<ul class="simple">
<li><p>A dataset of numerical features</p></li>
<li><p>A quality function</p></li>
<li><p>Stopping criteria (optional)</p></li>
</ul>
<p><em>Step 1</em>. For each unsplit node <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> (starting from the root node):</p>
<ul>
<li><p>Compute the impurity of node <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p></li>
<li><p>For each candiate (which is a combination a feature and a threshold):</p>
<ul class="simple">
<li><p>Split node <span class="math notranslate nohighlight">\(D\)</span> into 2 smaller nodes, <span class="math notranslate nohighlight">\(\mathcal{D}_{\text{left}}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{D}_{\text{right}}\)</span>.</p></li>
<li><p>Calculate the impurity for these child nodes.</p></li>
<li><p>Calculate the information gain for the candidate:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
    \text{InfoGain}=
    \text{Impurity}_{\text{parent}}-
    \left(
        \frac{|\mathcal{D}_{\text{left}}|}{|\mathcal{D}|}\,\text{Impurity}_{\text{left}}+
        \frac{|\mathcal{D}_{\text{right}}|}{|\mathcal{D}|}\,\text{Impurity}_{\text{right}}
    \right)
    \]</div>
</li>
<li><p>Choose the candidate with the highest information gain. Split node <span class="math notranslate nohighlight">\(D\)</span> using that candidate.</p></li>
</ul>
<p><em>Step 2</em>. Go back and prune the tree  until all stopping conditions are met. The purpose of this step is to prevent overfitting. For example, you can set the minimum number of observations to perform a split to 20, the algorithm will find all branches whose root node is not large enough. For each branch, it removes the entire branch and keeps only the root node.</p>
<p><em>Step 3</em>. Calculate the ratio of every class in every leaf node. These values are used as probability prediction.</p>
</section>
</section>
<section id="id2">
<h3>2.2. Implementation<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h3>
<p>Scikit-learn implements Decision Tree via the class <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"><code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code></a>.</p>
<section id="id3">
<h4>Hyperparameters<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">criterion</span></code>: the measure of quality of a split, defaults to <em>gini</em>. The other option is <em>entropy</em>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code>: the maximum depth of the tree, defaults to <em>None</em> (no limitations).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code>: the maximum number of leaf nodes, defaults to <em>None</em> (no limitations).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code>: the minimum number (if integer) or ratio (if float) of instances in a node to split, defautls to <em>2</em>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>: the minimum number (integer) or ratio (float) of instances a leaf node must have, deafaults to <em>1</em>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_weight_fraction_leaf</span></code>: the minimum sum of instance weights a node must have, defaults to <em>0</em>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_impurity_decrease</span></code>: a split will be performed if its information gain is not less than this value, defaults to <em>0</em>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dfCancer</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/breast_cancer.csv&#39;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">target</span>
<span class="n">xTrain</span><span class="p">,</span> <span class="n">xTest</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">yTest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">start</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;criterion&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="s1">&#39;entropy&#39;</span><span class="p">],</span>
    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span>
    <span class="s1">&#39;random_state&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">algo</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="n">validator</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">algo</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">)</span>
<span class="n">validator</span> <span class="o">=</span> <span class="n">validator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">validator</span><span class="o">.</span><span class="n">best_estimator_</span>

<span class="nb">print</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0:00:00.301890
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">validator</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;criterion&#39;: &#39;gini&#39;, &#39;max_depth&#39;: 4, &#39;random_state&#39;: 2}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yTestPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">xTest</span><span class="p">)[:,</span> <span class="n">model</span><span class="o">.</span><span class="n">classes_</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">aucTest</span> <span class="o">=</span> <span class="n">AUC</span><span class="p">(</span><span class="n">yTest</span><span class="p">,</span> <span class="n">yTestPred</span><span class="p">)</span>
<span class="n">modelName</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;AUC = </span><span class="si">{</span><span class="n">aucTest</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1"> [</span><span class="si">{</span><span class="n">modelName</span><span class="si">}</span><span class="s1">]&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AUC = 0.9373 [DecisionTreeClassifier]
</pre></div>
</div>
</div>
</div>
</section>
<section id="feature-importances">
<h4>Feature importances<a class="headerlink" href="#feature-importances" title="Permalink to this headline">#</a></h4>
<p>Decision Tree supports computing feature importances by taking the total information gain brought by each feature. This can be extracted using the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.feature_importances_"><code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code></a> attribute.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nTop</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">feature_names_in_</span><span class="p">,</span> <span class="s1">&#39;importance&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">})</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;importance&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;importance &gt; 0&quot;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="n">nTop</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;importance&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;teal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/sklearn-classification_30_0.png"><img alt="../_images/sklearn-classification_30_0.png" class="align-center" src="../_images/sklearn-classification_30_0.png" style="width: 414.5px; height: 180.5px;" /></a>
</div>
</div>
</section>
<section id="interpretation">
<h4>Interpretation<a class="headerlink" href="#interpretation" title="Permalink to this headline">#</a></h4>
<p>The Scikit-learns <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html"><code class="docutils literal notranslate"><span class="pre">plot_tree()</span></code></a> function plots the entire structure of a Decision Tree model. In this example, I use a max depth of 3 for better visualization. Each color represents a class, the darker the color a node has, the purer it is. In contrast, its very hard to make a decision for bright nodes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">tree</span><span class="o">.</span><span class="n">feature_names_in_</span><span class="p">,</span> <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/sklearn-classification_32_0.png"><img alt="../_images/sklearn-classification_32_0.png" class="align-center" src="../_images/sklearn-classification_32_0.png" style="width: 794.9000000000001px; height: 322.0px;" /></a>
</div>
</div>
</section>
<section id="tree-structure">
<h4>Tree structure<a class="headerlink" href="#tree-structure" title="Permalink to this headline">#</a></h4>
<p>In this section, we discuss the underlying <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html">tree structure</a> and how to use the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.decision_path"><code class="docutils literal notranslate"><span class="pre">decision_path()</span></code></a> method to get access to the predicting process.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">print_tree_structure</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">nNode</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">node_count</span>
    <span class="n">childLeftList</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_left</span>
    <span class="n">childRightList</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_right</span>
    <span class="n">thresholdList</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">threshold</span>
    <span class="n">valuesList</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">value</span>
    
    <span class="k">try</span><span class="p">:</span>
        <span class="n">featureList</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;feature</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">feature</span><span class="p">]</span>
        <span class="n">featureList</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">feature_names_in_</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="n">nodeDepthList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">nNode</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">isLeafList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">nNode</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
    <span class="n">stack</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span>  <span class="c1"># start with the root node id (0) and its depth (0)</span>
    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">stack</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># `pop` ensures each node is only visited once</span>
        <span class="n">nodeId</span><span class="p">,</span> <span class="n">depth</span> <span class="o">=</span> <span class="n">stack</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
        <span class="n">nodeDepthList</span><span class="p">[</span><span class="n">nodeId</span><span class="p">]</span> <span class="o">=</span> <span class="n">depth</span>

        <span class="c1"># If the left and right child of a node is not the same we have a split node</span>
        <span class="n">isSplitNode</span> <span class="o">=</span> <span class="n">childLeftList</span><span class="p">[</span><span class="n">nodeId</span><span class="p">]</span> <span class="o">!=</span> <span class="n">childRightList</span><span class="p">[</span><span class="n">nodeId</span><span class="p">]</span>
        <span class="c1"># If a split node, append left and right children and depth to `stack`</span>
        <span class="c1"># so we can loop through them</span>
        <span class="k">if</span> <span class="n">isSplitNode</span><span class="p">:</span>
            <span class="n">stack</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">childLeftList</span><span class="p">[</span><span class="n">nodeId</span><span class="p">],</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">stack</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">childRightList</span><span class="p">[</span><span class="n">nodeId</span><span class="p">],</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">isLeafList</span><span class="p">[</span><span class="n">nodeId</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;The binary tree structure has </span><span class="si">{</span><span class="n">nNode</span><span class="si">}</span><span class="s2"> nodes.</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Data smaller than threshold goes to the left, else go to the right.</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Internal syntax: &lt;splitCondition&gt;, &lt;childLeft&gt;, &lt;childRight&gt;.</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Leaf syntax: &lt;prediction&gt;, &lt;probability&gt;.</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nNode</span><span class="p">):</span>
        <span class="n">space</span> <span class="o">=</span> <span class="n">nodeDepthList</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span>
        <span class="n">nodeId</span> <span class="o">=</span> <span class="n">i</span>
        <span class="n">childLeft</span> <span class="o">=</span> <span class="n">childLeftList</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">childRight</span> <span class="o">=</span> <span class="n">childRightList</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">feature</span> <span class="o">=</span> <span class="n">featureList</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">threshold</span> <span class="o">=</span> <span class="n">thresholdList</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">valuesList</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">predictClass</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
        <span class="n">predictProb</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="n">predictClass</span><span class="p">]</span> <span class="o">/</span> <span class="n">values</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">isLeafList</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">space</span><span class="si">}</span><span class="s2">NODE=</span><span class="si">{</span><span class="n">nodeId</span><span class="si">}</span><span class="s2"> (leaf): &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;class=</span><span class="si">{</span><span class="n">predictClass</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">predictProb</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">space</span><span class="si">}</span><span class="s2">NODE=</span><span class="si">{</span><span class="n">nodeId</span><span class="si">}</span><span class="s2"> (internal): &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n">threshold</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, node</span><span class="si">{</span><span class="n">childLeft</span><span class="si">}</span><span class="s2">, node</span><span class="si">{</span><span class="n">childRight</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_tree_structure</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The binary tree structure has 25 nodes.
Data smaller than threshold goes to the left, else go to the right.
Internal syntax: &lt;splitCondition&gt;, &lt;childLeft&gt;, &lt;childRight&gt;.
Leaf syntax: &lt;prediction&gt;, &lt;probability&gt;.

NODE=0 (internal): mean_radius=106.05, node1, node12
	NODE=1 (internal): mean_texture=0.16, node2, node9
		NODE=2 (internal): mean_perimeter=0.14, node3, node6
			NODE=3 (internal): mean_area=0.64, node4, node5
				NODE=4 (leaf): class=1, 100.00%
				NODE=5 (leaf): class=1, 66.67%
			NODE=6 (internal): mean_concavity=20.84, node7, node8
				NODE=7 (leaf): class=1, 100.00%
				NODE=8 (leaf): class=0, 100.00%
		NODE=9 (internal): mean_fractal_dimension=16.22, node10, node11
			NODE=10 (leaf): class=1, 100.00%
			NODE=11 (leaf): class=0, 100.00%
	NODE=12 (internal): perimeter_error=20.65, node13, node18
		NODE=13 (internal): area_error=116.80, node14, node15
			NODE=14 (leaf): class=1, 100.00%
			NODE=15 (internal): compactness_error=0.01, node16, node17
				NODE=16 (leaf): class=1, 100.00%
				NODE=17 (leaf): class=0, 100.00%
		NODE=18 (internal): symmetry_error=0.05, node19, node22
			NODE=19 (internal): fractal_dimension_error=0.02, node20, node21
				NODE=20 (leaf): class=0, 100.00%
				NODE=21 (leaf): class=1, 100.00%
			NODE=22 (internal): worst_perimeter=0.08, node23, node24
				NODE=23 (leaf): class=1, 100.00%
				NODE=24 (leaf): class=0, 100.00%
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">print_decision_path</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sample</span><span class="p">):</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decision_path</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">path</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;node</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">path</span><span class="p">]</span>
    <span class="n">path</span> <span class="o">=</span> <span class="s1">&#39; -&gt; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample</span> <span class="o">=</span> <span class="n">xTest</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">print_decision_path</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sample</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>node0 -&gt; node12 -&gt; node13 -&gt; node14
</pre></div>
</div>
</div>
</div>
</section>
<section id="multilabel-problem">
<h4>Multilabel problem<a class="headerlink" href="#multilabel-problem" title="Permalink to this headline">#</a></h4>
<p>Decision Tree, as well as some other tree-based algorithms, can be extended to <em>multi-label</em> problems, including both regression and classification. The term <em>multi-label</em> is also known as <em>multi-output</em>, but is different from <em>multi-class</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dfEmotionTrain</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/emotions_train.csv&#39;</span><span class="p">)</span>
<span class="n">dfEmotionTest</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/emotions_test.csv&#39;</span><span class="p">)</span>

<span class="n">xTrain</span> <span class="o">=</span> <span class="n">dfEmotionTrain</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">6</span><span class="p">]</span>
<span class="n">yTrain</span> <span class="o">=</span> <span class="n">dfEmotionTrain</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">6</span><span class="p">:]</span>
<span class="n">xTest</span> <span class="o">=</span> <span class="n">dfEmotionTest</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">6</span><span class="p">]</span>
<span class="n">yTest</span> <span class="o">=</span> <span class="n">dfEmotionTest</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">6</span><span class="p">:]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">xTrain</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">yTrain</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(391, 72) (391, 6)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">start</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;criterion&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="s1">&#39;entropy&#39;</span><span class="p">],</span>
    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span>
    <span class="s1">&#39;random_state&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">algo</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="n">validator</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">algo</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">)</span>
<span class="n">validator</span> <span class="o">=</span> <span class="n">validator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">validator</span><span class="o">.</span><span class="n">best_estimator_</span>

<span class="nb">print</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0:00:00.941082
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yTestProb</span> <span class="o">=</span> <span class="n">xTest</span> <span class="o">|</span> <span class="n">f</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">)</span> <span class="o">|</span> <span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">)</span>
<span class="n">yTestProb</span> <span class="o">=</span> <span class="n">yTestProb</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>
<span class="n">listAuc</span> <span class="o">=</span> <span class="n">AUC</span><span class="p">(</span><span class="n">yTest</span><span class="p">,</span> <span class="n">yTestProb</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">listAuc</span> <span class="o">=</span> <span class="n">listAuc</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;AUC = </span><span class="si">{</span><span class="n">listAuc</span><span class="si">}</span><span class="s1"> [</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">]&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AUC = [0.7801, 0.5942, 0.679, 0.8473, 0.707, 0.82] [DecisionTreeClassifier]
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="naive-bayes">
<h2>3. Naive Bayes<a class="headerlink" href="#naive-bayes" title="Permalink to this headline">#</a></h2>
<section id="id4">
<h3>3.1. Algorithm<a class="headerlink" href="#id4" title="Permalink to this headline">#</a></h3>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">Naive Bayes</a> is an algorithm based on the <a class="reference external" href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes theorem</a>. In the context of classification, given <span class="math notranslate nohighlight">\(\mathbf{X}=\mathbf{x}_1,\mathbf{x}_2,\dots\)</span> is the set of input variables and <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> is the output variable; the Bayes theorem can be written as:</p>
<div class="math notranslate nohighlight">
\[P(\mathbf{y}|\mathbf{X}) = \frac{P(\mathbf{X}|\mathbf{y})P(\mathbf{y})}{P(\mathbf{X})}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(\mathbf{y}|\mathbf{X})\)</span> is the posterior probability, the probability of a class for given predictors</p></li>
<li><p><span class="math notranslate nohighlight">\(P(\mathbf{X}|\mathbf{y})\)</span> is the likelihood, the probability of predictors for a given class</p></li>
<li><p><span class="math notranslate nohighlight">\(P(\mathbf{y})\)</span> is the prior probability of a class</p></li>
<li><p><span class="math notranslate nohighlight">\(P(\mathbf{X})\)</span> is the prior probability of predictors</p></li>
</ul>
<p>This formula expresses how the algorithm classifies a new query point to the class <span class="math notranslate nohighlight">\(c\)</span>:</p>
<div class="math notranslate nohighlight">
\[\hat{\mathbf{y}} = \arg\max P(\mathbf{y}=c|\mathbf{X}) =
\arg\max P(\mathbf{X}|\mathbf{y}=c)P(\mathbf{y}=c)\]</div>
<section id="likelihood-estimation">
<h4>Likelihood estimation<a class="headerlink" href="#likelihood-estimation" title="Permalink to this headline">#</a></h4>
<p>Naive Bayes assumes that <span class="math notranslate nohighlight">\(\mathbf{x}_1,\mathbf{x}_2,\dots\)</span> are independent of each other. This assumption looks quite unrealistic, explains why the algorithm is considered naive. However, Naive Bayes performs surprisingly well in real-world classification problems. The likelihood can be written under this assumption:</p>
<div class="math notranslate nohighlight">
\[P(\mathbf{x}_1,\mathbf{x}_2,\dots|\mathbf{y}) = \prod_{d=1}^{D}{P(\mathbf{x}_d|\mathbf{y})}\]</div>
<p>To estimate <span class="math notranslate nohighlight">\(P(\mathbf{x}_i|\mathbf{y})\)</span>, there are three distributions can be used, depending on the input data:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Normal_distribution">Gaussian distribution</a>, used when the input data is continuous. The parameters <span class="math notranslate nohighlight">\(\mu_{\mathbf{y}}\)</span> and <span class="math notranslate nohighlight">\(\sigma_{\mathbf{y}}\)</span> are estimated using maximum likelihood.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[P(\mathbf{x}_d|\mathbf{y}) = \frac{1}{\sqrt{2\pi\sigma^2_{\mathbf{y}}}} \exp\left(-\frac{(\mathbf{x}_d - \mu_{\mathbf{y}})^2}{2\sigma^2_{\mathbf{y}}}\right)\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Multinomial_distribution">Multinomial distribution</a>, used when the input data is categorical data. Widely used in text classification. In this formula, <span class="math notranslate nohighlight">\(N\)</span> represents the number of observations, <span class="math notranslate nohighlight">\(\alpha\)</span> represents the Laplace smooth coefficient, <span class="math notranslate nohighlight">\(K\)</span> is the number of words. <span class="math notranslate nohighlight">\(\alpha=1\)</span> is usually chosen, prevents the probability to be 0.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[P(\mathbf{x}_d|\mathbf{y}) = \frac{N(\mathbf{x}_d|\mathbf{y})+\alpha}{N(\mathbf{y})+\alpha K}\]</div>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli distribution</a>, used for binary input data.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[P(\mathbf{x}_d|\mathbf{y}) = p_d^{\mathbf{x}_d}(1-p_d)^{1-\mathbf{x}_d}\]</div>
</section>
</section>
<section id="id5">
<h3>3.2. Implementation<a class="headerlink" href="#id5" title="Permalink to this headline">#</a></h3>
<section id="tabular-data">
<h4>Tabular data<a class="headerlink" href="#tabular-data" title="Permalink to this headline">#</a></h4>
<p>This section uses the breast cancer dataset, where input variables are continuous. For a mixed types dataset, we independently train</p>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html"><code class="docutils literal notranslate"><span class="pre">GaussianNB</span></code></a> for continuous features</p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html"><code class="docutils literal notranslate"><span class="pre">CategoricalNB</span></code></a> for categorical features</p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html"><code class="docutils literal notranslate"><span class="pre">BernoulliNB</span></code></a> for binary features</p></li>
</ul>
<p>then stack their results by multiplication.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dfCancer</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/breast_cancer.csv&#39;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">target</span>
<span class="n">xTrain</span><span class="p">,</span> <span class="n">xTest</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">yTest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">start</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;criterion&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="s1">&#39;entropy&#39;</span><span class="p">],</span>
    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span>
    <span class="s1">&#39;random_state&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">algo</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">algo</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0:00:00.003376
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yTestPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">xTest</span><span class="p">)[:,</span> <span class="n">model</span><span class="o">.</span><span class="n">classes_</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">aucTest</span> <span class="o">=</span> <span class="n">AUC</span><span class="p">(</span><span class="n">yTest</span><span class="p">,</span> <span class="n">yTestPred</span><span class="p">)</span>
<span class="n">modelName</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;AUC = </span><span class="si">{</span><span class="n">aucTest</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1"> [</span><span class="si">{</span><span class="n">modelName</span><span class="si">}</span><span class="s1">]&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AUC = 0.9772 [GaussianNB]
</pre></div>
</div>
</div>
</div>
</section>
<section id="text-data">
<h4>Text data<a class="headerlink" href="#text-data" title="Permalink to this headline">#</a></h4>
<p>Text data is preprocessed so that columns represent words and row represents their number of occurrences (also known as count vectorization). <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"><code class="docutils literal notranslate"><span class="pre">MultinomialNB</span></code></a> is suitable in this case.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xTrain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">])</span>
<span class="n">yTrain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">])</span>

<span class="n">xTest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">algo</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">algo</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xTest</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;A&#39;, &#39;B&#39;], dtype=&#39;&lt;U1&#39;)
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="support-vector-machines">
<h2>4. Support Vector Machines<a class="headerlink" href="#support-vector-machines" title="Permalink to this headline">#</a></h2>
<section id="id6">
<h3>4.1. Algorithm<a class="headerlink" href="#id6" title="Permalink to this headline">#</a></h3>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Support-vector_machine">Support Vector Machines</a> is a binary classification algorithm, aiming to find a hyperplane that best splits the data into two classes (<span class="math notranslate nohighlight">\(\mathbf{y}=1\)</span> and <span class="math notranslate nohighlight">\(\mathbf{y}=-1\)</span>). SVM uses the following concepts:</p>
<ul class="simple">
<li><p>Support vector: the closest point from the separating hyperplane. There is at least one support vector in each class.</p></li>
<li><p>Margin: the distance between a support vector and the separating hyperplane.</p></li>
</ul>
<p>Notice that all support vectors should have the same distance from the decision boundary. In other words, the margins of both class are equal. Its quite clear to state that the larger the margin is, the better the algorithm classifies the data.</p>
<section id="the-loss-function">
<h4>The loss function<a class="headerlink" href="#the-loss-function" title="Permalink to this headline">#</a></h4>
<p>Assume the equation of the separating hyperplane is <span class="math notranslate nohighlight">\(w_0+w_1\mathbf{x}_1+w_2\mathbf{x}_2+\dots=0\)</span>. Denote <span class="math notranslate nohighlight">\(\mathbf{w}=(w_1,w_2,\dots)\)</span> and <span class="math notranslate nohighlight">\(\mathbf{X}=(\mathbf{x}_1,\mathbf{x}_2,\dots)\)</span>, the boundary can be rewritten as <span class="math notranslate nohighlight">\(w_0+\mathbf{w}\mathbf{X}=0\)</span>. Now do some transformations so that the equations of the two edges (hyperplanes that are parallel to the boundary and go through the support vectors) are <span class="math notranslate nohighlight">\(w_0+\mathbf{w}\mathbf{X}=1\)</span> and <span class="math notranslate nohighlight">\(w_0+\mathbf{w}\mathbf{X}=-1\)</span>.</p>
<a class="reference internal image-reference" href="../_images/svm_hard.png"><img alt="../_images/svm_hard.png" class="align-center" src="../_images/svm_hard.png" style="height: 300px;" /></a>
<br>
<p>By assigning suitable class values (for example, <span class="math notranslate nohighlight">\(\mathbf{y}=1\)</span> for blue class and <span class="math notranslate nohighlight">\(\mathbf{y}=-1\)</span> for red class), we have the following important property, which becomes the constraint for the margin formula:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(|w_0+\mathbf{w}\mathbf{s}_n|=y_n\,(w_0+\mathbf{w}\mathbf{s}_n)=1\)</span> for a support vector</p></li>
<li><p><span class="math notranslate nohighlight">\(|w_0+\mathbf{w}\mathbf{s}_n|=y_n\,(w_0+\mathbf{w}\mathbf{s}_n)&gt;1\)</span> for another data point</p></li>
</ul>
<p>The margin can be calculated using the formula:</p>
<div class="math notranslate nohighlight">
\[\frac{y_n\,(w_0+\mathbf{w}\mathbf{s}_n)}{\|\mathbf{w}\|_2}
\quad\text{subject to:}\;y_n\,(w_0+\mathbf{w}\mathbf{s}_n)\geq 1\]</div>
<p>Notice that <span class="math notranslate nohighlight">\(y_n\;(w_0+\mathbf{w}\mathbf{s}_n)=1\)</span> and the objective of SVM is to maximize the margin, so the loss function is selected:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(w_0,\mathbf{w}) = \|\mathbf{w}\|_2
\quad\text{subject to:}\;y_n\,(w_0+\mathbf{w}\mathbf{s}_n)\geq 1\]</div>
<p>The coefficients of the separating equation are be estimated: <span class="math notranslate nohighlight">\((\hat{w}_0,\hat{\mathbf{w}}) = \arg\min{\mathcal{L}(w_0,\mathbf{w})}\)</span>.</p>
</section>
<section id="soft-margin-svm">
<h4>Soft Margin SVM<a class="headerlink" href="#soft-margin-svm" title="Permalink to this headline">#</a></h4>
<p>In the simple example above, the line segregates perfectly; however a hard margin like that is very sensitive to outliers and can easily lead to overfitting. This can be avoided by allowing some misclassified points to get a larger margin, and thus return a better long run performance.</p>
<p>To get the soft margin, we soften the constrain of the margin formula:</p>
<div class="math notranslate nohighlight">
\[y_n\,(w_0+\mathbf{w}\mathbf{s}_n)\geq 1-\xi_n\]</div>
<p><span class="math notranslate nohighlight">\(\xi_n\)</span> is the slack variable corresponding to the observation <span class="math notranslate nohighlight">\(\mathbf{s}_n\)</span>, which is the distance from a data point in the wrong side to its corresponding edge, and is 0 otherwise. Mathematically:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\xi_n=0\)</span> if a data point is in the safe zone</p></li>
<li><p><span class="math notranslate nohighlight">\(\xi_n=|w_0+\mathbf{w}\mathbf{s}_n-y_n|&lt;1\)</span> if a data point is correctly classified but lies within the margin</p></li>
<li><p><span class="math notranslate nohighlight">\(\xi_n=|w_0+\mathbf{w}\mathbf{s}_n-y_n|\geq1\)</span> if a data point is in the wrong side of separating hyperplane</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/svm_soft.png"><img alt="../_images/svm_soft.png" class="align-center" src="../_images/svm_soft.png" style="height: 300px;" /></a>
<br>
<p>The objective function of Soft Margin SVM adds a regularization amount to the loss function:</p>
<div class="math notranslate nohighlight">
\[\mathcal{O}(w_0,\mathbf{w}) = ||\mathbf{w}||_2+C\sum_{n=1}^{N}{\xi_n}
\quad\text{subject to:}\;y_n\,(w_0+\mathbf{w}\mathbf{s}_n)\geq 1-\xi_n\]</div>
<p><span class="math notranslate nohighlight">\(C\)</span> is the regularization parameter, it maintains the trade-off between the misclassifications and how large the margin is. When <span class="math notranslate nohighlight">\(C\)</span> is very large, <span class="math notranslate nohighlight">\(\mathcal{R}(w_0,\mathbf{w})\)</span> approaches 0, the algorithm is now using hard margin. In contrast, a small value of <span class="math notranslate nohighlight">\(C\)</span> allows more data to be within the margin. A popular value of <span class="math notranslate nohighlight">\(C\)</span> is <span class="math notranslate nohighlight">\(1/N\)</span>.</p>
</section>
<section id="kernel-svm">
<h4>Kernel SVM<a class="headerlink" href="#kernel-svm" title="Permalink to this headline">#</a></h4>
<p>Soft Margin SVM only works on linear separable data. When the data is non-linear, we project the data to a higher dimensional space. For example, mapping <span class="math notranslate nohighlight">\((\mathbf{x}_1,\mathbf{x}_2)\)</span> to <span class="math notranslate nohighlight">\((\mathbf{x}_1,\mathbf{x}_2,\mathbf{x}_3)\)</span> where <span class="math notranslate nohighlight">\(\mathbf{x}_3=\mathbf{x}_1^2+\mathbf{x}_2^2\)</span> seems a good strategy.</p>
<a class="reference internal image-reference" href="../_images/svm_kernel.png"><img alt="../_images/svm_kernel.png" class="align-center" src="../_images/svm_kernel.png" style="height: 300px;" /></a>
<br>
<p>However, transforming data directly may require a lot of computation, and becomes impossible when infinite dimensional is used. This problem can be avoided thanks to a technique called the kernel trick. It calculates the dot product of two transformed vectors, which represents their relationship in higher dimensional space. Depending on the problem, there are many kernel functions can be used:</p>
<ul class="simple">
<li><p>Linear kernel: <span class="math notranslate nohighlight">\(\kappa(\mathbf{a},\mathbf{b})=\mathbf{a}\mathbf{b}\)</span></p></li>
<li><p>Polynomial kernel: <span class="math notranslate nohighlight">\(\kappa(\mathbf{a},\mathbf{b})=(\gamma\mathbf{a}\mathbf{b}+r)^d\)</span></p></li>
<li><p>Radial Basic Function kernel: <span class="math notranslate nohighlight">\(\kappa(\mathbf{a},\mathbf{b})=\exp{\left(-\gamma\|\mathbf{a}-\mathbf{b}\|_2^2\right)}\)</span></p></li>
<li><p>Sigmoid kernel: <span class="math notranslate nohighlight">\(\kappa(\mathbf{a},\mathbf{b})=\tanh{(\gamma\mathbf{a}\mathbf{b}+r)}\)</span></p></li>
</ul>
</section>
</section>
<section id="id7">
<h3>4.2. Implementation<a class="headerlink" href="#id7" title="Permalink to this headline">#</a></h3>
<p>Scikit-learn implements Support Vector Classifier via the class <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"><code class="docutils literal notranslate"><span class="pre">SVC</span></code></a>.</p>
<section id="id8">
<h4>Hyperparameters<a class="headerlink" href="#id8" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">C</span></code>: the significance of the penalty, defaults to <em>1</em>. Common values are <span class="math notranslate nohighlight">\(10^k\)</span> for <span class="math notranslate nohighlight">\(k\in\{-2,-1,0,1,2\}\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kernel</span></code>: the kernel function to be used, defaults to <em>rbf</em>. Other options are <em>poly</em> and <em>sigmoid</em>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">gamma</span></code>: the parameter <span class="math notranslate nohighlight">\(\gamma\)</span> in some kernel functions, defaults to <em>scale</em>. Common values are <span class="math notranslate nohighlight">\(10^k\)</span> for <span class="math notranslate nohighlight">\(k\in\{-2,-1,0,1,2\}\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">coef0</span></code>: the paremeter <span class="math notranslate nohighlight">\(r\)</span> in some kernel functions, defautls to <em>0</em>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">degree</span></code>: the parameter <span class="math notranslate nohighlight">\(d\)</span> in polynomial kernel, defaults to <em>3</em>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dfCancer</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/breast_cancer.csv&#39;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">target</span>
<span class="n">xTrain</span><span class="p">,</span> <span class="n">xTest</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">yTest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">start</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">],</span>
    <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="s1">&#39;probability&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">algo</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
<span class="n">validator</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">algo</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">)</span>
<span class="n">validator</span> <span class="o">=</span> <span class="n">validator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">validator</span><span class="o">.</span><span class="n">best_estimator_</span>

<span class="nb">print</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0:00:03.631612
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">validator</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;C&#39;: 1, &#39;gamma&#39;: 0.01, &#39;kernel&#39;: &#39;rbf&#39;, &#39;probability&#39;: True}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">support_vectors_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">xTrain</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(452, 30)
(455, 30)
</pre></div>
</div>
</div>
</div>
</section>
<section id="probabilistic-prediction">
<h4>Probabilistic prediction<a class="headerlink" href="#probabilistic-prediction" title="Permalink to this headline">#</a></h4>
<p>SVM does not easily calculate probabilities like K-NN or Decision Tree, it instead implements cross validated logistic regression on the scores. Thus, it is computationally expensive and need to be enabled. Otherwise, decision function of SVM can be used instead.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yTestPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">xTest</span><span class="p">)[:,</span> <span class="n">model</span><span class="o">.</span><span class="n">classes_</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">aucTest</span> <span class="o">=</span> <span class="n">AUC</span><span class="p">(</span><span class="n">yTest</span><span class="p">,</span> <span class="n">yTestPred</span><span class="p">)</span>
<span class="n">modelName</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;AUC = </span><span class="si">{</span><span class="n">aucTest</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1"> [</span><span class="si">{</span><span class="n">modelName</span><span class="si">}</span><span class="s1">]&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AUC = 0.9696 [SVC]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yTestPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">xTest</span><span class="p">)</span>
<span class="n">aucTest</span> <span class="o">=</span> <span class="n">AUC</span><span class="p">(</span><span class="n">yTest</span><span class="p">,</span> <span class="n">yTestPred</span><span class="p">)</span>
<span class="n">modelName</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;AUC = </span><span class="si">{</span><span class="n">aucTest</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1"> [</span><span class="si">{</span><span class="n">modelName</span><span class="si">}</span><span class="s1">]&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AUC = 0.9696 [SVC]
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "hungpq7/tabular-book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./06-machine-learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="sklearn-machine-learning.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Sklearn: Machine Learning</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="sklearn-regression.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Sklearn: Regression</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Quang Hung &#9829; Thuy Linh<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>