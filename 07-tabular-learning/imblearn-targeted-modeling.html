
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Imblearn: Targeted Modeling</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="8. Time Series" href="../08-time-series/_intro.html" />
    <link rel="prev" title="Shap: Model Interpretation" href="shap-model-interpretation.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.svg" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../util/intro.html">
                    Data Science
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01-python-programing/_intro.html">
   <b>
    1. Python Programing
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-basic-concepts.html">
     Python: Basic Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-data-types.html">
     Python: Data Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-data-containers.html">
     Python: Data Containers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-functions-objects.html">
     Python: Functions and Objects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-algorithms.html">
     (w) Python: Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/python-external-sources.html">
     Python: External Sources
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-python-programing/selenium-web-scraping.html">
     Selenium: Web Scraping
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02-mathematics/_intro.html">
   <b>
    2. Mathematics
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/numpy-linear-algebra.html">
     NumPy: Linear Algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/sympy-calculus.html">
     SymPy: Calculus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/numpy-probability.html">
     NumPy: Probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/numpy-statistics.html">
     NumPy: Statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/scipy-hypothesis-testing.html">
     SciPy: Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/numpy-applied-mathematics.html">
     (w) NumPy: Applied Mathematics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-mathematics/networkx-network-analysis.html">
     (w) NetworkX: Network Analysis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03-data-manipulation/_intro.html">
   <b>
    3. Data Manipulation
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/numpy-arrays.html">
     NumPy: Arrays
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/pandas-data-exploratory.html">
     Pandas: Data Exploratory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/pandas-data-cleaning.html">
     Pandas: Data Cleaning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/pandas-data-transformation.html">
     Pandas: Data Transformation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-data-manipulation/janitor-pandas-extensions.html">
     Janitor: Pandas Extensions
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04-big-data/_intro.html">
   <b>
    4. Big Data
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/hiveql-data-manipulation.html">
     HiveQL: Data Manipulation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/pyspark-data-exploratory.html">
     PySpark: Data Exploratory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/pyspark-data-cleaning.html">
     PySpark: Data Cleaning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/pyspark-data-transformation.html">
     PySpark: Data Transformation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-big-data/dask-parallelized-pandas.html">
     Dask: Parallelized Pandas
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../05-data-visualization/_intro.html">
   <b>
    5. Data Visualization
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-data-visualization/matplotlib-graph-construction.html">
     Matplotlib: Graph Construction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-data-visualization/seaborn-statistical-visualization.html">
     Seaborn: Statistical Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-data-visualization/plotly-interactive-visualization.html">
     Plotly: Interactive Visualization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../06-machine-learning/_intro.html">
   <b>
    6. Machine Learning
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-machine-learning/sklearn-machine-learning.html">
     Sklearn: Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-machine-learning/sklearn-classification.html">
     Sklearn: Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-machine-learning/sklearn-regression.html">
     Sklearn: Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-machine-learning/sklearn-feature-engineering.html">
     Featuretools: Feature Engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-machine-learning/lenskit-recommendation.html">
     Lenskit: Recommendation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-machine-learning/pyspark-machine-learning.html">
     PySpark: Machine Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="_intro.html">
   <b>
    7. Tabular Learning
   </b>
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="sklearn-ensemble-learning.html">
     Sklearn: Ensemble Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="xgboost-tree-boosting.html">
     XGBoost: Tree Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ray-hyperparameter-optimization.html">
     Ray: Hyperparam Optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="shap-model-interpretation.html">
     Shap: Model Interpretation
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Imblearn: Targeted Modeling
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../08-time-series/_intro.html">
   <b>
    8. Time Series
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-time-series/statsmodels-temporal-analysis.html">
     Statsmodels: Temporal Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-time-series/prophet-forecasting-algorithms.html">
     Prophet: Forecasting Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-time-series/sktime-forecasting-pipeline.html">
     Sktime: Forecasting Pipeline
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08-time-series/darts-deep-forecasting.html">
     Darts: Deep Forecasting
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../09-unsupervised-learning/_intro.html">
   <b>
    9. Unsupervised Learning
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-unsupervised-learning/mlxtend-association-rules.html">
     (w) MLxtend: Association Rules
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-unsupervised-learning/sklearn-clustering.html">
     Sklearn: Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-unsupervised-learning/sklearn-dimensional-reduction.html">
     Sklearn: Dimensional Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-unsupervised-learning/pyod-anomaly-detection.html">
     PyOD: Anomaly Detection
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../10-deep-learning/_intro.html">
   <b>
    10. Deep Learning
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/gensim-text-mining.html">
     Gensim: Text Mining
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/opencv-image-processing.html">
     (w) OpenCV: Image Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/numpy-gradient-descent.html">
     Python: Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/keras-multilayer-perceptron.html">
     Keras: Multilayer Perceptron
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/keras-recurrent-networks.html">
     Keras: Recurrent Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/keras-convolutional-networks.html">
     (w) Keras: Convolutional Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/pytorch-deep-learning.html">
     PyTorch: Deep Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-learning/transformers-transfer-learning.html">
     (w) Transformers: Transfer Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../11-r-programing/_intro.html">
   <b>
    11. R Programing
   </b>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/r-basic-concepts.html">
     R: Basic Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/r-data-structures.html">
     R: Data Structures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/tidyverse-data-wrangling.html">
     Tidyverse: Data Wrangling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/dplyr-data-cleaning.html">
     Dplyr: Data Cleaning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/ggplot-data-visualization.html">
     Ggplot: Data Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-r-programing/r-statistics.html">
     R: Statistics
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/hungpq7/tabular-book/master?urlpath=lab/tree/07-tabular-learning/imblearn-targeted-modeling.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/hungpq7/tabular-book/blob/master/07-tabular-learning/imblearn-targeted-modeling.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/hungpq7/tabular-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/07-tabular-learning/imblearn-targeted-modeling.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imbalanced-learning">
   1. Imbalanced learning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accuracy-analysis">
     1.1. Accuracy analysis
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#precision-recall">
       Precision-Recall
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cumulative-gains">
       Cumulative gains
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#class-weighting">
       Class weighting
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#focal-loss">
     1.2. Focal loss
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#hyperparameters">
       Hyperparameters
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#implementation">
       Implementation
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#under-sampling">
     1.3. Under-sampling
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#controlled-methods">
       Controlled methods
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cleaning-methods">
       Cleaning methods
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#over-sampling">
     1.4. Over-sampling
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#synthetic-minority">
       Synthetic minority
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#smote-variants">
       SMOTE variants
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#smote-combinations">
       SMOTE combinations
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#implementation-imblearn">
     1.5. Implementation: Imblearn
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#uplift-modeling">
   2. Uplift modeling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#learning-to-rank">
   3. Learning to rank
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#approaches">
     3.1. Approaches
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluation">
     3.2. Evaluation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     3.3. Implementation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resources">
   Resources
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Imblearn: Targeted Modeling</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imbalanced-learning">
   1. Imbalanced learning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accuracy-analysis">
     1.1. Accuracy analysis
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#precision-recall">
       Precision-Recall
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cumulative-gains">
       Cumulative gains
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#class-weighting">
       Class weighting
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#focal-loss">
     1.2. Focal loss
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#hyperparameters">
       Hyperparameters
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#implementation">
       Implementation
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#under-sampling">
     1.3. Under-sampling
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#controlled-methods">
       Controlled methods
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cleaning-methods">
       Cleaning methods
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#over-sampling">
     1.4. Over-sampling
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#synthetic-minority">
       Synthetic minority
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#smote-variants">
       SMOTE variants
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#smote-combinations">
       SMOTE combinations
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#implementation-imblearn">
     1.5. Implementation: Imblearn
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#uplift-modeling">
   2. Uplift modeling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#learning-to-rank">
   3. Learning to rank
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#approaches">
     3.1. Approaches
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluation">
     3.2. Evaluation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     3.3. Implementation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resources">
   Resources
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="imblearn-targeted-modeling">
<h1>Imblearn: Targeted Modeling<a class="headerlink" href="#imblearn-targeted-modeling" title="Permalink to this headline">#</a></h1>
<section id="imbalanced-learning">
<h2>1. Imbalanced learning<a class="headerlink" href="#imbalanced-learning" title="Permalink to this headline">#</a></h2>
<p>A common phenomenom in classification is imbalance data, it refers to the situation that a class has too few data and our Machine Learning model cannot put focus to learn it. This phenomenom exists in all types of classification problems, but we will focus only on solving it in <em>binary classification</em>. In real-world problems, often times there will be a class being more important than the other but contains only a small fraction of data. For convention, we will denote this class <span class="math notranslate nohighlight">\(1\)</span> and the other <span class="math notranslate nohighlight">\(0\)</span>.</p>
<p>In this section, we will introduce three approaches to fight this challenge: class weighting, using focal loss and resampling, but will focus on the last method using <a class="reference external" href="https://github.com/scikit-learn-contrib/imbalanced-learn">Imbalanced-learn</a>. Resampling is divided into over/up-sampling and under/down-sampling as described in the following image.</p>
<a class="reference internal image-reference" href="../_images/resampling.png"><img alt="../_images/resampling.png" class="align-center" src="../_images/resampling.png" style="height: 160px;" /></a>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Any method solving imbalanced data causes data leakage.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">imblearn</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">lightgbm</span> <span class="k">as</span> <span class="nn">lgb</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>

<span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">LGBMClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">ndcg_score</span> <span class="k">as</span> <span class="n">NDCG</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_score</span> <span class="k">as</span> <span class="n">Precision</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">recall_score</span> <span class="k">as</span> <span class="n">Recall</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">fbeta_score</span> <span class="k">as</span> <span class="n">FBeta</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span> <span class="k">as</span> <span class="n">AUC</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;seaborn&#39;</span><span class="p">,</span> <span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">])</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
</pre></div>
</div>
</div>
</div>
<section id="accuracy-analysis">
<h3>1.1. Accuracy analysis<a class="headerlink" href="#accuracy-analysis" title="Permalink to this headline">#</a></h3>
<section id="precision-recall">
<h4>Precision-Recall<a class="headerlink" href="#precision-recall" title="Permalink to this headline">#</a></h4>
<p>When analyzing the performance of a binary classifier, we usually care about Precision or Recall more than the other. To remind, a <span class="math notranslate nohighlight">\(0.65\)</span> Precision indicates <span class="math notranslate nohighlight">\(35\%\)</span> users predicted as good are actually bad, and a Recall of <span class="math notranslate nohighlight">\(0.2\)</span> indicates <span class="math notranslate nohighlight">\(80\%\)</span> good users are predicted as bad. Here is an example of Precision-Recall analysis for a typical case, targeted marketing:</p>
<ul class="simple">
<li><p>We don’t want to miss any user that actually likes our products. In Machine Learning language, we would want False Negative to be as low as possible, which is equivalent to high Recall.</p></li>
<li><p>On the other hand, we also don’t want to sent irrelevant messages to non-promising users (False Positive), because this will spam them and waste our budget. So, Precision should also be high, but not that important when compared to Recall.</p></li>
</ul>
<p>According to the above analyses, an F-beta score with <span class="math notranslate nohighlight">\(\beta&gt;1\)</span> (which favors Recall) will be a good evaluation metric. In addition, Precision and Recall (and of couse, F-score) vary at different thresholds, so we use the Precision-Recall chart to decide the best theshold.</p>
</section>
<section id="cumulative-gains">
<h4>Cumulative gains<a class="headerlink" href="#cumulative-gains" title="Permalink to this headline">#</a></h4>
<p>The downside of Precision-Recall analyses is that it considers the entire dataset, while our resources (such as time and money) are limited, so caring about how the model distributes its probabilitic predictions is more practical. This is exactly what cumulative gains shows us; a good model commonly gains a high ratio of good users at the three first deciles.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plotPRChart</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yProb</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yProb</span><span class="p">)</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">precision</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="n">recall</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(([</span><span class="mi">0</span><span class="p">],</span> <span class="n">threshold</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(([</span><span class="mi">0</span><span class="p">],</span> <span class="n">precision</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(([</span><span class="mi">1</span><span class="p">],</span> <span class="n">recall</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">if</span> <span class="n">beta</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fbeta</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">beta</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">precision</span> <span class="o">+</span> <span class="n">beta</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">beta</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">recall</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Precision&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Recall&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="n">fbeta</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;F-beta&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Threshold&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Score&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;scaled&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ax</span>

<span class="k">def</span> <span class="nf">plotCumulativeGains</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yProb</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">dfProb</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;yTrue&#39;</span><span class="p">:</span> <span class="n">yTrue</span><span class="p">,</span> <span class="s1">&#39;yProb&#39;</span><span class="p">:</span> <span class="n">yProb</span><span class="p">})</span>
    <span class="n">dfProb</span> <span class="o">=</span> <span class="n">dfProb</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;yProb&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">dfProb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">nPositive</span> <span class="o">=</span> <span class="n">dfProb</span><span class="p">[</span><span class="n">dfProb</span><span class="o">.</span><span class="n">yTrue</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="n">deciles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
    <span class="n">gains</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">decile</span> <span class="ow">in</span> <span class="n">deciles</span><span class="p">:</span>
        <span class="n">nVisit</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">decile</span><span class="p">)</span>
        <span class="n">dfGain</span> <span class="o">=</span> <span class="n">dfProb</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">nVisit</span><span class="p">)</span>
        <span class="n">nGainPositive</span> <span class="o">=</span> <span class="n">dfGain</span><span class="p">[</span><span class="n">dfGain</span><span class="o">.</span><span class="n">yTrue</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">gain</span> <span class="o">=</span> <span class="n">nGainPositive</span> <span class="o">/</span> <span class="n">nPositive</span>
        <span class="n">gains</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gain</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">deciles</span><span class="p">,</span> <span class="n">gains</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Baseline&#39;</span><span class="p">,</span> <span class="s1">&#39;Gains&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Deciles&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Gains&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;scaled&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ax</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/credit_scoring.csv&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;bad_customer&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;bad_customer&#39;</span><span class="p">]</span>
<span class="n">y</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    139974
1     10026
Name: bad_customer, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LGBMClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">yPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">yProb</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">auc</span> <span class="o">=</span> <span class="n">AUC</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yProb</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plotPRChart</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yProb</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">beta</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plotCumulativeGains</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yProb</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/imblearn-targeted-modeling_10_0.png"><img alt="../_images/imblearn-targeted-modeling_10_0.png" class="align-center" src="../_images/imblearn-targeted-modeling_10_0.png" style="width: 655.5px; height: 352.5px;" /></a>
</div>
</div>
</section>
<section id="class-weighting">
<h4>Class weighting<a class="headerlink" href="#class-weighting" title="Permalink to this headline">#</a></h4>
<p>When train a LightGBM classifier as above, a threshold of <span class="math notranslate nohighlight">\(0.5\)</span> witnesses a higher Recall. This behaviour can be controlled by assigning a higher weight to the minority class. Most Scikit-learn’s classifiers support this method via the parameter <code class="docutils literal notranslate"><span class="pre">class_weight</span></code>. We can see how this strategy impacts PR-chart: the range of thresholds providing a high F-score is wider than balanced class weights.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">yPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">yProb</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">auc</span> <span class="o">=</span> <span class="n">AUC</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yProb</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plotPRChart</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yProb</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">beta</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plotCumulativeGains</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yProb</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/imblearn-targeted-modeling_13_0.png"><img alt="../_images/imblearn-targeted-modeling_13_0.png" class="align-center" src="../_images/imblearn-targeted-modeling_13_0.png" style="width: 655.5px; height: 352.5px;" /></a>
</div>
</div>
</section>
</section>
<section id="focal-loss">
<h3>1.2. Focal loss<a class="headerlink" href="#focal-loss" title="Permalink to this headline">#</a></h3>
<p><a class="reference external" href="https://arxiv.org/pdf/1708.02002.pdf">Focal Loss</a> is a variant of Cross Entropy (CE) that prevents the majority class from overwhelmeing the loss function. It has two hyperparameters: <span class="math notranslate nohighlight">\(\alpha\in[0,1]\)</span>, the <em>balance</em> parameter and <span class="math notranslate nohighlight">\(\gamma\in[0,\infty]\)</span>, the <em>focusing</em> parameter. Before going to the Focal Loss formula, we first introduce two artificial variables <span class="math notranslate nohighlight">\(p_n\)</span> and <span class="math notranslate nohighlight">\(\alpha_n\)</span> defined same way:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
p_n=
\begin{cases}
\hat{y}_n   &amp; \text{if }y_n=1 \\
1-\hat{y}_n &amp; \text{if }y_n=0
\end{cases}
\quad\text{and}\quad
\alpha_n=
\begin{cases}
\alpha   &amp; \text{if }y_n=1 \\
1-\alpha &amp; \text{if }y_n=0
\end{cases}
\end{split}\]</div>
<a class="reference internal image-reference" href="../_images/crossentropy_prediction_goodness.png"><img alt="../_images/crossentropy_prediction_goodness.png" class="align-center" src="../_images/crossentropy_prediction_goodness.png" style="height: 250px;" /></a>
<br>
<p>Here, <span class="math notranslate nohighlight">\(p_n\)</span> represents prediction goodness (higher-is-better) and <span class="math notranslate nohighlight">\(\alpha_n\)</span> is simple class weight. The formula of Focal Loss (FL) is then given by:</p>
<div class="math notranslate nohighlight">
\[\text{FL}(\hat{\mathbf{y}})=-\sum_{n=1}^N \alpha_n(1-p_n)^\gamma\log{p_n}\]</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">xPlot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">yPlot</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">xPlot</span><span class="p">)</span>

<span class="n">xPos</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">xNeg</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">tight_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xPlot</span><span class="p">,</span> <span class="n">yPlot</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Logit (Log-odds)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;$\hat</span><span class="si">{y}</span><span class="s1">_n$, predicted probability&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">xPos</span><span class="p">):</span>
    <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Positive&#39;</span> <span class="k">if</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x_</span><span class="p">,</span> <span class="n">x_</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">func</span><span class="p">(</span><span class="n">x_</span><span class="p">)],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;royalblue&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">xNeg</span><span class="p">):</span>
    <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Negative&#39;</span> <span class="k">if</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x_</span><span class="p">,</span> <span class="n">x_</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">func</span><span class="p">(</span><span class="n">x_</span><span class="p">)],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;indianred&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xPlot</span><span class="p">,</span> <span class="n">yPlot</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Logit (Log-odds)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;$p_n$, prediction goodness&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">xPos</span><span class="p">):</span>
    <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Positive&#39;</span> <span class="k">if</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x_</span><span class="p">,</span> <span class="n">x_</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">func</span><span class="p">(</span><span class="n">x_</span><span class="p">)],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;royalblue&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">xNeg</span><span class="p">):</span>
    <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Negative&#39;</span> <span class="k">if</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x_</span><span class="p">,</span> <span class="n">x_</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">func</span><span class="p">(</span><span class="n">x_</span><span class="p">)],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;indianred&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;../output/crossentropy_prediction_goodness.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="hyperparameters">
<h4>Hyperparameters<a class="headerlink" href="#hyperparameters" title="Permalink to this headline">#</a></h4>
<p>In an imbalanced classification problem, the majority class dominates the loss function. This makes the the majority class easier to learn, thus <span class="math notranslate nohighlight">\(p_n\)</span> in this class tends to be higher than in the minority class. We can see the impact of the term <span class="math notranslate nohighlight">\((1-p_n)^\gamma\)</span> here, it gives smaller weights to those <em>easy</em> predictions which are mostly in the negative class. This design, in my opinion, is very smart as it only <em>discards</em> the unimportant part but leaves the important part of the negative class to train the next iteration.</p>
<a class="reference internal image-reference" href="../_images/imbalanced_probability_distribution.png"><img alt="../_images/imbalanced_probability_distribution.png" class="align-center" src="../_images/imbalanced_probability_distribution.png" style="height: 250px;" /></a>
<p>In summary:</p>
<ul class="simple">
<li><p>The <em>focusing</em> parameter, <span class="math notranslate nohighlight">\(\gamma\)</span> shows how strong we punish easy predictions. It is recommended by the author to be <span class="math notranslate nohighlight">\(2\)</span>, otherwise it should be tuned within the range <span class="math notranslate nohighlight">\([0.5,5]\)</span>.</p></li>
<li><p>The <em>balance</em> parameter, <span class="math notranslate nohighlight">\(\alpha\)</span> simply indicates the weight of the positive class. Although <span class="math notranslate nohighlight">\(\alpha&lt;0.5\)</span> favors the negative class, the recommended value for it is <span class="math notranslate nohighlight">\(0.25\)</span>. This can be explained that most of the focusing effect of this function comes from <span class="math notranslate nohighlight">\(\gamma\)</span>, and since it already favors class <span class="math notranslate nohighlight">\(1\)</span>, a low <span class="math notranslate nohighlight">\(\alpha\)</span> will compensate that a bit. In the case you want to tune this parameter, it should be set within the range <span class="math notranslate nohighlight">\([0.25,0.75]\)</span>.</p></li>
</ul>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/credit_scoring.csv&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;bad_customer&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;bad_customer&#39;</span><span class="p">]</span>
<span class="n">y</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LGBMClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">yPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">p1</span> <span class="o">=</span> <span class="n">yPred</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">p0</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">yPred</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">tight_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkred&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Negative/Majority class ($y_n=0$)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Bin density&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$p_n$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Positive/Minority class ($y_n=1$)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$p_n$&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;../output/imbalanced_probability_distribution.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <span class="math notranslate nohighlight">\(\alpha\)</span> is used standalone (known as the Balanced Cross Entropy), then it should be <span class="math notranslate nohighlight">\(&gt;0.5\)</span>.</p>
</div>
</section>
<section id="implementation">
<h4>Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline">#</a></h4>
<p>We are going to use Focal Loss as a custom loss function in tree boosting algorithms. Keep in mind two important properties of these algorithms: (1) they require us to provide both gradient and hessian of the loss function with respect to the predicted value and (2) they predict <a class="reference external" href="https://en.wikipedia.org/wiki/Logit">logits</a> then turn into probability using <a class="reference external" href="https://en.wikipedia.org/wiki/Logistic_function">logistic function</a>. With these information, we need to calculate the first and second order derivatives of Focal Loss with respect to the logit (let’s denote it <span class="math notranslate nohighlight">\(z_n\)</span>). Note that Focal Loss as well as Cross Entropy is usually formulated using <span class="math notranslate nohighlight">\(\hat{y}_n\)</span> or <span class="math notranslate nohighlight">\(p_n\)</span>, so the first derivative will be obtained using the chain rule:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\frac{\partial\mathcal{L}}{\partial z_n}
&amp;= \frac{\partial\mathcal{L}}{\partial p_n}\times\frac{\partial p_n}{\partial\hat{y}_n}\times\frac{\partial\hat{y}_n}{\partial z_n} \\
&amp;= \alpha_n y_n(1-p_n)^\gamma(\gamma p_n\log{p_n}+p_n-1)
\end{aligned}\end{split}\]</div>
<p>We skip the derivation because it is quite complicated. Similary, we compute the hessian as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\frac{\partial^2\mathcal{L}}{\partial z_n^2}
&amp;= \frac{\partial}{\partial z_n}\left( \frac{\partial\mathcal{L}}{\partial z_n} \right) \\
&amp;= \frac{\partial}{\partial p_n}\left( \frac{\partial\mathcal{L}}{\partial z_n} \right)
   \times\frac{\partial p_n}{\partial\hat{y}_n}
   \times\frac{\partial\hat{y}_n}{\partial z_n} \\
&amp;= \left( \frac{\partial{u}}{\partial{p_n}}\times{v}+\frac{\partial{v}}{\partial{p_n}}\times{u} \right)y_np_n(1-p_n)
\end{aligned}\end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
u=\alpha_ny_n(1-p_n)^\gamma \quad&amp;;\quad
v=\gamma p_n\log{p_n}+p_n-1 \\
\frac{\partial{u}}{\partial{p_n}}=-\gamma\alpha_n y_n(1-p_n)^{\gamma-1} \quad&amp;;\quad
\frac{\partial{v}}{\partial{p_n}}=\gamma\log{p_n}+\gamma+1
\end{aligned}\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/credit_scoring.csv&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;bad_customer&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;bad_customer&#39;</span><span class="p">]</span>
<span class="n">y</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    139974
1     10026
Name: bad_customer, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">optimize</span><span class="p">,</span> <span class="n">special</span>

<span class="k">class</span> <span class="nc">FocalLoss</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>

    <span class="k">def</span> <span class="nf">at</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">pt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="mf">1e-15</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="mf">1e-15</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">yTrue</span><span class="p">,</span> <span class="n">yPred</span><span class="p">):</span>
        <span class="n">at</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">yTrue</span><span class="p">)</span>
        <span class="n">pt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pt</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yPred</span><span class="p">)</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">at</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pt</span><span class="p">)</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pt</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">yTrue</span><span class="p">,</span> <span class="n">yPred</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">yTrue</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># {0, 1} -&gt; {-1, 1}</span>
        <span class="n">at</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">yTrue</span><span class="p">)</span>
        <span class="n">pt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pt</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yPred</span><span class="p">)</span>
        <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span>
        <span class="k">return</span> <span class="n">at</span> <span class="o">*</span> <span class="n">y</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pt</span><span class="p">)</span> <span class="o">**</span> <span class="n">g</span> <span class="o">*</span> <span class="p">(</span><span class="n">g</span> <span class="o">*</span> <span class="n">pt</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pt</span><span class="p">)</span> <span class="o">+</span> <span class="n">pt</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">hess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">yTrue</span><span class="p">,</span> <span class="n">yPred</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">yTrue</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># {0, 1} -&gt; {-1, 1}</span>
        <span class="n">at</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">yTrue</span><span class="p">)</span>
        <span class="n">pt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pt</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">yPred</span><span class="p">)</span>
        <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span>

        <span class="n">u</span> <span class="o">=</span> <span class="n">at</span> <span class="o">*</span> <span class="n">y</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pt</span><span class="p">)</span> <span class="o">**</span> <span class="n">g</span>
        <span class="n">du</span> <span class="o">=</span> <span class="o">-</span><span class="n">at</span> <span class="o">*</span> <span class="n">y</span> <span class="o">*</span> <span class="n">g</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pt</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="n">g</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">g</span> <span class="o">*</span> <span class="n">pt</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pt</span><span class="p">)</span> <span class="o">+</span> <span class="n">pt</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">dv</span> <span class="o">=</span> <span class="n">g</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pt</span><span class="p">)</span> <span class="o">+</span> <span class="n">g</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">du</span> <span class="o">*</span> <span class="n">v</span> <span class="o">+</span> <span class="n">u</span> <span class="o">*</span> <span class="n">dv</span><span class="p">)</span> <span class="o">*</span> <span class="n">y</span> <span class="o">*</span> <span class="p">(</span><span class="n">pt</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pt</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">init_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">yTrue</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">minimize_scalar</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="bp">self</span><span class="p">(</span><span class="n">yTrue</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
            <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">method</span><span class="o">=</span><span class="s1">&#39;bounded&#39;</span>
        <span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span>
        <span class="n">log_odds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">log_odds</span>

    <span class="k">def</span> <span class="nf">lgb_obj</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">train_data</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">get_label</span><span class="p">()</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">expit</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">hess</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">lgb_eval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">train_data</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">get_label</span><span class="p">()</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">expit</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
        <span class="n">is_higher_better</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="s1">&#39;focal_loss&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">is_higher_better</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fl</span> <span class="o">=</span> <span class="n">FocalLoss</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">init_score</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">fl</span><span class="o">.</span><span class="n">init_score</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">train_set</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">fobj</span><span class="o">=</span><span class="n">fl</span><span class="o">.</span><span class="n">lgb_obj</span><span class="p">)</span>
<span class="n">yProb</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">expit</span><span class="p">(</span><span class="n">fl</span><span class="o">.</span><span class="n">init_score</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span>

<span class="n">auc</span> <span class="o">=</span> <span class="n">AUC</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yProb</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plotPRChart</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yProb</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">beta</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plotCumulativeGains</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yProb</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/imblearn-targeted-modeling_23_0.png"><img alt="../_images/imblearn-targeted-modeling_23_0.png" class="align-center" src="../_images/imblearn-targeted-modeling_23_0.png" style="width: 655.5px; height: 352.5px;" /></a>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fl</span> <span class="o">=</span> <span class="n">FocalLoss</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="p">{},</span> <span class="n">dtrain</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="n">fl</span><span class="o">.</span><span class="n">lgb_obj</span><span class="p">)</span>
<span class="n">yProb</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">expit</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">d</span><span class="p">)</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span>

<span class="n">auc</span> <span class="o">=</span> <span class="n">AUC</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yProb</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plotPRChart</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yProb</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">beta</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plotCumulativeGains</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">yProb</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/imblearn-targeted-modeling_24_0.png"><img alt="../_images/imblearn-targeted-modeling_24_0.png" class="align-center" src="../_images/imblearn-targeted-modeling_24_0.png" style="width: 655.5px; height: 352.5px;" /></a>
</div>
</div>
</section>
</section>
<section id="under-sampling">
<h3>1.3. Under-sampling<a class="headerlink" href="#under-sampling" title="Permalink to this headline">#</a></h3>
<p>Let’s say a binary labeled dataset has <span class="math notranslate nohighlight">\(N_0\)</span> negative samples and <span class="math notranslate nohighlight">\(N_1\)</span> positive samples (with <span class="math notranslate nohighlight">\(N_0\gg N_1\)</span>). <a class="reference external" href="https://imbalanced-learn.org/stable/under_sampling.html#prototype-selection">Under-sampling</a> is the process of reducing the majority class until there are <span class="math notranslate nohighlight">\(N_0^*\)</span> negative samples left. This method is helpful for large datasets, but can accidentally drop informative data.</p>
<p>The rest of this section presents several down-sampling algorithm provided by Imbalanced-learn, which mainly differ in how they determine points to remove. They are divided into two groups: <em>controlled</em> techniques allowing us to specify how much data to remove, and <em>cleaning</em> techniques being <a class="reference external" href="https://en.wikipedia.org/wiki/Heuristic">heuristics</a> for data cleaning.</p>
<section id="controlled-methods">
<h4>Controlled methods<a class="headerlink" href="#controlled-methods" title="Permalink to this headline">#</a></h4>
<p>All techniques in this group require us to provide <code class="docutils literal notranslate"><span class="pre">sampling_strategy</span></code>, which is usually set to a number indicating the desired class ratio, <span class="math notranslate nohighlight">\(N_1/N_0^*\)</span>. We can use either the basic <a class="reference external" href="https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html"><code class="docutils literal notranslate"><span class="pre">RandomUnderSampler</span></code></a>, or the more advanced <a class="reference external" href="https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.NearMiss.html"><code class="docutils literal notranslate"><span class="pre">NearMiss</span></code></a> which removes furthest negative samples from the positive class. With a pre-selected value of <span class="math notranslate nohighlight">\(K\)</span>, NearMiss has three variants presented as follows:</p>
<ul class="simple">
<li><p>NearMiss-1 keeps negative samples with the smallest average distance to <span class="math notranslate nohighlight">\(K\)</span> nearest positive samples.</p></li>
<li><p>NearMiss-2 keeps negative samples with the smallest average distance to <span class="math notranslate nohighlight">\(K\)</span> furthest positive samples.</p></li>
<li><p>NearMiss-3 first keeps several nearest negative samples to each positive sample and then keeps negative samples with the largest average distance to <span class="math notranslate nohighlight">\(K\)</span> nearest positive samples. This version is considered less affected by outlier and is thus the most efficient, according to the authors.</p></li>
</ul>
</section>
<section id="cleaning-methods">
<h4>Cleaning methods<a class="headerlink" href="#cleaning-methods" title="Permalink to this headline">#</a></h4>
<p>As introduced earlier, cleaning methods don’t use the desired class ratio, thus the parameter <code class="docutils literal notranslate"><span class="pre">sampling_strategy</span></code> should be left alone. There are mainly three algorithms in this group:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.TomekLinks.html"><code class="docutils literal notranslate"><span class="pre">TomekLinks</span></code></a> detects and removes any negative sample having the nearest neighbor falling into the minority class. Such a connection is called a Tomek link.</p></li>
<li><p><a class="reference external" href="https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.CondensedNearestNeighbour.html"><code class="docutils literal notranslate"><span class="pre">CondensedNearestNeighbour</span></code></a> uses 1-NN rule to interatively determine whether to keep a negative sample. Low execution time but is sensitive to noise.</p></li>
<li><p><a class="reference external" href="https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.EditedNearestNeighbours.html"><code class="docutils literal notranslate"><span class="pre">EditedNearestNeighbours</span></code></a> trains a K-NN classifier and removes any sample which doesn’t <em>agree enough</em> with its neighbors. There are two dropping strategies available (set via the <code class="docutils literal notranslate"><span class="pre">kind_sel</span></code> parameter): <code class="docutils literal notranslate"><span class="pre">mode</span></code> keeps an inspected point if at least <span class="math notranslate nohighlight">\(50\%\)</span> neighbors are in the same class with it, and <code class="docutils literal notranslate"><span class="pre">all</span></code> keeps an inspected point if only all <span class="math notranslate nohighlight">\(100\%\)</span> neighbors agree with it. The later is more aggressive and is the default.</p></li>
</ul>
</section>
</section>
<section id="over-sampling">
<h3>1.4. Over-sampling<a class="headerlink" href="#over-sampling" title="Permalink to this headline">#</a></h3>
<p>Let’s say a binary labeled dataset has <span class="math notranslate nohighlight">\(N_0\)</span> negative samples and <span class="math notranslate nohighlight">\(N_1\)</span> positive samples (with <span class="math notranslate nohighlight">\(N_0\gg N_1\)</span>). Over-sampling is the process of generating new observations for the minority class, so it will end up having <span class="math notranslate nohighlight">\(N_1^*\)</span> samples. You can try a <a class="reference external" href="https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html"><code class="docutils literal notranslate"><span class="pre">RandomOverSampler</span></code></a> or another advanced method that intentionally creates <em>synthetic data</em>, which will be introduced in this section. All over-sampling algorithms require the parameter <code class="docutils literal notranslate"><span class="pre">sampling_strategy</span></code>, which is usually set to a number indicating the desired class ratio, <span class="math notranslate nohighlight">\(N_1^*/N_0\)</span>. There are some disadvantages of over-sampling you should be aware of:</p>
<ul class="simple">
<li><p>causing data leakage</p></li>
<li><p>slowing down training</p></li>
<li><p>adding incorrect information that hurts model performance</p></li>
</ul>
<section id="synthetic-minority">
<h4>Synthetic minority<a class="headerlink" href="#synthetic-minority" title="Permalink to this headline">#</a></h4>
<p><a class="reference external" href="https://arxiv.org/pdf/1106.1813.pdf">Synthetic Minority Oversampling Techique</a> (SMOTE) create new data using a very simple mechanism: the clone of a data point moves towards a neighbor that belongs to the same class. You can also think of this process as drawing a line between a point and one of its neighbor, then pick a new point somewhere on that line.</p>
<a class="reference internal image-reference" href="../_images/smote.png"><img alt="../_images/smote.png" class="align-center" src="../_images/smote.png" style="height: 300px;" /></a>
<p>Formally, denote <span class="math notranslate nohighlight">\(\mathbf{s}_n\)</span> a data point of the minority class. Among its <span class="math notranslate nohighlight">\(K\)</span> <em>same-class</em> nearest neighbors, randomly select a point <span class="math notranslate nohighlight">\(\mathbf{s}_k\)</span> and a number <span class="math notranslate nohighlight">\(\lambda\in(0,1)\)</span>. A clone of <span class="math notranslate nohighlight">\(\mathbf{s}_n\)</span> will be created using the formula:</p>
<div class="math notranslate nohighlight">
\[\mathbf{s}_n+\lambda(\mathbf{s}_k-\mathbf{s}_n)\]</div>
<p>In SMOTE, the number of points to be synthesized are uniformally allocated to each sample in the minority class. In other words, each member of class <span class="math notranslate nohighlight">\(1\)</span> will be cloned <span class="math notranslate nohighlight">\(N_1^*/N_1-1\)</span> times. Also note that each clone is created with another value of <span class="math notranslate nohighlight">\(\lambda\)</span>.</p>
</section>
<section id="smote-variants">
<h4>SMOTE variants<a class="headerlink" href="#smote-variants" title="Permalink to this headline">#</a></h4>
<p>Imbalanced-learn provides several SMOTE variants as well:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.BorderlineSMOTE.html"><code class="docutils literal notranslate"><span class="pre">BorderlineSMOTE</span></code></a>, which creates clones only from <em>borderline points</em> instead of from all positive samples. A borderline point is defined as a positive sample having more than a half of its neighbors belong to the negative class. This improvement bases on the design of many Machine Learning algorithms that attemp to learn the borderlines between classes, making borderline points easily misclassified. The impact of this algorithm can be thought as highlighting grey zones, so that prediction accuracy can be boosted a bit.</p></li>
<li><p><a class="reference external" href="https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SVMSMOTE.html"><code class="docutils literal notranslate"><span class="pre">SVMSMOTE</span></code></a> is proposed based on the same idea as Borderline SMOTE, where support vectors of the positive class serve the same role as borderline points. If less than a half of <span class="math notranslate nohighlight">\(K\)</span> neighbors of a point are of the majority class, then synthetic point will be created outside of the segment connnecting two points by setting <span class="math notranslate nohighlight">\(\lambda&gt;1\)</span>.</p></li>
<li><p><a class="reference external" href="https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.KMeansSMOTE.html"><code class="docutils literal notranslate"><span class="pre">KMeansSMOTE</span></code></a> firstly uses K-Means to divide the dataset into clusters, then use any cluster with at least <span class="math notranslate nohighlight">\(50\%\)</span> positive samples will be used for cloning.</p></li>
<li><p><a class="reference external" href="https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.ADASYN.html"><code class="docutils literal notranslate"><span class="pre">ADASYN</span></code></a> (Adaptive Synthetic) works similarly to regular SMOTE, but the clones of each positive sample will be proportional to the number of negative points in its <span class="math notranslate nohighlight">\(K\)</span> nearest neighbors. The purpose of this is to generate more data in those regions with low density of the minority class.</p></li>
</ul>
</section>
<section id="smote-combinations">
<h4>SMOTE combinations<a class="headerlink" href="#smote-combinations" title="Permalink to this headline">#</a></h4>
<p>As SMOTE can generate noisy samples, it makes sense to use cleaning under-sampling techniques to clean up the output out SMOTE. Imbalanced-learn implements this idea via <a class="reference external" href="https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTETomek.html"><code class="docutils literal notranslate"><span class="pre">SMOTETomek</span></code></a> and <a class="reference external" href="https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTEENN.html"><code class="docutils literal notranslate"><span class="pre">SMOTEENN</span></code></a>.</p>
</section>
</section>
<section id="implementation-imblearn">
<h3>1.5. Implementation: Imblearn<a class="headerlink" href="#implementation-imblearn" title="Permalink to this headline">#</a></h3>
<p>All over-samplers share a general hyperparameter, <code class="docutils literal notranslate"><span class="pre">sampling_strategy</span></code>, which supports a number of strategies. However, as we are focusing on binary classification, a float should be passed in, indicating the desired ratio between size of positive class and size of negative class:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">LGBMClassifier</span>
<span class="kn">from</span> <span class="nn">imblearn.datasets</span> <span class="kn">import</span> <span class="n">make_imbalance</span>
<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span><span class="p">,</span> <span class="n">BorderlineSMOTE</span><span class="p">,</span> <span class="n">ADASYN</span>
<span class="kn">from</span> <span class="nn">imblearn.under_sampling</span> <span class="kn">import</span> <span class="n">NearMiss</span><span class="p">,</span> <span class="n">TomekLinks</span>
<span class="kn">from</span> <span class="nn">imblearn.combine</span> <span class="kn">import</span> <span class="n">SMOTEENN</span><span class="p">,</span> <span class="n">SMOTETomek</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;seaborn&#39;</span><span class="p">,</span> <span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">])</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/breast_cancer.csv&#39;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">xImb</span><span class="p">,</span> <span class="n">yImb</span> <span class="o">=</span> <span class="n">make_imbalance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sampling_strategy</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="mi">212</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">50</span><span class="p">})</span>
<span class="n">yImb</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    212
1     50
Name: target, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">listResampler</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">SMOTE</span><span class="p">()),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">ADASYN</span><span class="p">()),</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">NearMiss</span><span class="p">()),</span>
    <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">SMOTETomek</span><span class="p">()),</span>
<span class="p">]</span>

<span class="n">mosaic</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="p">]</span>

<span class="n">paramScatter</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Spectral&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">paramTick</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">bottom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">labelbottom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">labelleft</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot_mosaic</span><span class="p">(</span><span class="n">mosaic</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xImb</span><span class="o">.</span><span class="n">mean_radius</span><span class="p">,</span> <span class="n">xImb</span><span class="o">.</span><span class="n">mean_smoothness</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">yImb</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="o">**</span><span class="n">paramScatter</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Original data&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="o">**</span><span class="n">paramTick</span><span class="p">)</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">resampler</span> <span class="ow">in</span> <span class="n">listResampler</span><span class="p">:</span>
    <span class="n">xRes</span><span class="p">,</span> <span class="n">yRes</span> <span class="o">=</span> <span class="n">resampler</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">xImb</span><span class="p">,</span> <span class="n">yImb</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xRes</span><span class="o">.</span><span class="n">mean_radius</span><span class="p">,</span> <span class="n">xRes</span><span class="o">.</span><span class="n">mean_smoothness</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">yRes</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">paramScatter</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">resampler</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="o">**</span><span class="n">paramTick</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/imblearn-targeted-modeling_36_0.png" src="../_images/imblearn-targeted-modeling_36_0.png" />
</div>
</div>
</section>
</section>
<section id="uplift-modeling">
<h2>2. Uplift modeling<a class="headerlink" href="#uplift-modeling" title="Permalink to this headline">#</a></h2>
</section>
<section id="learning-to-rank">
<h2>3. Learning to rank<a class="headerlink" href="#learning-to-rank" title="Permalink to this headline">#</a></h2>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Learning_to_rank">Learning to rank</a>, or <em>ranking</em> in short, is a problem in <a class="reference external" href="https://en.wikipedia.org/wiki/Information_retrieval">Information Retrieval</a> with many applications such as recommendation systems and search engines. The problem’s goal is to <em>grade</em> a <em>document</em> given a <em>query</em>. This definition has covered a lot of terms, now let’s place them into a movie recommender to have better understanding.</p>
<ul class="simple">
<li><p>A <em>query</em> <span class="math notranslate nohighlight">\(q\)</span> represents a user who wants to see a list of interesting movies displayed at the home page. Can also be a user-movie pair, where the user wants to see relevent movies to the one he is watching.</p></li>
<li><p>A <em>document</em> <span class="math notranslate nohighlight">\(d\)</span> represents a movie to be introduced to the user.</p></li>
<li><p>A <em>relevance score</em> <span class="math notranslate nohighlight">\(y\)</span> is the grade we give to the movie with respect to the user. The scoring system is usually binary (relevant and non-relevant) or 5-level ordinal (excellent, good, normal, bad, terrible) and is integer-encoded with higher-is-better rule.</p></li>
</ul>
<p>In order to learn the scoring pattern, we attemp to build a Machine Learning model <span class="math notranslate nohighlight">\(f(q,d)\rightarrow y\)</span>. This is just the general form, and we need to select the label (from <span class="math notranslate nohighlight">\(y\)</span>) for different approaches. For features, they can be genrally devided into three groups: (1) query features such as user demographic and logs data, (2) document features such as movie genre, and (3) dynamic features which consider both query and document such as number of times user <span class="math notranslate nohighlight">\(q\)</span> has watched movie <span class="math notranslate nohighlight">\(d\)</span> in the past.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>We can see that with relevance scores only, our data is just the pivot-longer form of the <em>utility matrix</em>. This form allows adding features of three groups described earlier, so we can incorporate more data into model training.</p>
</div>
<section id="approaches">
<h3>3.1. Approaches<a class="headerlink" href="#approaches" title="Permalink to this headline">#</a></h3>
<p>There are three approaches to solve the learning to rank problem as follows:</p>
<ul class="simple">
<li><p><em>Pointwise</em>: We ignore the query column and reduce the task to a regression problem (for ordinal label) or classification problem (for binary label).</p></li>
<li><p><em>Pairwise</em>: We take the difference between every sample pair in the same query to construct training samples. We treat the task as a binary classification problem which decides if the two documents are equal or not. Like pointwise, pairwise approach also ignores the group structure.</p></li>
<li><p><em>Listwise</em>: This approach attemps to model the entire ranking list at once, which is more straightfoward. It is thus more complicated but can outperform pointwise and pairwise.</p></li>
</ul>
</section>
<section id="evaluation">
<h3>3.2. Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this headline">#</a></h3>
<p>As we see, the label of the ranking problem is similar to recommendation problem, so they use the same evaluation metric. More specifically, metrics considering only top <span class="math notranslate nohighlight">\(K\)</span> items is commonly used in practice: MAP&#64;K for binary label and NDCG for ordinal label.</p>
</section>
<section id="id1">
<h3>3.3. Implementation<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p>In this section we will train several Gradient Boosting rankers on the <a class="reference external" href="https://www.microsoft.com/en-us/research/project/mslr/">MS rank dataset</a>. All algorithms require features, labels and queries for training; but there are some minor differences between their implementations:</p>
<ul class="simple">
<li><p>During initialization: objective functions and evaluation metrics.</p></li>
<li><p>During training: queries are provided via IDs or document counts. Features and labels are also required as usual.</p></li>
</ul>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>Class</p></th>
<th class="text-align:left head"><p>Objective</p></th>
<th class="text-align:left head"><p>Metric</p></th>
<th class="text-align:left head"><p>Query ids</p></th>
<th class="text-align:left head"><p>Document counts</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p><a class="reference external" href="https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBRanker"><code class="docutils literal notranslate"><span class="pre">XGBRanker</span></code></a></p></td>
<td class="text-align:left"><p><code class="docutils literal notranslate"><span class="pre">objective</span></code></p></td>
<td class="text-align:left"><p><code class="docutils literal notranslate"><span class="pre">eval_metric</span></code></p></td>
<td class="text-align:left"><p><code class="docutils literal notranslate"><span class="pre">qid</span></code></p></td>
<td class="text-align:left"><p><code class="docutils literal notranslate"><span class="pre">group</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><a class="reference external" href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRanker.html"><code class="docutils literal notranslate"><span class="pre">LGBMRanker</span></code></a></p></td>
<td class="text-align:left"><p><code class="docutils literal notranslate"><span class="pre">objective</span></code></p></td>
<td class="text-align:left"><p><code class="docutils literal notranslate"><span class="pre">metric</span></code></p></td>
<td class="text-align:left"><p></p></td>
<td class="text-align:left"><p><code class="docutils literal notranslate"><span class="pre">group</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p><a class="reference external" href="https://catboost.ai/en/docs/concepts/python-reference_catboostranker"><code class="docutils literal notranslate"><span class="pre">CatBoostRanker</span></code></a></p></td>
<td class="text-align:left"><p><code class="docutils literal notranslate"><span class="pre">objective</span></code></p></td>
<td class="text-align:left"><p><code class="docutils literal notranslate"><span class="pre">eval_metric</span></code></p></td>
<td class="text-align:left"><p><code class="docutils literal notranslate"><span class="pre">group_id</span></code></p></td>
<td class="text-align:left"><p></p></td>
</tr>
</tbody>
</table>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>
<span class="kn">import</span> <span class="nn">lightgbm</span> <span class="k">as</span> <span class="nn">lgb</span>
<span class="kn">import</span> <span class="nn">catboost</span> <span class="k">as</span> <span class="nn">cgb</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dfTrain</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/msrank_train.csv&#39;</span><span class="p">)</span>
<span class="n">dfTest</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/msrank_test.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xTrain</span> <span class="o">=</span> <span class="n">dfTrain</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:]</span>
<span class="n">yTrain</span> <span class="o">=</span> <span class="n">dfTrain</span><span class="o">.</span><span class="n">relevance_score</span>
<span class="n">qTrain</span> <span class="o">=</span> <span class="n">dfTrain</span><span class="o">.</span><span class="n">query_id</span>

<span class="n">xTest</span> <span class="o">=</span> <span class="n">dfTest</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:]</span>
<span class="n">yTest</span> <span class="o">=</span> <span class="n">dfTest</span><span class="o">.</span><span class="n">relevance_score</span>
<span class="n">qTest</span> <span class="o">=</span> <span class="n">dfTest</span><span class="o">.</span><span class="n">query_id</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">cgb</span><span class="o">.</span><span class="n">CatBoostRanker</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">group_id</span><span class="o">=</span><span class="n">qTrain</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">yPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xTest</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMRanker</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="n">qTrain</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">yPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xTest</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRanker</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="n">qTrain</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">yPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xTest</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="resources">
<h2>Resources<a class="headerlink" href="#resources" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><em>medium - <a class="reference external" href="https://medium.com/quantyca/oversampling-and-undersampling-adasyn-vs-enn-60828a58db39">Oversampling and undersampling: ADASYN vs ENN</a></em></p></li>
<li><p><em>sci2s.ugr - <a class="reference external" href="https://sci2s.ugr.es/keel/keel-dataset/pdfs/2005-Han-LNCS.pdf">Borderline SMOTE</a></em></p></li>
<li><p><em>diva-portal - <a class="reference external" href="https://www.diva-portal.org/smash/get/diva2:1519153/FULLTEXT01.pdf">ADASYN</a></em></p></li>
<li><p><em>maxhalford.github - <a class="reference external" href="https://maxhalford.github.io/blog/lightgbm-focal-loss/">Focal loss implementation for LightGBM</a></em></p></li>
<li><p><em>leimao.github - <a class="reference external" href="https://leimao.github.io/blog/Focal-Loss-Explained/">Focal Loss explained</a></em></p></li>
<li><p><em>neptune - <a class="reference external" href="https://neptune.ai/blog/binary-classification-tips-and-tricks-from-kaggle">Binary classification tips and tricks from Kaggle</a></em></p></li>
<li><p><em>jstage.jst.go - <a class="reference external" href="https://www.jstage.jst.go.jp/article/transinf/E94.D/10/E94.D_10_1854/_pdf/-char/en">A short introduction to Learning to Rank</a></em></p></li>
<li><p><em>everdark.github - <a class="reference external" href="https://everdark.github.io/k9/notebooks/ml/learning_to_rank/learning_to_rank.html">Introduction to Learning to Rank</a></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">U</span> <span class="n">imbalanced</span><span class="o">-</span><span class="n">learn</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting imbalanced-learn
  Downloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">226.0/226.0 kB</span> <span class=" -Color -Color-Red">871.1 kB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>00:0100:01
?25hRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn) (3.0.0)
Requirement already satisfied: joblib&gt;=1.1.1 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn) (1.2.0)
Requirement already satisfied: scipy&gt;=1.3.2 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn) (1.7.3)
Requirement already satisfied: numpy&gt;=1.17.3 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn) (1.21.6)
Requirement already satisfied: scikit-learn&gt;=1.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn) (1.1.0)
Installing collected packages: imbalanced-learn
Successfully installed imbalanced-learn-0.10.1

<span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> A new release of pip available: <span class=" -Color -Color-Red">22.3.1</span> -&gt; <span class=" -Color -Color-Green">23.0</span>
<span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> To update, run: <span class=" -Color -Color-Green">pip install --upgrade pip</span>
Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "hungpq7/tabular-book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./07-tabular-learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="shap-model-interpretation.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Shap: Model Interpretation</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../08-time-series/_intro.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><b>8. Time Series</b></p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Quang Hung &#9829; Thuy Linh<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>