
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>1. Gradient Descent variants &#8212; My sample book</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="1. Introduction" href="27-plotly-interactive-visualization.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">My sample book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <p class="caption">
 <span class="caption-text">
  Python Programming
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01-python-basic-concepts.html">
   (python) Basic Concepts
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Data Visualization
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="09-matplotlib-graph-construction.html">
   1. Matplotlib API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="27-plotly-interactive-visualization.html">
   1. Introduction
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Optimization
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   1. Gradient Descent variants
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/content/36-numpy-gradient-descent.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fcontent/36-numpy-gradient-descent.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/content/36-numpy-gradient-descent.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   1. Gradient Descent variants
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bgd">
     1.1. BGD
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#analysis-of-derivative">
       Analysis of derivative
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#algorithm">
       Algorithm
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sgd">
     1.2. SGD
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stochastic-behaviour">
       Stochastic behaviour
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Algorithm
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#enhanced-methods">
   2. Enhanced methods
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adaptive-gradient">
     2.1. Adaptive gradient
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#momentum">
       Momentum
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nesterov">
       Nesterov
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adaptive-learning-rate">
     2.2. Adaptive learning rate
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#adagrad">
       AdaGrad
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#rmsprop">
       RMSprop
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#adadelta">
       AdaDelta
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#addams-family">
     2.3. Addams family
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#adam">
       Adam
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#adamax">
       AdaMax
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nadam">
       Nadam
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#amsgrad">
       AMSGrad
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>1. Gradient Descent variants</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   1. Gradient Descent variants
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bgd">
     1.1. BGD
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#analysis-of-derivative">
       Analysis of derivative
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#algorithm">
       Algorithm
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sgd">
     1.2. SGD
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stochastic-behaviour">
       Stochastic behaviour
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Algorithm
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#enhanced-methods">
   2. Enhanced methods
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adaptive-gradient">
     2.1. Adaptive gradient
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#momentum">
       Momentum
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nesterov">
       Nesterov
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adaptive-learning-rate">
     2.2. Adaptive learning rate
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#adagrad">
       AdaGrad
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#rmsprop">
       RMSprop
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#adadelta">
       AdaDelta
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#addams-family">
     2.3. Addams family
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#adam">
       Adam
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#adamax">
       AdaMax
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nadam">
       Nadam
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#amsgrad">
       AMSGrad
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="gradient-descent-variants">
<h1>1. Gradient Descent variants<a class="headerlink" href="#gradient-descent-variants" title="Permalink to this headline">#</a></h1>
<p>In real life, especially when the gradient gets very complicated or is very large, mathematical methods on solving for global minimum are shown to be impossible. There are a number of computational methods have been developed in order to find extrema of a function, where <a class="reference external" href="https://en.wikipedia.org/wiki/Gradient_descent">Gradient Descent</a> (GD) is one of the most pupular and is widely used in Machine Learning. This is an iterative method trying to minimize a <a class="reference external" href="https://en.wikipedia.org/wiki/Differentiable_function">differentiable</a> function; in the context of Machine Learning, the function to be minimized is nothing but the loss function, <span class="math notranslate nohighlight">\(\mathcal{L}(\mathbf{w})\)</span>, where <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> represents model parameters. The gradient of this function is denoted <span class="math notranslate nohighlight">\(\mathbf{g}=g(\mathbf{w})=\nabla \mathcal{L}(\mathbf{w})\)</span>.</p>
<p>There is a drawback of GD is that it is designed to find a local minimum, while we need the global minimum of the loss function.
Gradient Descent itself is a simple method, and there has been a lot of works proposed to tackle this problem, described in a evolutionary chart as below.</p>
<img src='image/gradient_descent_evolutionary.png' style='height:350px; margin:20px auto 20px;'><section id="bgd">
<h2>1.1. BGD<a class="headerlink" href="#bgd" title="Permalink to this headline">#</a></h2>
<p>This section is about the most basic idea of the family, Full-Batch Gradient Descent (BGD). Also known as Vanilla GD.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.animation</span> <span class="kn">import</span> <span class="n">FuncAnimation</span><span class="p">,</span> <span class="n">ArtistAnimation</span><span class="p">,</span> <span class="n">PillowWriter</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;seaborn&#39;</span><span class="p">,</span> <span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">])</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
</pre></div>
</div>
</div>
</div>
<section id="analysis-of-derivative">
<h3>Analysis of derivative<a class="headerlink" href="#analysis-of-derivative" title="Permalink to this headline">#</a></h3>
<p>To understand the smart idea behind Gradient Descent, we first analyze the relative position between a random point to its <em>closest</em> local minimum. We have already known derivarive at a point is the representation of <em>instantaneous velocity</em>, but how about its direction? To illustrate this, letâ€™s plot the derivatives at some points of a 1-dimensional function as vectors along the <span class="math notranslate nohighlight">\(x\)</span>-axis.</p>
<div class="math notranslate nohighlight">
\[y=\frac{1}{128}(x^4-8x^3)\]</div>
<img src='output/directional_derivative.png' style='height:300px; margin:0px auto 20px;'>
<p>In this function, there are two <a class="reference external" href="https://en.wikipedia.org/wiki/Critical_point_(mathematics)">critical points</a> at <span class="math notranslate nohighlight">\(x=0\)</span> and <span class="math notranslate nohighlight">\(x=6\)</span>, in which the first one is a <a class="reference external" href="https://en.wikipedia.org/wiki/Saddle_point">saddle point</a> and the second one is a <a class="reference external" href="https://en.wikipedia.org/wiki/Maxima_and_minima">local minimum</a>. A very important conclusion can be drawn from this graph is that directional derivatives always <em>point away</em> from the steepest path downwards. In other words, if we move the point in the <em>opposite direction</em> of the derivative, we will end up approach a local minimum or a saddle point. Unfortunately, from the perspective of a single point on the graph and using only gradient, there is no way to regconize if there comes a saddle point.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span><span class="o">/</span><span class="mi">128</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">4</span> <span class="o">-</span> <span class="mi">8</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>
<span class="n">grad</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span><span class="o">/</span><span class="mi">32</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">3</span> <span class="o">-</span> <span class="mi">6</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">left</span><span class="p">,</span> <span class="n">right</span> <span class="o">=</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span>
<span class="n">xData</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">yData</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">xData</span><span class="p">)</span>

<span class="n">xCritical</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">yCritical</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">xCritical</span><span class="p">)</span>

<span class="n">xRed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<span class="n">yRed</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">xRed</span><span class="p">)</span>
<span class="n">uRed</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">xRed</span><span class="p">)</span>
<span class="n">vRed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">xRed</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">xBlue</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
<span class="n">yBlue</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">xBlue</span><span class="p">)</span>
<span class="n">uBlue</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">xBlue</span><span class="p">)</span>
<span class="n">vBlue</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">xBlue</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xData</span><span class="p">,</span> <span class="n">yData</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xCritical</span><span class="p">,</span> <span class="n">yCritical</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xRed</span><span class="p">,</span> <span class="n">yRed</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;indianred&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="n">xRed</span><span class="p">,</span> <span class="n">yRed</span><span class="p">,</span> <span class="n">uRed</span><span class="p">,</span> <span class="n">vRed</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;indianred&#39;</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xBlue</span><span class="p">,</span> <span class="n">yBlue</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;cornflowerblue&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="n">xBlue</span><span class="p">,</span> <span class="n">yBlue</span><span class="p">,</span> <span class="n">uBlue</span><span class="p">,</span> <span class="n">vBlue</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;cornflowerblue&#39;</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;output/directional_derivative.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="algorithm">
<h3>Algorithm<a class="headerlink" href="#algorithm" title="Permalink to this headline">#</a></h3>
<p>From the above analyses, an iterative method call Gradient Descent has been proposed to find local minima. This algorithm initializes an arbitrary point and update its position at each iteration <span class="math notranslate nohighlight">\(t\)</span> using the formula:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\Delta x_t &amp;= -\eta g_t \\
x_{t+1} &amp;= x_t+\Delta x_t
\end{aligned}\end{split}\]</div>
<p>Using this design, the (magnitude of) the gradient gets smaller and smaller and finally approach 0, thus the name of the algorithm. The whole process can be thought as a ball rolling down the hill. There is a coefficient named the <em>learning rate</em> (denoted <span class="math notranslate nohighlight">\(\eta\)</span>) attached to the gradient, controls how large each step is. The value of this hyperparameter should not be either too large (making the convergence not happening) or too small (taking too long to converge). The effect of learning rate is illustrated in the following example, in which we build the algorithm from scratch to find the minimum of the function <span class="math notranslate nohighlight">\(y=x^2+5\sin(x)\)</span> for different values of <span class="math notranslate nohighlight">\(\eta\)</span>.</p>
<img src='output/batch_gradient_descent.gif' style='height:250px; margin:20px auto 20px;'>
<p>The updating process can also be summarized as <a class="reference external" href="https://en.wikipedia.org/wiki/Learning_curve_(machine_learning)">learning curves</a>. A couple of stopping conditions are also used such as tolerance (maximum magnitude of gradient) or maximum number of iterations. In the example, I use 50 iterations and set the value of tolerance to 0 to make sure all iterations are used.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">BatchGD</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">xInit</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">xList</span><span class="p">,</span> <span class="n">yList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nIter</span><span class="p">):</span>
        <span class="n">xDelta</span> <span class="o">=</span> <span class="o">-</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">xDelta</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">xList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">xList</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">yList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yList</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span> <span class="k">break</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xList</span><span class="p">,</span> <span class="n">yList</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">grad</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">nIter</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">xInit</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">eta1</span> <span class="o">=</span> <span class="mf">0.4</span>
<span class="n">eta2</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">eta3</span> <span class="o">=</span> <span class="mf">0.06</span>

<span class="n">frames1</span> <span class="o">=</span> <span class="n">BatchGD</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta1</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">)</span>
<span class="n">frames2</span> <span class="o">=</span> <span class="n">BatchGD</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta2</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">)</span>
<span class="n">frames3</span> <span class="o">=</span> <span class="n">BatchGD</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta3</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">)</span>
<span class="n">iList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">nIter</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">frames</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">iList</span><span class="p">,</span> <span class="n">frames1</span><span class="p">,</span> <span class="n">frames2</span><span class="p">,</span> <span class="n">frames3</span><span class="p">]</span>

<span class="n">xLeft</span><span class="p">,</span> <span class="n">xRight</span> <span class="o">=</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span>

<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ax3</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">xGraph</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xLeft</span><span class="p">,</span> <span class="n">xRight</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">yGraph</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">xGraph</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">animate</span><span class="p">(</span><span class="n">frame</span><span class="p">):</span>
    <span class="n">i</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="n">x3</span><span class="p">,</span> <span class="n">y3</span> <span class="o">=</span> <span class="n">frame</span>
    
    <span class="n">ax1</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xLeft</span><span class="p">,</span> <span class="n">xRight</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;learningRate=</span><span class="si">{</span><span class="n">eta1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">line1</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xGraph</span><span class="p">,</span> <span class="n">yGraph</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
    <span class="n">point1</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;indianred&#39;</span><span class="p">)</span>
    
    <span class="n">ax2</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;learningRate=</span><span class="si">{</span><span class="n">eta2</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">line2</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xGraph</span><span class="p">,</span> <span class="n">yGraph</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
    <span class="n">point2</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;indianred&#39;</span><span class="p">)</span>
    
    <span class="n">ax3</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;learningRate=</span><span class="si">{</span><span class="n">eta3</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">line3</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax3</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xGraph</span><span class="p">,</span> <span class="n">yGraph</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
    <span class="n">point3</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax3</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="n">y3</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;indianred&#39;</span><span class="p">)</span>
    
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Iteration </span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="s1">.0f</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">nIter</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">line1</span><span class="p">,</span> <span class="n">point1</span><span class="p">,</span> <span class="n">line2</span><span class="p">,</span> <span class="n">point2</span><span class="p">,</span> <span class="n">line3</span><span class="p">,</span> <span class="n">point3</span>

<span class="n">gif</span> <span class="o">=</span> <span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">animate</span><span class="p">,</span> <span class="n">frames</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

<span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;output/batch_gradient_descent.gif&#39;</span>
<span class="n">gif</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="n">PillowWriter</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compare_gd</span><span class="p">(</span><span class="n">listAlgo</span><span class="p">,</span> <span class="n">listLabel</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">algo</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">listAlgo</span><span class="p">,</span> <span class="n">listLabel</span><span class="p">):</span>
        <span class="n">xList</span><span class="p">,</span> <span class="n">yList</span> <span class="o">=</span> <span class="n">algo</span><span class="o">.</span><span class="n">T</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">yList</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;FunctionValue&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Learning Curves&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">grad</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">eta1</span> <span class="o">=</span> <span class="mf">0.4</span>
<span class="n">eta2</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">eta3</span> <span class="o">=</span> <span class="mf">0.06</span>

<span class="n">listAlgo</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">BatchGD</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="n">eta1</span><span class="p">,</span> <span class="n">nIter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">xInit</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
    <span class="n">BatchGD</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="n">eta2</span><span class="p">,</span> <span class="n">nIter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">xInit</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
    <span class="n">BatchGD</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="n">eta3</span><span class="p">,</span> <span class="n">nIter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">xInit</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
<span class="p">]</span>

<span class="n">listLabel</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sa">f</span><span class="s1">&#39;BatchGD | eta=</span><span class="si">{</span><span class="n">eta1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s1">&#39;BatchGD | eta=</span><span class="si">{</span><span class="n">eta2</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s1">&#39;BatchGD | eta=</span><span class="si">{</span><span class="n">eta3</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">compare_gd</span><span class="p">(</span><span class="n">listAlgo</span><span class="p">,</span> <span class="n">listLabel</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/36-numpy-gradient-descent_9_0.png" src="../_images/36-numpy-gradient-descent_9_0.png" />
</div>
</div>
</section>
</section>
<section id="sgd">
<h2>1.2. SGD<a class="headerlink" href="#sgd" title="Permalink to this headline">#</a></h2>
<p>In this section, we talk about some drawbacks of BGD in practice: (1) its heavy dependence on the intial point, (2) the capability of online learning, (3) the memory cost and how <a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic Gradient Descent</a> (SGD) comes to the rescue.</p>
<section id="stochastic-behaviour">
<h3>Stochastic behaviour<a class="headerlink" href="#stochastic-behaviour" title="Permalink to this headline">#</a></h3>
<p>This Gradient Descentâ€™s variant only considers a part of data (mini-batch, or batch for short) instead of the whole dataset (full-batch) in each iteration to compute the gradient. The term <em>stochastic</em> means we add something <em>random</em>, <em>non-deterministic</em> into the algorithm. At first glance, a common sense is that using a part of data is less accurate, but it turns out SGD is amazingly efficient in practice. Letâ€™s analyze the advantages of SGD over BGD.</p>
<ul class="simple">
<li><p>SGD makes data in each iteration small enough so that it can be loaded into RAM with ease, this also reduces the computation cost significantly.</p></li>
<li><p>Randomness in SGD works as a regularization mechanic, some sort of trade-off between exploration and exploitation. In short-term, noisy steps can lead the ball away from local minima or saddle points; while in long-term, the ball still tends to finish in a valley bottom. For BGD, the ball goes straight to the local minimum; this behaviour is deterministic and thus has no exploration.</p></li>
<li><p>SGD enables <em>online learning</em>, which is a very important feature when implementing in practice. When there are new data, SGD treats them as a number of batches and updates to the current model easily, without re-computing gradients for the entire dataset.</p></li>
</ul>
<p>As steps in SGD are very noisy, we need to update more frequently than BGD to reach <em>long-term</em> state. This leads to the idea of using more than one epoch (an epoch is a pass over all data samples), which will be described in the next part. Nowadays, the SGD algorithm using the epoch concept is implemented in many modern ML/DL frameworks. Later improved techniques are also developed based on this implementation; however, I still use BGD to make things as simple as possible.</p>
</section>
<section id="id1">
<h3>Algorithm<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p><em>Input</em></p>
<ul class="simple">
<li><p>A dataset <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> having <span class="math notranslate nohighlight">\(N\)</span> samples</p></li>
<li><p>A loss function <span class="math notranslate nohighlight">\(\mathcal{L}(\mathbf{w})\)</span> and its gradient <span class="math notranslate nohighlight">\(\nabla{\mathcal{L}}\)</span></p></li>
<li><p>A learning rate, <span class="math notranslate nohighlight">\(\eta\)</span></p></li>
<li><p>A (mini) batch size, <span class="math notranslate nohighlight">\(M\)</span></p></li>
<li><p>A number of epochs, <span class="math notranslate nohighlight">\(E\)</span></p></li>
</ul>
<p><em>Step 1</em>. Calculate the number of batches <span class="math notranslate nohighlight">\(B=\lceil N/M\rceil\)</span>.</p>
<p><em>Step 2</em>. Initialize model parameters <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> randomly.</p>
<p><em>Step 3</em>. For <span class="math notranslate nohighlight">\(e=1,2,\dots,E\)</span>:</p>
<ul class="simple">
<li><p>Shuffle the training set <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> to renew batches.</p></li>
<li><p>Divide <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> into <span class="math notranslate nohighlight">\(B\)</span> batches, denoted <span class="math notranslate nohighlight">\(\mathcal{B}_1,\mathcal{B}_2,\dots,\mathcal{B}_B\)</span>. Each batch has the size of <span class="math notranslate nohighlight">\(M\)</span> and the last batch may have less than <span class="math notranslate nohighlight">\(M\)</span> samples.</p></li>
<li><p>For <span class="math notranslate nohighlight">\(b=1,2,\dots,B\)</span>:</p>
<ul>
<li><p>Compute the gradient <span class="math notranslate nohighlight">\(\nabla{\mathcal{L}(\mathbf{w})}\)</span> for batch <span class="math notranslate nohighlight">\(\mathcal{B}_b\)</span></p></li>
<li><p>Compute the step size by multiplying the learning rate and the gradient</p></li>
<li><p>Update the position using the rule: <span class="math notranslate nohighlight">\(\mathbf{w}\leftarrow\mathbf{w}-\eta\,\nabla{\mathcal{L}(\mathbf{w})}\)</span></p></li>
</ul>
</li>
</ul>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="enhanced-methods">
<h1>2. Enhanced methods<a class="headerlink" href="#enhanced-methods" title="Permalink to this headline">#</a></h1>
<p>For simplification purpose, in this section, the function to be minimized is <span class="math notranslate nohighlight">\(y=f(x)\)</span>.</p>
<section id="adaptive-gradient">
<h2>2.1. Adaptive gradient<a class="headerlink" href="#adaptive-gradient" title="Permalink to this headline">#</a></h2>
<section id="momentum">
<h3>Momentum<a class="headerlink" href="#momentum" title="Permalink to this headline">#</a></h3>
<p>As far as we know, GD works as a ball rolling down the hill and stops in a valley bottom. However, our ball will stuck in local minima most of the time, then we need some <a class="reference external" href="https://en.wikipedia.org/wiki/Acceleration">acceleration</a> to helps it cross these traps. A Momentum term (in red) has been introduced to extend the GDâ€™s update rule as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
m_t &amp;= \color{indianred}{\gamma m_{t-1}}-\eta g_t \\
\Delta x_t &amp;= m_t \\
x_{t+1} &amp;= x_t+\Delta x_t
\end{aligned}\end{split}\]</div>
<p>In each step, the ball not only moves downwards as normal GD, but also accumulates <a class="reference external" href="https://en.wikipedia.org/wiki/Momentum">momentum</a> from all previous steps:</p>
<div class="math notranslate nohighlight">
\[m_T=-\eta\sum_{t=1}^{T}{\gamma^t g_{T-t}}\]</div>
<p>The amount of information memorized from the previous step is controled by a coefficient, <span class="math notranslate nohighlight">\(\gamma\)</span>. The value of this hyperparameter is set <span class="math notranslate nohighlight">\(0&lt;\gamma&lt;1\)</span>, typically <span class="math notranslate nohighlight">\(0.9\)</span>, forcing earlier steps to have less effect. Visually, the motion of the ball is now more realistic, as it seems to carry <a class="reference external" href="https://en.wikipedia.org/wiki/Inertia">inertia</a>.</p>
<img src='output/momentum_gradient_descent.gif' style='height:250px; margin:20px auto 20px;'>
<p>The benefits of using Momentum includes:</p>
<ul class="simple">
<li><p>Momentum can help escaping local minima and saddle points</p></li>
<li><p>Momentum accelerates the ball so that it moves faster towards the minima</p></li>
<li><p>When implemented in SGD, Momentum dampens the <em>oscillations</em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.animation</span> <span class="kn">import</span> <span class="n">FuncAnimation</span><span class="p">,</span> <span class="n">ArtistAnimation</span><span class="p">,</span> <span class="n">PillowWriter</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;seaborn&#39;</span><span class="p">,</span> <span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">])</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">MomentumGD</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">xInit</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">xDelta</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">xList</span><span class="p">,</span> <span class="n">yList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nIter</span><span class="p">):</span>
        <span class="n">xDelta</span> <span class="o">=</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">xDelta</span> <span class="o">-</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">xDelta</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">xList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">xList</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">yList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yList</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span> <span class="k">break</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xList</span><span class="p">,</span> <span class="n">yList</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span><span class="o">/</span><span class="mi">12</span> <span class="o">*</span> <span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">4</span> <span class="o">-</span> <span class="mi">16</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">3</span> <span class="o">+</span> <span class="mi">18</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">grad</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">**</span><span class="mi">3</span> <span class="o">-</span> <span class="mi">4</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">x</span>

<span class="n">nIter</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">xInit</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.5</span>
<span class="n">eta</span> <span class="o">=</span> <span class="mf">0.08</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.8</span>

<span class="n">frames1</span> <span class="o">=</span> <span class="n">BatchGD</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">)</span>
<span class="n">frames2</span> <span class="o">=</span> <span class="n">MomentumGD</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">)</span>
<span class="n">iList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">nIter</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">frames</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">iList</span><span class="p">,</span> <span class="n">frames1</span><span class="p">,</span> <span class="n">frames2</span><span class="p">]</span>

<span class="n">xLeft</span><span class="p">,</span> <span class="n">xRight</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span>

<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">xGraph</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xLeft</span><span class="p">,</span> <span class="n">xRight</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">yGraph</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">xGraph</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">animate</span><span class="p">(</span><span class="n">frame</span><span class="p">):</span>
    <span class="n">i</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="n">frame</span>
    
    <span class="n">ax1</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xLeft</span><span class="p">,</span> <span class="n">xRight</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;learningRate=</span><span class="si">{</span><span class="n">eta</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">line1</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xGraph</span><span class="p">,</span> <span class="n">yGraph</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
    <span class="n">point1</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;indianred&#39;</span><span class="p">)</span>
    
    <span class="n">ax2</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;learningRate=</span><span class="si">{</span><span class="n">eta</span><span class="si">}</span><span class="s1">, momentum=</span><span class="si">{</span><span class="n">gamma</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">line2</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xGraph</span><span class="p">,</span> <span class="n">yGraph</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
    <span class="n">point2</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;indianred&#39;</span><span class="p">)</span>
    
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Iteration </span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="s1">.0f</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">nIter</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">line1</span><span class="p">,</span> <span class="n">point1</span><span class="p">,</span> <span class="n">line2</span><span class="p">,</span> <span class="n">point2</span>

<span class="n">gif</span> <span class="o">=</span> <span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">animate</span><span class="p">,</span> <span class="n">frames</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

<span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;output/momentum_gradient_descent.gif&#39;</span>
<span class="n">gif</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="n">PillowWriter</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="nesterov">
<h3>Nesterov<a class="headerlink" href="#nesterov" title="Permalink to this headline">#</a></h3>
<p>NAG (Nesterov Accelerated Gradient) is an improved version of Momentum. As far as we know, Momentum adds <span class="math notranslate nohighlight">\(\gamma m_{t-1}\)</span> to the current update; we can take advantage of this information to <em>approximately forecast</em> the next position <span class="math notranslate nohighlight">\(x_{t+1}\approx x_t+\gamma m_{t-1}\)</span>. The gradient is now computed at this new location. Using this <em>looking ahead</em> strategy, NAG makes the ball smarter instead of letting it rolls down slowly and blindly.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
g_t &amp;= \nabla f(x_t+\color{indianred}{\gamma m_{t-1}}) \\
m_t &amp;= \gamma m_{t-1}-\eta g_t \\
\Delta x_t &amp;= m_t \\
x_{t+1} &amp;= x_t+\Delta x_t
\end{aligned}\end{split}\]</div>
<p>The new equation of <span class="math notranslate nohighlight">\(g_t\)</span> is good at explaining Nesterov but is not convenient for programming. By re-assigning <span class="math notranslate nohighlight">\(x_t \leftarrow x_t+\gamma m_{t-1}\)</span>, we end up getting equivalent update rules. All the changes made to Momentum are highlighted in red.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
g_t &amp;= \nabla f(x_t) \\
m_t &amp;= \gamma m_{t-1}-\eta g_t \\
\Delta x_t &amp;= \color{indianred}{\gamma m_t-\eta g_t} \\
x_{t+1} &amp;= x_t+\Delta x_t
\end{aligned}\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.animation</span> <span class="kn">import</span> <span class="n">FuncAnimation</span><span class="p">,</span> <span class="n">ArtistAnimation</span><span class="p">,</span> <span class="n">PillowWriter</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;seaborn&#39;</span><span class="p">,</span> <span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">])</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">NesterovGD</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">xInit</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">xList</span><span class="p">,</span> <span class="n">yList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nIter</span><span class="p">):</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">m</span> <span class="o">-</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">xDelta</span> <span class="o">=</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">m</span> <span class="o">-</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">xDelta</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">xList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">xList</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">yList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yList</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span> <span class="k">break</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xList</span><span class="p">,</span> <span class="n">yList</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span><span class="o">/</span><span class="mi">12</span> <span class="o">*</span> <span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">4</span> <span class="o">-</span> <span class="mi">16</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">3</span> <span class="o">+</span> <span class="mi">18</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">grad</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">**</span><span class="mi">3</span> <span class="o">-</span> <span class="mi">4</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">x</span>

<span class="n">eta</span> <span class="o">=</span> <span class="mf">0.08</span>
<span class="n">gamma1</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">gamma2</span> <span class="o">=</span> <span class="mf">0.9</span>

<span class="n">listAlgo</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">MomentumGD</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma1</span><span class="p">,</span> <span class="n">nIter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">xInit</span><span class="o">=-</span><span class="mf">1.5</span><span class="p">),</span>
    <span class="n">NesterovGD</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma1</span><span class="p">,</span> <span class="n">nIter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">xInit</span><span class="o">=-</span><span class="mf">1.5</span><span class="p">),</span>
    <span class="n">NesterovGD</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma2</span><span class="p">,</span> <span class="n">nIter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">xInit</span><span class="o">=-</span><span class="mf">1.5</span><span class="p">),</span>
<span class="p">]</span>

<span class="n">listLabel</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sa">f</span><span class="s1">&#39;Momentum | gamma=</span><span class="si">{</span><span class="n">gamma1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s1">&#39;Nesterov | gamma=</span><span class="si">{</span><span class="n">gamma1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s1">&#39;Nesterov | gamma=</span><span class="si">{</span><span class="n">gamma2</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="p">]</span>

<span class="n">compare_gd</span><span class="p">(</span><span class="n">listAlgo</span><span class="p">,</span> <span class="n">listLabel</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/36-numpy-gradient-descent_22_0.png" src="../_images/36-numpy-gradient-descent_22_0.png" />
</div>
</div>
</section>
</section>
<section id="adaptive-learning-rate">
<h2>2.2. Adaptive learning rate<a class="headerlink" href="#adaptive-learning-rate" title="Permalink to this headline">#</a></h2>
<section id="adagrad">
<h3>AdaGrad<a class="headerlink" href="#adagrad" title="Permalink to this headline">#</a></h3>
<p>AdaGrad (Adaptive Gradients)
The optimizers above remain one learning rate constant through training while AdaGrad adapts learning rate to the parameters, performing low learning rates for parameters associated with dense features, and higher learning rates for parameters associated with sparse features. AdaGrad is suitable for dealing with sparse data, the learning rate will be updated after each iteration.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\eta_t &amp;= \frac{\eta}{\color{indianred}{\sqrt{g_{t}^2+g_{t-1}^2+\dots+\epsilon}}} \\
\Delta x_t &amp;= -\eta_t g_t \\
x_{t+1} &amp;= x_t+\Delta x_t
\end{aligned}\end{split}\]</div>
<p>The current learning rate <span class="math notranslate nohighlight">\(\eta_t\)</span> will be affected by accumulate gradients of all previous steps (in red) so that it will get smaller after each interation. This leads to a slow convergence, so the initiation value of learning rate should be high, typically <span class="math notranslate nohighlight">\(\eta=0.1\)</span>. A smoothing term <span class="math notranslate nohighlight">\(\epsilon\)</span> is added to the denominator to prevent divide by zero error.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.animation</span> <span class="kn">import</span> <span class="n">FuncAnimation</span><span class="p">,</span> <span class="n">ArtistAnimation</span><span class="p">,</span> <span class="n">PillowWriter</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;seaborn&#39;</span><span class="p">,</span> <span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">])</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">AdaGrad</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">xInit</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">gradInit</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">xList</span><span class="p">,</span> <span class="n">yList</span><span class="p">,</span> <span class="n">gradList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">gradInit</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nIter</span><span class="p">):</span>
        <span class="n">etaAdj</span> <span class="o">=</span> <span class="n">eta</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">gradList</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
        <span class="n">xDelta</span> <span class="o">=</span> <span class="o">-</span> <span class="n">etaAdj</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">xDelta</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">gradList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gradList</span><span class="p">,</span> <span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">xList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">xList</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">yList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yList</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span> <span class="k">break</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xList</span><span class="p">,</span> <span class="n">yList</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">grad</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">eta1</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">eta2</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">eta3</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">eta4</span> <span class="o">=</span> <span class="mi">7</span>

<span class="n">listAlgo</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">BatchGD</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="n">eta1</span><span class="p">,</span> <span class="n">nIter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">xInit</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
    <span class="n">AdaGrad</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="n">eta2</span><span class="p">,</span> <span class="n">nIter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">xInit</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
    <span class="n">AdaGrad</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="n">eta3</span><span class="p">,</span> <span class="n">nIter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">xInit</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
    <span class="n">AdaGrad</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="n">eta4</span><span class="p">,</span> <span class="n">nIter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">xInit</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
<span class="p">]</span>

<span class="n">listLabel</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sa">f</span><span class="s1">&#39;BatchGD | eta=</span><span class="si">{</span><span class="n">eta1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s1">&#39;AdaGrad | eta=</span><span class="si">{</span><span class="n">eta2</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s1">&#39;AdaGrad | eta=</span><span class="si">{</span><span class="n">eta3</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s1">&#39;AdaGrad | eta=</span><span class="si">{</span><span class="n">eta4</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">compare_gd</span><span class="p">(</span><span class="n">listAlgo</span><span class="p">,</span> <span class="n">listLabel</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/36-numpy-gradient-descent_27_0.png" src="../_images/36-numpy-gradient-descent_27_0.png" />
</div>
</div>
</section>
<section id="rmsprop">
<h3>RMSprop<a class="headerlink" href="#rmsprop" title="Permalink to this headline">#</a></h3>
<p>RMSprop (Root Mean Squared Propagation) has been developed in attemp to resolve AdaGradâ€™s radically diminishing learning rates. It defines <span class="math notranslate nohighlight">\(v_t\)</span>, an <a class="reference external" href="https://en.wikipedia.org/wiki/Exponential_smoothing">exponentially moving average</a> which is calculated using <span class="math notranslate nohighlight">\(v_{t-1}\)</span> and the last squared gradient <span class="math notranslate nohighlight">\(g_t^2\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
v_t &amp;= \color{indianred}{\rho v_{t-1}+(1-\rho)g_t^2} \\
\eta_t &amp;= \frac{\eta}{\sqrt{v_t+\epsilon}} \\
\Delta x_t &amp;= -\eta_t g_t \\
x_{t+1} &amp;= x_t+\Delta x_t
\end{aligned}\end{split}\]</div>
<p>The part <span class="math notranslate nohighlight">\(\sqrt{v_t+\epsilon}\)</span> is called <em>root mean squared</em>, thus the name of the algorithm. As above formula for <span class="math notranslate nohighlight">\(v_t\)</span> is only optimal for programming, we rewrite its formula to have a better understanding of how <span class="math notranslate nohighlight">\(v_t\)</span> works.</p>
<div class="math notranslate nohighlight">
\[v_T=(1-\rho)\sum_{t=1}^{T}{\rho^t g_{T-t}^2}\]</div>
<p>Itâ€™s easy to see that the further a gradient <span class="math notranslate nohighlight">\(g_t\)</span> is from the current step (<span class="math notranslate nohighlight">\(T\)</span>), the lower multiplier attached to it. For this reason, we actually accumulate past gradients over a restricted time window, in which gradients significantly contribute to <span class="math notranslate nohighlight">\(v_t\)</span>. The number of effective gradients is approximately <span class="math notranslate nohighlight">\((1-\rho)^{-1}\)</span>, thus <span class="math notranslate nohighlight">\(\rho\)</span> is usually choosen between <span class="math notranslate nohighlight">\(0.9\)</span> and <span class="math notranslate nohighlight">\(0.98\)</span>. For example, <span class="math notranslate nohighlight">\(\rho=0.9\)</span> implies that only last 10 <span class="math notranslate nohighlight">\(g_t\)</span> are effective. Being an extension of AdaGrad, RMSprop also requires <span class="math notranslate nohighlight">\(\eta\)</span> to be high enough, usually in the interval <span class="math notranslate nohighlight">\((0.1,0.5)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.animation</span> <span class="kn">import</span> <span class="n">FuncAnimation</span><span class="p">,</span> <span class="n">ArtistAnimation</span><span class="p">,</span> <span class="n">PillowWriter</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;seaborn&#39;</span><span class="p">,</span> <span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">])</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">RMSprop</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">xInit</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">xList</span><span class="p">,</span> <span class="n">yList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nIter</span><span class="p">):</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">v</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">gamma</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">etaAdj</span> <span class="o">=</span> <span class="n">eta</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
        <span class="n">xDelta</span> <span class="o">=</span> <span class="o">-</span> <span class="n">etaAdj</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">xDelta</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">xList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">xList</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">yList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yList</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span> <span class="k">break</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xList</span><span class="p">,</span> <span class="n">yList</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">grad</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">eta1</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">eta2</span><span class="p">,</span> <span class="n">gamma2</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span>
<span class="n">eta3</span><span class="p">,</span> <span class="n">gamma3</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.9</span>
<span class="n">eta4</span><span class="p">,</span> <span class="n">gamma4</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.98</span>

<span class="n">listAlgo</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">AdaGrad</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="n">eta1</span><span class="p">,</span> <span class="n">nIter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">xInit</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
    <span class="n">RMSprop</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="n">eta2</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma2</span><span class="p">,</span> <span class="n">nIter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">xInit</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
    <span class="n">RMSprop</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="n">eta3</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma3</span><span class="p">,</span> <span class="n">nIter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">xInit</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
    <span class="n">RMSprop</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="n">eta4</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma4</span><span class="p">,</span> <span class="n">nIter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">xInit</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
<span class="p">]</span>

<span class="n">listLabel</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sa">f</span><span class="s1">&#39;AdaGrad | eta=</span><span class="si">{</span><span class="n">eta1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s1">&#39;RMSprop | eta=</span><span class="si">{</span><span class="n">eta2</span><span class="si">}</span><span class="s1"> gamma=</span><span class="si">{</span><span class="n">gamma2</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s1">&#39;RMSprop | eta=</span><span class="si">{</span><span class="n">eta3</span><span class="si">}</span><span class="s1"> gamma=</span><span class="si">{</span><span class="n">gamma3</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s1">&#39;RMSprop | eta=</span><span class="si">{</span><span class="n">eta4</span><span class="si">}</span><span class="s1"> gamma=</span><span class="si">{</span><span class="n">gamma4</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">compare_gd</span><span class="p">(</span><span class="n">listAlgo</span><span class="p">,</span> <span class="n">listLabel</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/36-numpy-gradient-descent_31_0.png" src="../_images/36-numpy-gradient-descent_31_0.png" />
</div>
</div>
</section>
<section id="adadelta">
<h3>AdaDelta<a class="headerlink" href="#adadelta" title="Permalink to this headline">#</a></h3>
<p>AdaDelta (Adaptive Delta <span class="math notranslate nohighlight">\(\Delta x\)</span>) has both been developed in around the same time, but independently with RMSprop. Its main idea is very much like RMSprop, with an additional variable <span class="math notranslate nohighlight">\(u_t\)</span>, the exponential smoothing of <span class="math notranslate nohighlight">\(\Delta^2 x_t\)</span>. Both <span class="math notranslate nohighlight">\(u_t\)</span> and <span class="math notranslate nohighlight">\(v_t\)</span> share the same smoothing parameter, <span class="math notranslate nohighlight">\(\rho\)</span>. The update rules of AdaDelta is given below:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
v_t &amp;= \rho v_{t-1}+(1-\rho)g_t^2 \\
u_t &amp;= \color{indianred}{\rho u_{t-1}+(1-\rho)\Delta^2 x_t} \\
\eta_t &amp;= \sqrt\frac{\color{indianred}{u_t}+\epsilon}{v_t+\epsilon} \\
\Delta x_t &amp;= -\eta_t g_t \\
x_{t+1} &amp;= x_t+\Delta x_t
\end{aligned}\end{split}\]</div>
<p>The interesting part of AdaDelta is the absence of <span class="math notranslate nohighlight">\(\eta\)</span>. The update rules make sense because <span class="math notranslate nohighlight">\(\sqrt{u_t+\epsilon}\)</span> and <span class="math notranslate nohighlight">\(\sqrt{v_t+\epsilon}\)</span> have the same unit with <span class="math notranslate nohighlight">\(x_t\)</span> and <span class="math notranslate nohighlight">\(g_t\)</span>, respectively. But keep in mind that large values of <span class="math notranslate nohighlight">\(\rho\)</span> will make the convergence slow.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.animation</span> <span class="kn">import</span> <span class="n">FuncAnimation</span><span class="p">,</span> <span class="n">ArtistAnimation</span><span class="p">,</span> <span class="n">PillowWriter</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;seaborn&#39;</span><span class="p">,</span> <span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">])</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">AdaDelta</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">xInit</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">xDelta</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">u</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">v</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">xList</span><span class="p">,</span> <span class="n">yList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nIter</span><span class="p">):</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">*</span><span class="n">u</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">gamma</span><span class="p">)</span><span class="o">*</span><span class="n">xDelta</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">*</span><span class="n">v</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">gamma</span><span class="p">)</span><span class="o">*</span><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">eta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">u</span><span class="o">+</span><span class="n">eps</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v</span><span class="o">+</span><span class="n">eps</span><span class="p">)</span>
        <span class="n">xDelta</span> <span class="o">=</span> <span class="o">-</span><span class="n">eta</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">+=</span> <span class="n">xDelta</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="n">xList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">xList</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">yList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yList</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span> <span class="k">break</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xList</span><span class="p">,</span> <span class="n">yList</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">grad</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">xInit</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">nIter</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">gamma1</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">gamma2</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">gamma3</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">gamma4</span> <span class="o">=</span> <span class="mf">0.98</span>

<span class="n">listAlgo</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">AdaDelta</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">gamma1</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">),</span>
    <span class="n">AdaDelta</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">gamma2</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">),</span>
    <span class="n">AdaDelta</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">gamma3</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">),</span>
    <span class="n">AdaDelta</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">gamma4</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">),</span>
<span class="p">]</span>

<span class="n">listLabel</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sa">f</span><span class="s1">&#39;AdaDelta | gamma=</span><span class="si">{</span><span class="n">gamma1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s1">&#39;AdaDelta | gamma=</span><span class="si">{</span><span class="n">gamma2</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s1">&#39;AdaDelta | gamma=</span><span class="si">{</span><span class="n">gamma3</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
    <span class="sa">f</span><span class="s1">&#39;AdaDelta | gamma=</span><span class="si">{</span><span class="n">gamma4</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">compare_gd</span><span class="p">(</span><span class="n">listAlgo</span><span class="p">,</span> <span class="n">listLabel</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/36-numpy-gradient-descent_35_0.png" src="../_images/36-numpy-gradient-descent_35_0.png" />
</div>
</div>
</section>
</section>
<section id="addams-family">
<h2>2.3. Addams family<a class="headerlink" href="#addams-family" title="Permalink to this headline">#</a></h2>
<section id="adam">
<h3>Adam<a class="headerlink" href="#adam" title="Permalink to this headline">#</a></h3>
<p>Adam (Adaptive Momentum) is the combination of Momentum and RMSprop. It inherits <span class="math notranslate nohighlight">\(m_t\)</span>, the exponential smoothing of <em>gradient</em> from Momentum and <span class="math notranslate nohighlight">\(v_t\)</span>, the exponential smoothing of <em>squared gradient</em> from RMSprop. According to the author of Adam, the inititialize value of <span class="math notranslate nohighlight">\(m_t\)</span> and <span class="math notranslate nohighlight">\(v_t\)</span> are 0 so they are biased towards 0, especially with a large smoothing factor. Adam fixes these biases by computing the corrected version of exponential smoothing, <span class="math notranslate nohighlight">\(\hat{m}_t\)</span> and <span class="math notranslate nohighlight">\(\hat{v}_t\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
m_t &amp;= \gamma m_{t-1} + (1-\gamma)g_t \\
v_t &amp;= \rho v_{t-1} + (1-\rho)g_t^2 \\
\hat{m}_t,\hat{v}_t &amp;= \frac{m_t}{1-\gamma^t},\frac{v_t}{1-\rho^t} \\
\Delta x_t &amp;= -\frac{\eta}{\sqrt{\hat{v}_t}+\epsilon} \hat{m}_t \\
x_{t+1} &amp;= x_t+\Delta x_t
\end{aligned}\end{split}\]</div>
<p>The original paper of Adam denotes <span class="math notranslate nohighlight">\(\beta_1\)</span> and <span class="math notranslate nohighlight">\(\beta_2\)</span> for smoothing coefficients. However, I keep the notations <span class="math notranslate nohighlight">\(\gamma\)</span> and <span class="math notranslate nohighlight">\(\rho\)</span> from Momentum and RMSprop to make things consistent. The default values suggested by the author are <span class="math notranslate nohighlight">\(\gamma=0.9\)</span> and <span class="math notranslate nohighlight">\(\rho=0.999\)</span>. Because <span class="math notranslate nohighlight">\(\eta\)</span> is a constant, a higher value will lead to faster convergence. Adam has the advantages of both Momentum and RMSprop: it can work well with sparse data, has a low learning time and can work well in online and non-stationary settings.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.animation</span> <span class="kn">import</span> <span class="n">FuncAnimation</span><span class="p">,</span> <span class="n">ArtistAnimation</span><span class="p">,</span> <span class="n">PillowWriter</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;seaborn&#39;</span><span class="p">,</span> <span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">])</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">Adam</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">xInit</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">v</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">xList</span><span class="p">,</span> <span class="n">yList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">nIter</span><span class="p">):</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">beta1</span> <span class="o">*</span> <span class="n">m</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">beta1</span><span class="p">)</span><span class="o">*</span><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">beta2</span> <span class="o">*</span> <span class="n">v</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">beta2</span><span class="p">)</span><span class="o">*</span><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">m_hat</span> <span class="o">=</span> <span class="n">m</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">beta1</span><span class="o">**</span><span class="n">i</span><span class="p">)</span>
        <span class="n">v_hat</span> <span class="o">=</span> <span class="n">v</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">beta2</span><span class="o">**</span><span class="n">i</span><span class="p">)</span>
        <span class="n">xDelta</span> <span class="o">=</span> <span class="o">-</span><span class="n">eta</span> <span class="o">*</span> <span class="n">m_hat</span><span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v_hat</span><span class="p">)</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">xDelta</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">xList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">xList</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">yList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yList</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span> <span class="k">break</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xList</span><span class="p">,</span> <span class="n">yList</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">grad</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">nIter</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">xInit</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">eta1</span> <span class="o">=</span> <span class="o">.</span><span class="mi">1</span>
<span class="n">eta2</span> <span class="o">=</span> <span class="o">.</span><span class="mi">3</span>
<span class="n">eta3</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span>
<span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-8</span>
<span class="n">beta1</span> <span class="o">=</span> <span class="o">.</span><span class="mi">9</span>
<span class="n">beta2</span> <span class="o">=</span> <span class="o">.</span><span class="mi">999</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">frames1</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta1</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">)</span>
<span class="n">frames2</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta2</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">)</span>
<span class="n">frames3</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">eta3</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span><span class="p">,</span> <span class="n">nIter</span><span class="p">,</span> <span class="n">xInit</span><span class="p">)</span>
<span class="n">iList</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">nIter</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">frames</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">iList</span><span class="p">,</span> <span class="n">frames1</span><span class="p">,</span> <span class="n">frames2</span><span class="p">,</span> <span class="n">frames3</span><span class="p">]</span>

<span class="n">xLeft</span><span class="p">,</span> <span class="n">xRight</span> <span class="o">=</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span>

<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ax3</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">xGraph</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xLeft</span><span class="p">,</span> <span class="n">xRight</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">yGraph</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">xGraph</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">animate</span><span class="p">(</span><span class="n">frame</span><span class="p">):</span>
    <span class="n">i</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="n">x3</span><span class="p">,</span> <span class="n">y3</span> <span class="o">=</span> <span class="n">frame</span>
    
    <span class="n">ax1</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xLeft</span><span class="p">,</span> <span class="n">xRight</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;eta=</span><span class="si">{</span><span class="n">eta1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">line1</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xGraph</span><span class="p">,</span> <span class="n">yGraph</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
    <span class="n">point1</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;indianred&#39;</span><span class="p">)</span>
    
    <span class="n">ax2</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;eta=</span><span class="si">{</span><span class="n">eta2</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">line2</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xGraph</span><span class="p">,</span> <span class="n">yGraph</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
    <span class="n">point2</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;indianred&#39;</span><span class="p">)</span>
    
    <span class="n">ax3</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;eta=</span><span class="si">{</span><span class="n">eta3</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">line3</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax3</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xGraph</span><span class="p">,</span> <span class="n">yGraph</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
    <span class="n">point3</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax3</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="n">y3</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;indianred&#39;</span><span class="p">)</span>
    
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Iteration </span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="s1">.0f</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">nIter</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">line1</span><span class="p">,</span> <span class="n">point1</span><span class="p">,</span> <span class="n">line2</span><span class="p">,</span> <span class="n">point2</span><span class="p">,</span> <span class="n">line3</span><span class="p">,</span> <span class="n">point3</span>

<span class="n">gif</span> <span class="o">=</span> <span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">animate</span><span class="p">,</span> <span class="n">frames</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

<span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;output/adam.gif&#39;</span>
<span class="n">gif</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="n">PillowWriter</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="adamax">
<h3>AdaMax<a class="headerlink" href="#adamax" title="Permalink to this headline">#</a></h3>
<p>While Adam only updates <span class="math notranslate nohighlight">\(v_t\)</span> using current gradient <span class="math notranslate nohighlight">\(g_t\)</span> and past gradient <span class="math notranslate nohighlight">\(v_{t-1}\)</span>, it scales the gradient inversely proportionally with <span class="math notranslate nohighlight">\(L_2\)</span> norm, AdaMax can generalize this update to the <span class="math notranslate nohighlight">\(L_p\)</span> norm. But with large value of <span class="math notranslate nohighlight">\(p\)</span>, norms become unstable, however <span class="math notranslate nohighlight">\(L_\infty\)</span> also generally exhibits stable behavior:
<span class="math notranslate nohighlight">\(\rho^\infty v_{t-1} + (1-\rho^\infty)|g_t|^\infty=\max(\rho v_{t-1},|g_t|)\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
m_t &amp;= \gamma m_{t-1} + (1-\gamma)g_t \\
v_t &amp;= \color{indianred}{\max(\rho v_{t-1},|g_t|)} \\
\hat{m}_t &amp;= \frac{m_t}{1-\gamma^t} \\
\Delta x_t &amp;= -\frac{\eta}{v_t} \hat{m}_t \\
x_{t+1} &amp;= x_t+\Delta x_t
\end{aligned}\end{split}\]</div>
<p>AdaMax can perform better than Adam, especially in embedding problems.</p>
</section>
<section id="nadam">
<h3>Nadam<a class="headerlink" href="#nadam" title="Permalink to this headline">#</a></h3>
<p>Nadam (Nesterov accelerated Adam) is a combination of NAG and Adam. NAG performs more accurately than standard momentum because it allows to perform a more accurate step in the gradient direction by updating the parameters with the momentum step before computing the gradient.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
m_t &amp;= \gamma m_{t-1} + (1-\gamma)g_t \\
v_t &amp;= \rho v_{t-1} + (1-\rho)g_t^2 \\
\hat{m}_t,\hat{v}_t &amp;= \frac{m_t}{1-\gamma^t},\frac{v_t}{1-\rho^t} \\
\Delta x_t &amp;= -\frac{\eta}{\sqrt{\hat{v}_t}+\epsilon}
    \left(\color{indianred}{\gamma\hat{m}_t+\frac{1-\gamma}{1-\gamma^t}g_t}\right) \\
x_{t+1} &amp;= x_t+\Delta x_t
\end{aligned}\end{split}\]</div>
</section>
<section id="amsgrad">
<h3>AMSGrad<a class="headerlink" href="#amsgrad" title="Permalink to this headline">#</a></h3>
<p>AMSGrad is a variant of Adam which revisits the adaptive learning rate component in Adam and changes it to ensure that the current <span class="math notranslate nohighlight">\(v\)</span> is always larger than the <span class="math notranslate nohighlight">\(v\)</span> from the previous time step. In Adam, it has been observed that some minibatches provide large and informative gradients, but as these minibatches only occur rarely, exponential averaging diminishes their influence, which leads to poor convergence. By selecting max <span class="math notranslate nohighlight">\(v\)</span>, AMSGrad results in a non-increasing step size, which avoids the problems suffered by Adam.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
m_t &amp;= \gamma m_{t-1} + (1-\gamma)g_t \\
v_t &amp;= \rho v_{t-1} + (1-\rho)g_t^2 \\
\hat{v}_t &amp;= \color{indianred}{\max(\hat{v}_{t-1},v_t)} \\
\Delta x_t &amp;= -\frac{\eta}{\sqrt{\hat{v}_t}+\epsilon} \hat{m}_t \\
x_{t+1} &amp;= x_t+\Delta x_t
\end{aligned}\end{split}\]</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="references">
<h1>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h1>
<ul class="simple">
<li><p><em><a class="reference external" href="http://ruder.io">ruder.io</a> - <a class="reference external" href="https://ruder.io/optimizing-gradient-descent/index.html">An overview of gradient descent optimization algorithms</a></em></p></li>
<li><p><em><a class="reference external" href="http://arxiv.org">arxiv.org</a> - <a class="reference external" href="https://arxiv.org/pdf/1212.0901v2.pdf">Advances in optimizing Recurrent Networks</a></em></p></li>
<li><p><em><a class="reference external" href="http://arxiv.org">arxiv.org</a> - <a class="reference external" href="https://arxiv.org/pdf/1212.5701.pdf">AdaDelta: An Adaptive Learning Rate Method</a></em></p></li>
<li><p><em><a class="reference external" href="http://arxiv.org">arxiv.org</a> - <a class="reference external" href="https://arxiv.org/pdf/1412.6980.pdf">Adam: A method for Stochastic Optimization</a></em></p></li>
<li><p><em><a class="reference external" href="http://web.stanford.edu">web.stanford.edu</a> - <a class="reference external" href="https://web.stanford.edu/~jduchi/projects/DuchiHaSi10_colt.pdf">Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></em></p></li>
<li><p><em><a class="reference external" href="http://cs229.stanford.edu">cs229.stanford.edu</a> - <a class="reference external" href="https://cs229.stanford.edu/proj2015/054_report.pdf">Incoporating Nesterov Momentum into Adam</a></em></p></li>
<li><p><em><a class="reference external" href="http://openreview.net">openreview.net</a> - <a class="reference external" href="https://openreview.net/pdf?id=ryQu7f-RZ">On the Convergence of Adam and Beyond</a></em></p></li>
<li><p><em><a class="reference external" href="http://d2l.ai">d2l.ai</a> - <a class="reference external" href="http://d2l.ai/chapter_optimization/index.html">Optimization algorithms</a></em></p></li>
<li><p><em>distill.pub - <a class="reference external" href="https://distill.pub/2017/momentum/">Why Momentum really works</a></em></p></li>
<li><p><em><a class="reference external" href="http://compphysics.github.io">compphysics.github.io</a> - <a class="reference external" href="https://compphysics.github.io/MachineLearningMSU/doc/pub/GradientOptim/html/._GradientOptim-bs000.html">Optimization and Gradient Methods</a></em></p></li>
<li><p><em><a class="reference external" href="http://towardsdatascience.com">towardsdatascience.com</a> - <a class="reference external" href="https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d">Stochastic Gradient Descent with momentum</a></em></p></li>
<li><p><em><a class="reference external" href="http://blog.paperspace.com">blog.paperspace.com</a> - <a class="reference external" href="https://blog.paperspace.com/intro-to-optimization-momentum-rmsprop-adam/">Intro to optimization in deep learning: Momentum, RMSProp and Adam</a></em></p></li>
</ul>
<hr class="docutils" />
<p><em>â™¥ By Quang Hung x Thuy Linh â™¥</em></p>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="27-plotly-interactive-visualization.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">1. Introduction</p>
        </div>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Jupyter Book Community<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>